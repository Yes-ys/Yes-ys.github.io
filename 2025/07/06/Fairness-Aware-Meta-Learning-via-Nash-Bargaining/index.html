


<!DOCTYPE html>
<html lang="ch">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<title>Fairness-Aware Meta-Learning via Nash Bargaining [ 代码和诗 ]</title>
	
	
	<!-- stylesheets list from _config.yml -->
	
	<link rel="stylesheet" href="/css/PreciousJoy.css">
	
	<link rel="stylesheet" href="/css/top-bar.css">
	
	<link rel="stylesheet" href="/css/menu-outer.css">
	
	<link rel="stylesheet" href="/css/content-outer.css">
	
	<link rel="stylesheet" href="/css/bottom-outer.css">
	
	<link rel="stylesheet" href="/css/atom-one-dark.css">
	
	<link rel="stylesheet" href="/css/recent-posts-item.css">
	
	<link rel="stylesheet" href="/css/article-sidebar-toc.css">
	
	<link rel="stylesheet" href="/css/jquery.fancybox.min.css">
	
	<link rel="stylesheet" href="/css/search.css">
	
	<link rel="stylesheet" href="/css/toc.css">
	
	<link rel="stylesheet" href="/css/sidebar.css">
	
	<link rel="stylesheet" href="/css/archive.css">
	
	<link rel="stylesheet" href="/css/jquery.mCustomScrollbar.min.css">
	
	<link rel="stylesheet" href="/css/Z-last-cover-others.css">
	
	
	
<meta name="generator" content="Hexo 7.3.0"></head>




<body id="wrapper">

	<div id="">
		
		<div id="top-bar">
			
			<div id="avatar-box">
				<img 
				class="avatar"
				src="/images/my-avatar.jpg" //网站头像
				alt="avatar">
			</div>

			<div id="top-bar-text">
				<div id="top-bar-title">
					阳生。
				</div>
				<div id="top-bar-slogan">
					风毛丛劲节，只上尽头竿。
				</div>
			</div>

		</div>

		<div id="menu-outer">
			<div id="menu-inner">
				
				
				<div class="menu-item">
					<a href="/">Home</a>
				</div>
				
				<div class="menu-item">
					<a href="/about">About</a>
				</div>
				
				<div class="menu-item">
					<a href="/archives">Archives</a>
				</div>
				

				<div class="menu-item menu-item-search">
					
  <span class="local-search local-search-google local-search-plugin">
      <input type="search" placeholder="站内搜索" id="local-search-input" class="local-search-input-cls" style="">
      <div id="local-search-result" class="local-search-result-cls"></div>
  </span>
	
				</div>

			</div>
		</div>

		<div id="content-outer">
			<div id="content-inner">

				
<div id="details">
	
	<article id="details-post">
		<div id=details-post-item>
			<h1>Fairness-Aware Meta-Learning via Nash Bargaining</h1>
			<p><code>这篇blog用于记录我阅读的一篇将传统的Game中的方法应用到学习中的论文</code></p>
<h2 id="论文理解"><a href="#论文理解" class="headerlink" title="论文理解"></a>论文理解</h2><p>思路：</p>
<ol>
<li>经典的Meta-learning的框架</li>
<li>Meta-learning在learning with fairness中的运用（框架、典型的方法）</li>
<li>经典方法中存在的问题 &amp; 使用 NBS的改进</li>
</ol>
<h3 id="Meta-learning的框架"><a href="#Meta-learning的框架" class="headerlink" title="Meta-learning的框架"></a>Meta-learning的框架</h3><p>在解决机器学习的过程中对于不同group的公平性问题的时候，会使用sensitive-attributed validation set来训练调整模型的参数，这个过程与常规的训练过程相结合通常被套入一个meta-learning framework中。</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p><code>用于记录阅读过程中，遇到的新的、不熟悉的概念</code></p>
<h3 id="Group-level-fairness"><a href="#Group-level-fairness" class="headerlink" title="Group-level fairness"></a>Group-level fairness</h3><p>群体级公平性： 群体级公平性是指在机器学习模型中确保不同群体（如性别、种族、年龄等）在预测结果上受到公平对待。具体来说，这意味着模型的性能（如准确率、误报率等）在不同群体之间应该尽可能一致，避免某些群体受到系统性的偏见或歧视。例如，在招聘系统中，不同性别的候选人应该有相似的通过率，而不是系统性地偏向某一性别。</p>
<h3 id="Fairness-objectives"><a href="#Fairness-objectives" class="headerlink" title="Fairness objectives"></a>Fairness objectives</h3><p>公平性目标：公平性目标是指在模型训练和评估过程中设定的具体指标，用来衡量和改进模型的公平性。</p>
<p>常见的公平性目标有：</p>
<ol>
<li>Demographic parity：模型的预测结果应该在不同群体之间均匀分布。</li>
<li>Equalized odds：在不同群体中，模型的假正率和假负率应该相同。</li>
<li>Equal opportunity：对于实际正类样本，不同群体的真正率应该相同。</li>
</ol>
<p>补充：<br>Demographically balanced validation set（人口统计学平衡的验证集）：指在机器学习模型的验证过程中，确保验证集中的数据在人口统计学特征（例如：性别、年龄、种族、收入水平、地理位置等）上具有均衡性。这种平衡的目标是使得模型能够在不同群体之间表现一致，从而避免模型在某些群体上产生偏差或不公平的表现。</p>
<h3 id="Sensitive-attributed-validation-set"><a href="#Sensitive-attributed-validation-set" class="headerlink" title="Sensitive attributed validation set"></a>Sensitive attributed validation set</h3><p>敏感属性验证集：敏感属性验证集是指包含敏感属性（如性别、种族、年龄等）的数据集，用于评估模型在这些属性上的表现和公平性。通过在验证集上测试模型的表现，可以确定模型是否对某些群体存在偏见，并据此调整模型参数以提升公平性。例如，如果发现模型在不同种族上的准确率差异较大，可以通过调整模型来减少这种差异。</p>
<h3 id="Meta-learning-framework"><a href="#Meta-learning-framework" class="headerlink" title="Meta-learning framework"></a>Meta-learning framework</h3><p>元学习：指的是“学习如何学习”，即通过学习算法在多个任务上的表现，来调整和优化学习过程本身。在机器学习中，元学习框架通常用于设计模型，帮助它们更好地适应新任务，或者从不同任务中学习出更泛化的知识。</p>
<p>元学习框架：通过一个高层的学习过程，动态地调整模型的参数，以便满足公平性目标。这种框架让机器学习模型不仅仅是对一个固定任务进行学习，还能调整自己的学习策略，以实现更好的公平性目标。</p>
<h4 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h4><p>为什么需要Meta-learning</p>
<p>神经网络在进行猫、狗的图像识别的时候，可能需要数以千计的图片用于训练模型的参数，最终对于新给出的图片神经网络才能给出正确的结果。类比人类的小孩子，在没有见过任何动物的情况下，可能也需要见过许多猫猫狗狗才能正确区分这两种动物。</p>
<p>在此基础上，出现了一只驴子，人类小孩可以结合以前对于识别猫狗的经验，来观察驴子的特征，通过这一只驴子，在未来就可能正确的识别出新的驴子；但是对于神经网络而言无法做到。</p>
<p>Meta-learning的目的就是想赋予神经网络这样的能力——基于过去的学习经验，对于新的学习任务，进行一个快速的学习。</p>
<h4 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h4><p>基本机器学习算法流程：</p>
<ol>
<li>Data1，例如(x, y)，x是特征，y是label，将它们输入模型</li>
<li>Traning1，对Loss求gradient，迭代</li>
<li>Model1，直到收敛，得到一组权重，对应就是Model1</li>
</ol>
<p><em>算法描述：</em></p>
<p>For all $\mathcal{T}_i$ do<br>Evaluate $\nabla_\theta \mathcal{L}(\mathcal{T}_i, f_\theta)$ with respect to $K$ examples.<br>Compute adapted parameters with gradient descent:<br>$\theta’_i &#x3D; \theta - \alpha \nabla_\theta \mathcal{L}(\mathcal{T}_i, f_\theta)$<br>end for</p>
<p>实际上这就是Meta learning的inner part，在此基础上加上outer part就是完整的元学习框架。</p>
<p><em>算法描述：</em></p>
<p>Require：$p(\mathcal{T})$: distribution over tasks<br>Require: $\alpha, \beta$: step size hyperparameters</p>
<ol>
<li>randomly initialize $\theta$</li>
<li>while not done do</li>
<li>Sample batch of tasks $\mathcal{T}_i$~$p(\mathcal{T})$</li>
<li>for all $\mathcal{T}_i do$</li>
<li>Evaluate $\nabla_\theta \mathcal{L}(\mathcal{T}_i, f_\theta)$ with respect to $K$ examples.  </li>
<li>Compute adapted parameters with gradient descent:<br>$\theta’_i &#x3D; \theta - \alpha \nabla_\theta \mathcal{L}(\mathcal{T}_i, f_\theta)$  </li>
<li>end for</li>
<li>Update $\theta$&lt;-$\theta - \beta \nabla_{\theta} \sum_{\mathcal{T}<em>i ~ p(\mathcal{T})}\mathcal{L}</em>{\mathcal{T}<em>i}(f</em>{\theta’_{i}})$</li>
<li>end while</li>
</ol>
<p>元学习有两个loop，inner loop对应for，outer loop对应while</p>
<p>inner loop会从很多个模型挑出几个进行训练，$\theta_i$就对应第i个模型（训练器）</p>
<p>$p(\mathcal{T})$就是所有的Task<br>$\alpha, \beta$是学习率，前者是对每个模型学习的学习率，后者是元学习的学习率</p>
<p>Update $\theta$&lt;-$\theta - \beta \nabla_{\theta} \sum_{\mathcal{T}<em>i ~ p(\mathcal{T})}\mathcal{L}</em>{\mathcal{T}<em>i}(f</em>{\theta’_{i}})$是最关键的一步，结合inner loop中的所有loss，定义新的loss，再求梯度，用来更新$\theta$。其体现出的是元学习模型是要学习各种小模型的平均能力。</p>
<p>其好处是你最终得到的$\theta$（对应的各种weights），可以用于作为未来你要训练的用于一个新的任务的小模型时$\theta_{new}$的初始值（新的任务与过去的各种小模型对应的任务相似），这样由于初始的权重天然对应各种小模型的平均能力，其在学习的过程中可以很快地收敛，加快训练速度。</p>
<h3 id="Hypergradient"><a href="#Hypergradient" class="headerlink" title="Hypergradient"></a>Hypergradient</h3><p>超梯度： 在元学习中，<strong>超梯度（hypergradient）</strong>是指对学习过程本身的梯度进行计算。简单来说，元学习需要优化的目标不仅仅是模型的参数（如权重），还包括学习规则或算法本身的参数（例如学习率）。</p>
<p>超梯度冲突：在元学习过程中，当不同的子群体（如不同性别或种族的群体）需要不同的调整来实现公平性目标时，这些调整可能会产生冲突。例如，为了在某个群体上实现某个公平性目标，可能需要对模型的某个参数进行特定的调整，但对另一个群体却可能会产生不利影响，导致不同的公平性目标之间无法兼容。这样的冲突会导致模型优化过程的不稳定，甚至可能使得模型的性能和公平性都受到影响。</p>
<h3 id="validation-loss"><a href="#validation-loss" class="headerlink" title="validation loss"></a>validation loss</h3><p>验证损失：在验证集上评估模型性能时计算得到的损失值。它衡量了模型在验证集上的预测误差。通常来说，训练过程中，我们希望看到训练损失（training loss）和验证损失（validation loss）都逐渐降低，这表明模型在不断学习和提高性能。</p>
<p>损失（loss）：是模型预测结果与实际标签之间差异的度量。它通常表示为一个数值，表示模型在进行预测时的“错误程度”。常见的损失函数有均方误差（MSE）、交叉熵损失（Cross-Entropy Loss）等。</p>
<p>验证集：一个与训练集和测试集不同的数据集，通常用于在训练过程中对模型进行评估和调优。验证集用于检查模型的泛化能力——即模型能否在没有见过的数据上表现良好。</p>
<p>注：<strong>如果验证损失开始增加，而训练损失继续降低，可能表明模型在训练数据上过拟合，即模型学习了训练数据中的噪声和不相关的细节，而不是学到了一般性的规律。</strong></p>
<h3 id="social-context-of-a-learning-system"><a href="#social-context-of-a-learning-system" class="headerlink" title="social context of a learning system"></a>social context of a learning system</h3><p>Environment： 在传统的机器学习中，环境通常指的是模型与之交互并从中获取数据的外部系统或空间。例如，在强化学习中，智能体（agent）通过与环境交互来学习和优化其决策策略。在这个语境下，“环境”通常被视为一个相对抽象的、无差别的对象，包含了所有外部因素，模型仅通过这些因素进行训练。</p>
<p>Scarcity：稀缺性指的是资源（如时间、金钱、机会等）在社会中是有限的。在机器学习系统的社交背景下，稀缺性涉及到社会资源的分配问题，如何在有限的资源中做出选择，尤其是在多个利益相关方或群体之间进行权衡。</p>
<p>Conflict：冲突指的是在社会环境中，由于利益、目标或观点的差异，可能会出现对立或争执。在机器学习中，这个概念可以指不同利益相关者之间（如不同用户、群体、公司等）在使用技术时可能产生的矛盾与对立。例如，算法可能会在某些群体之间造成不平等，从而引发冲突。</p>
<p>Social norms：社会规范是指在某一社会群体中广泛接受和遵守的行为标准和价值观。它们定义了个体之间的行为预期。例如，公平性和诚信可能是许多社会群体的核心规范。机器学习系统在部署时需要考虑这些社会规范，以避免做出违反社会价值观的决策。</p>
<p>Communication：在机器学习的社会背景中，沟通通常指的是人与人、人与机器之间的信息交换。在机器学习系统中，沟通可能涉及模型与用户或开发者之间的反馈机制，以及如何有效地传达模型的意图、预测和决策。</p>
<p>Trust： 信任是指个体或群体对系统、技术或他人的可靠性和诚实性的信念。在机器学习系统中，信任至关重要，尤其是在人们需要依赖算法做出决策时。例如，如果用户不信任推荐系统或自动驾驶车辆的决策，那么这些系统的使用将受到限制。信任的缺失可能导致模型的抵制或不使用。</p>
<p>Fairness：公平性是指在决策或资源分配过程中，各方是否受到平等对待。机器学习中的公平性问题通常与算法可能对特定群体或个体产生不公正的偏见有关。例如，性别、种族、年龄等因素可能影响模型的预测结果。解决机器学习中的公平性问题，通常需要确保不同群体在模型中的待遇是平等的，避免不必要的偏见和歧视。</p>
<h3 id="Bi-level-optimization"><a href="#Bi-level-optimization" class="headerlink" title="Bi-level optimization"></a>Bi-level optimization</h3><p>双层优化：一种优化问题，其中的优化过程分为两个层级：上层优化和下层优化。每一层都有自己的优化目标和约束条件，而下层优化的解通常会影响上层优化的目标函数。</p>
<p>上层优化：这是优化问题的“外层”或“主层”，目标是优化一个总体目标，这通常是由下层优化问题的解所决定的。</p>
<p>下层优化：这是优化问题的“内层”或“子问题”，其目标是最小化或最大化一个局部目标。这个问题通常是通过上层优化问题中的参数来定义的，或者说下层优化问题的解是上层优化问题的约束之一。</p>
<p>在元学习中的应用：假设我们有一个双层优化问题，其中上层优化的目标是选择最优的模型参数，而下层优化则通过训练模型来优化模型的性能。这种结构常见于元学习（Meta-learning）和模型调优等问题中。例如，在元学习中，上层优化可能是学习一个优化策略，而下层优化则是针对特定任务的参数优化。</p>
<p>形式化：<br>双层优化问题通常可以用以下数学表达式来表示：</p>
<p>上层问题（Outer problem）：<br>$  \min_{\theta} , F(\theta, \mathbf{z}^*(\theta))$</p>
<p>其中，$\theta$ 是上层优化的决策变量，$\mathbf{z}^*(\theta)$<br>  是下层优化问题的最优解，它依赖于$\theta$。</p>
<p>下层问题（Inner problem）：<br>$  \min_{\mathbf{z}} , G(\mathbf{z}, \theta)$</p>
<p>其中，$\mathbf{z}$ 是下层优化的决策变量，$G(\mathbf{z}, \theta)$ 是下层优化问题的目标函数，$\theta$ 是从上层优化传递下来的参数。</p>
<h3 id="minibatch"><a href="#minibatch" class="headerlink" title="minibatch"></a>minibatch</h3><p>在机器学习和深度学习中，一种将大型数据集分割成较小的子集进行训练的方法。这种方法可以加速训练过程，同时减少计算资源的需求。</p>
<h2 id="词汇"><a href="#词汇" class="headerlink" title="词汇"></a>词汇</h2><p>aggregation：聚合</p>
<p>monotonic：单调的</p>
<p>steer：引导</p>
<p>navigate the issue：解决</p>
<p>validation：验证</p>
<p>emerging applications：新兴应用</p>
<p>lump：整合、混淆</p>
<p>deployment：部署</p>
<p>amplification：扩大、引申</p>
<p>clarity：清晰</p>
<p>align with：保持一致</p>
<p>address：解决</p>
<p>integrate：整合、合并</p>
<p>disparity：不一致</p>
<p>demographic：具有某种特征的群体；人口的</p>
<p>epochs：迭代次数</p>
<p>prevalence：流行、普遍存在</p>
<p>intrinsic：固有的</p>
<p>alignment issues：不一致问题</p>
<p>be derived by：由…推导出</p>
<p>untenable：站不住脚的</p>
<p>circumvent：回避</p>
<p>consensus：共识</p>
<p>intermediate：居中的、中等程度的</p>
<p>feasible：可行的、很可能会发生的</p>

		</div>

		<!-- <!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC80NjIyNC8yMjczNQ==">
	<script type="text/javascript">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
	</script>
<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 --> -->
		
	</article>

	<div id="toc">
		
	</div>

</div>

<!-- <div id="paginator"> -->
<!-- 	 -->
<!-- </div> -->
<!-- page.mathjax == true修改为true，默认开启-->

    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });
      </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });
      </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });
    </script>

    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



			</div>
		</div>

		<div id="bottom-outer">
			<div id="bottom-inner">
				Site by 阳生 | 
				Powered by <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a> |
				theme <a target="_blank" rel="noopener" href="https://github.com/fireworks99/hexo-theme-PreciousJoy">PreciousJoy</a>
			</div>
		</div>

		
	</div>





	
	<!-- scripts list from theme config.yml -->
	
	<script src="/js/jquery-3.5.1.min.js"></script>
	
	<script src="/js/PreciousJoy.js"></script>
	
	<script src="/js/highlight.pack.js"></script>
	
	<script src="/js/jquery.fancybox.min.js"></script>
	
	<script src="/js/search.js"></script>
	
	<script src="/js/load.js"></script>
	
	<script src="/js/jquery.mCustomScrollbar.concat.min.js"></script>
	
	<script src="/js/clipboard.min.js"></script>
	
	

	<script>hljs.initHighlightingOnLoad();</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
