


<!DOCTYPE html>
<html lang="ch">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<title>学习向量量化 [ 代码和诗 ]</title>
	
	
	<!-- stylesheets list from _config.yml -->
	
	<link rel="stylesheet" href="/css/PreciousJoy.css">
	
	<link rel="stylesheet" href="/css/top-bar.css">
	
	<link rel="stylesheet" href="/css/menu-outer.css">
	
	<link rel="stylesheet" href="/css/content-outer.css">
	
	<link rel="stylesheet" href="/css/bottom-outer.css">
	
	<link rel="stylesheet" href="/css/atom-one-dark.css">
	
	<link rel="stylesheet" href="/css/recent-posts-item.css">
	
	<link rel="stylesheet" href="/css/article-sidebar-toc.css">
	
	<link rel="stylesheet" href="/css/jquery.fancybox.min.css">
	
	<link rel="stylesheet" href="/css/search.css">
	
	<link rel="stylesheet" href="/css/toc.css">
	
	<link rel="stylesheet" href="/css/sidebar.css">
	
	<link rel="stylesheet" href="/css/archive.css">
	
	<link rel="stylesheet" href="/css/jquery.mCustomScrollbar.min.css">
	
	<link rel="stylesheet" href="/css/Z-last-cover-others.css">
	
	
	
<meta name="generator" content="Hexo 7.3.0"></head>




<body id="wrapper">

	<div id="">
		
		<div id="top-bar">
			
			<div id="avatar-box">
				<img 
				class="avatar"
				src="/images/my-avatar.jpg" //网站头像
				alt="avatar">
			</div>

			<div id="top-bar-text">
				<div id="top-bar-title">
					阳生。
				</div>
				<div id="top-bar-slogan">
					风毛丛劲节，只上尽头竿。
				</div>
			</div>

		</div>

		<div id="menu-outer">
			<div id="menu-inner">
				
				
				<div class="menu-item">
					<a href="/">Home</a>
				</div>
				
				<div class="menu-item">
					<a href="/about">About</a>
				</div>
				
				<div class="menu-item">
					<a href="/archives">Archives</a>
				</div>
				

				<div class="menu-item menu-item-search">
					
  <span class="local-search local-search-google local-search-plugin">
      <input type="search" placeholder="站内搜索" id="local-search-input" class="local-search-input-cls" style="">
      <div id="local-search-result" class="local-search-result-cls"></div>
  </span>
	
				</div>

			</div>
		</div>

		<div id="content-outer">
			<div id="content-inner">

				
<div id="details">
	
	<article id="details-post">
		<div id=details-post-item>
			<h1>学习向量量化</h1>
			<p><code>这篇blog用于记录我使用python对学习向量量化这种聚类算法的复现</code></p>
<h2 id="算法简介"><a href="#算法简介" class="headerlink" title="算法简介"></a>算法简介</h2><p>学习向量量化也成为LVQ(Learning Vector Quantization)，同样属于原型聚类算法，类似于k-means通过希望划分的簇的数量求得相同数量的“簇中心”并以此为原型将数据集划分为对应的簇，LVQ通过求得与希望划分的簇数量相同的“原型向量”，并以此来将数据集划分为对应的簇。</p>
<p>如果说k-means也同样是借助原型向量的话，那么关键就在于两种算法更新原型向量的方法不同。k-means是不断的用原型向量划分簇，又用簇更新原型向量；LVQ则是利用样本的预先标注作为“监督信息”，不断利用样本更新原型向量。</p>
<h2 id="算法详解"><a href="#算法详解" class="headerlink" title="算法详解"></a>算法详解</h2><p>整个算法的大致流程如下：</p>
<p>输入: $D &#x3D; {(x_1,y_1),(x_2,y_2),…,(x_m,y_m)}, q, {t_1,t_2,…,t_q},\eta \in (0,1)$其中，D是带有标记的数据集，q是原型向量个数，$t_i,i \in {1,2,…,q}$ 对应原型向量的标记，$\eta$是学习率</p>
<p>算法过程：</p>
<ol>
<li>初始化原型向量${p_1,p_2,…,p_q}$</li>
<li>repeat:</li>
<li>从$D$中随机挑选一个样本$(x_j,y_j)$</li>
<li>找到与$x_j$最近的原型向量$p_i^{*}$</li>
<li>if($t_i^{*}$ &#x3D;&#x3D; $y_j$): $p’ &#x3D; p_i^{*} + \eta(p_i^{*} - x_j)$</li>
<li>else: $p’ &#x3D; p_i^{*} - \eta(p_i^{*} - x_j)$</li>
<li>判断是否到达退出条件</li>
</ol>
<p>整个算法过程的关键就在于5、6，实际上相当于找到距离原型向量最近的样本，如果是同标记的则将该原型向量向该样本“拉近”，如果是不同标记的则“推远”（因为对应的是同标记的在一个簇中可能性较大，不同标记在不同簇中可能性较大）</p>
<p>关于7的退出条件，通常可以设置一个最大迭代轮数，或者是原型向量的更新程度已经小于了一个阈值。</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>使用python对西瓜书上的示例复现代码如下（30个样本，9-21号样本标记为2，其它样本标记为1，随机选择5个样本作为原始向量，标记分别为1、2、2、1、1，学习率为0.1）</p>
<p>Data.py数据集部分:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">D = [</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0.697</span>, <span class="number">0.460</span>], [<span class="number">0.774</span>, <span class="number">0.376</span>], [<span class="number">0.634</span>, <span class="number">0.264</span>], [<span class="number">0.608</span>, <span class="number">0.318</span>], [<span class="number">0.556</span>, <span class="number">0.215</span>],</span><br><span class="line">    [<span class="number">0.403</span>, <span class="number">0.237</span>], [<span class="number">0.481</span>, <span class="number">0.149</span>], [<span class="number">0.437</span>, <span class="number">0.211</span>], [<span class="number">0.666</span>, <span class="number">0.091</span>], [<span class="number">0.243</span>, <span class="number">0.267</span>],</span><br><span class="line">    [<span class="number">0.245</span>, <span class="number">0.057</span>], [<span class="number">0.343</span>, <span class="number">0.099</span>], [<span class="number">0.639</span>, <span class="number">0.161</span>], [<span class="number">0.657</span>, <span class="number">0.198</span>], [<span class="number">0.360</span>, <span class="number">0.370</span>],</span><br><span class="line">    [<span class="number">0.593</span>, <span class="number">0.042</span>], [<span class="number">0.719</span>, <span class="number">0.103</span>], [<span class="number">0.359</span>, <span class="number">0.188</span>], [<span class="number">0.339</span>, <span class="number">0.241</span>], [<span class="number">0.282</span>, <span class="number">0.257</span>],</span><br><span class="line">    [<span class="number">0.748</span>, <span class="number">0.232</span>], [<span class="number">0.714</span>, <span class="number">0.346</span>], [<span class="number">0.483</span>, <span class="number">0.312</span>], [<span class="number">0.478</span>, <span class="number">0.437</span>], [<span class="number">0.525</span>, <span class="number">0.369</span>],</span><br><span class="line">    [<span class="number">0.751</span>, <span class="number">0.489</span>], [<span class="number">0.532</span>, <span class="number">0.472</span>], [<span class="number">0.473</span>, <span class="number">0.376</span>], [<span class="number">0.725</span>, <span class="number">0.445</span>], [<span class="number">0.446</span>, <span class="number">0.459</span>]</span><br><span class="line">]  <span class="comment"># 数据集，1~30，0索引不使用</span></span><br><span class="line"><span class="comment"># 数据集的标记，LVQ使用</span></span><br><span class="line">T = [</span><br><span class="line">    <span class="number">0</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">    <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">    <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">    <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">]</span><br><span class="line"><span class="comment"># 原始向量标记的输入</span></span><br><span class="line">q_vect = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p>main.py主函数部分：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> K_means</span><br><span class="line"><span class="keyword">import</span> LVQ</span><br><span class="line"><span class="keyword">import</span> Data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(): </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;LVQ 的结果&quot;</span>, end=<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    res = LVQ.lvq(Data.D, Data.T, Data.q_vect)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">len</span>(res[i]) - <span class="number">1</span>, end=<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(res[i]) == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;[]&quot;</span>, end=<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(res[i])):</span><br><span class="line">            <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="built_in">print</span>(res[i][j], end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(res[i]) != <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">        main()</span><br></pre></td></tr></table></figure>

<p>LVQ.py学习向量量化算法部分：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lvq</span>(<span class="params">D:[[<span class="built_in">float</span>]], T:[<span class="built_in">int</span>], q_vect:[]</span>):</span><br><span class="line">l_rate = <span class="number">0.1</span></span><br><span class="line"><span class="keyword">import</span> random <span class="keyword">as</span> rd</span><br><span class="line">q_vec_index = rd.sample(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">31</span>), <span class="number">5</span>)  <span class="comment"># 随机选取5个样本作为原型向量</span></span><br><span class="line">q_vec = []  <span class="comment"># 原型向量</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">    q_vec.append(D[q_vec_index[i]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">10000</span>):  <span class="comment"># 迭代10000轮</span></span><br><span class="line">    j_dex = rd.randint(<span class="number">1</span>,<span class="number">30</span>)  <span class="comment"># 随机挑选一个样本，randint函数的参数是一个闭区间！</span></span><br><span class="line">    q = <span class="number">0</span> <span class="comment"># 距离j_dex最近的原型向量的索引</span></span><br><span class="line">    d = (D[j_dex][<span class="number">0</span>] - q_vec[<span class="number">0</span>][<span class="number">0</span>])**<span class="number">2</span> + (D[j_dex][<span class="number">1</span>] - q_vec[<span class="number">0</span>][<span class="number">1</span>])**<span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">5</span>):</span><br><span class="line">        d_i = (D[j_dex][<span class="number">0</span>] - q_vec[i][<span class="number">0</span>])**<span class="number">2</span> + (D[j_dex][<span class="number">1</span>] - q_vec[i][<span class="number">1</span>])**<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> d_i &lt; d:</span><br><span class="line">            q = i</span><br><span class="line">            d = d_i</span><br><span class="line">    <span class="keyword">if</span> q_vect[q] == T[j_dex]:  <span class="comment"># 将原型向量与样本拉近</span></span><br><span class="line">        q_vec[q][<span class="number">0</span>] = q_vec[q][<span class="number">0</span>] + l_rate*(D[j_dex][<span class="number">0</span>] - q_vec[q][<span class="number">0</span>])</span><br><span class="line">        q_vec[q][<span class="number">1</span>] = q_vec[q][<span class="number">1</span>] + l_rate*(D[j_dex][<span class="number">1</span>] - q_vec[q][<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># 将原型向量与样本推远</span></span><br><span class="line">        q_vec[q][<span class="number">0</span>] = q_vec[q][<span class="number">0</span>] - l_rate * (D[j_dex][<span class="number">0</span>] - q_vec[q][<span class="number">0</span>])</span><br><span class="line">        q_vec[q][<span class="number">1</span>] = q_vec[q][<span class="number">1</span>] - l_rate * (D[j_dex][<span class="number">1</span>] - q_vec[q][<span class="number">1</span>])</span><br><span class="line">result = [[], [], [], [], []]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">    result[i].append(q_vec[i])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">31</span>):</span><br><span class="line">    j = <span class="number">0</span></span><br><span class="line">    d = (D[i][<span class="number">0</span>] - q_vec[j][<span class="number">0</span>])**<span class="number">2</span> + (D[i][<span class="number">1</span>] - q_vec[j][<span class="number">0</span>])**<span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">5</span>):</span><br><span class="line">        d_ = (D[i][<span class="number">0</span>] - q_vec[_][<span class="number">0</span>])**<span class="number">2</span> + (D[i][<span class="number">1</span>] - q_vec[_][<span class="number">1</span>])**<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> d_ &lt; d:</span><br><span class="line">            d = d_</span><br><span class="line">            j = _</span><br><span class="line">    result[j].append(D[i])</span><br><span class="line"><span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>

<p><code>捉个一个虫，py中万物皆对象，在初始化q_vec的时候直接将数据集D中的元素append进去，实际上共享了内存，这会导致更新原型向量的时候，数据集中的元素被更新，解决方案是使用深拷贝</code></p>
<p>修改方法：<br>将q_vec初始化的地方：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">q_vec = []  <span class="comment"># 原型向量</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">    q_vec.append(D[q_vec_index[i]])</span><br></pre></td></tr></table></figure>

<p>更改为：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">q_vec = [x.copy() <span class="keyword">for</span> x <span class="keyword">in</span> (D[i] <span class="keyword">for</span> i <span class="keyword">in</span> q_vec_index)]  <span class="comment"># 关键修复点：使用列表拷贝</span></span><br></pre></td></tr></table></figure>

<p>最终运行结果：</p>
<blockquote>
<p>3<br>[0.36, 0.37] [0.478, 0.437] [0.446, 0.459]<br>8<br>[0.634, 0.264] [0.556, 0.215] [0.666, 0.091] [0.639, 0.161] [0.657, 0.198] [0.593, 0.042] [0.719, 0.103] [0.748, 0.232]<br>9<br>[0.403, 0.237] [0.481, 0.149] [0.437, 0.211] [0.243, 0.267] [0.245, 0.057] [0.343, 0.099] [0.359, 0.188] [0.339, 0.241] [0.282, 0.257]<br>5<br>[0.697, 0.46] [0.774, 0.376] [0.714, 0.346] [0.751, 0.489] [0.725, 0.445]<br>5<br>[0.608, 0.318] [0.483, 0.312] [0.525, 0.369] [0.532, 0.472] [0.473, 0.376]  </p>
</blockquote>
<p>对应为5个簇中样本的数量和相应的样本</p>
<p><code>注：理论上应该将数据集D划分为训练集和测试集，通过训练集训练模型（得到所有合理的原型向量），然后利用测试集测试，利用原型向量将测试集划分为对应数量的簇；这样才能完整地体现“机器学习”，但是这里只是一个简单的例子，将数据集D全用作训练集，得到原型向量，再把整个训练集划分为了对应的簇。</code><br><code>有了原型向量之后，划分为簇是很简单的，样本距离哪个原型向量最近，就纳入对应的簇即可。</code></p>

		</div>

		<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC80NjIyNC8yMjczNQ==">
	<script type="text/javascript">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
	</script>
<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->
		
	</article>

	<div id="toc">
		
	</div>

</div>

<!-- <div id="paginator"> -->
<!-- 	 -->
<!-- </div> -->


			</div>
		</div>

		<div id="bottom-outer">
			<div id="bottom-inner">
				Site by 阳生 | 
				Powered by <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a> |
				theme <a target="_blank" rel="noopener" href="https://github.com/fireworks99/hexo-theme-PreciousJoy">PreciousJoy</a>
			</div>
		</div>

		
	</div>





	
	<!-- scripts list from theme config.yml -->
	
	<script src="/js/jquery-3.5.1.min.js"></script>
	
	<script src="/js/PreciousJoy.js"></script>
	
	<script src="/js/highlight.pack.js"></script>
	
	<script src="/js/jquery.fancybox.min.js"></script>
	
	<script src="/js/search.js"></script>
	
	<script src="/js/load.js"></script>
	
	<script src="/js/jquery.mCustomScrollbar.concat.min.js"></script>
	
	<script src="/js/clipboard.min.js"></script>
	
	

	<script>hljs.initHighlightingOnLoad();</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
