


<!DOCTYPE html>
<html lang="ch">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<title> [ 代码和诗 ]</title>
	
	
	<!-- stylesheets list from _config.yml -->
	
	<link rel="stylesheet" href="/css/PreciousJoy.css">
	
	<link rel="stylesheet" href="/css/top-bar.css">
	
	<link rel="stylesheet" href="/css/menu-outer.css">
	
	<link rel="stylesheet" href="/css/content-outer.css">
	
	<link rel="stylesheet" href="/css/bottom-outer.css">
	
	<link rel="stylesheet" href="/css/atom-one-dark.css">
	
	<link rel="stylesheet" href="/css/recent-posts-item.css">
	
	<link rel="stylesheet" href="/css/article-sidebar-toc.css">
	
	<link rel="stylesheet" href="/css/jquery.fancybox.min.css">
	
	<link rel="stylesheet" href="/css/search.css">
	
	<link rel="stylesheet" href="/css/toc.css">
	
	<link rel="stylesheet" href="/css/sidebar.css">
	
	<link rel="stylesheet" href="/css/archive.css">
	
	<link rel="stylesheet" href="/css/jquery.mCustomScrollbar.min.css">
	
	<link rel="stylesheet" href="/css/Z-last-cover-others.css">
	
	
	
<meta name="generator" content="Hexo 7.3.0"></head>




<body id="wrapper">

	<div id="">
		
		<div id="top-bar">
			
			<div id="avatar-box">
				<img 
				class="avatar"
				src="/images/my-avatar.jpg" //网站头像
				alt="avatar">
			</div>

			<div id="top-bar-text">
				<div id="top-bar-title">
					阳生。
				</div>
				<div id="top-bar-slogan">
					风毛丛劲节，只上尽头竿。
				</div>
			</div>

		</div>

		<div id="menu-outer">
			<div id="menu-inner">
				
				
				<div class="menu-item">
					<a href="/">Home</a>
				</div>
				
				<div class="menu-item">
					<a href="/about">About</a>
				</div>
				
				<div class="menu-item">
					<a href="/archives">Archives</a>
				</div>
				

				<div class="menu-item menu-item-search">
					
  <span class="local-search local-search-google local-search-plugin">
      <input type="search" placeholder="站内搜索" id="local-search-input" class="local-search-input-cls" style="">
      <div id="local-search-result" class="local-search-result-cls"></div>
  </span>
	
				</div>

			</div>
		</div>

		<div id="content-outer">
			<div id="content-inner">

				

<div id="recent-posts-box">

  
  <div id="recent-posts">
    <!-- <h1>Recent Posts</h1> -->
    
    
    <div class="recent-post-item">

      <a href="/2025/08/29/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%9F%BA%E7%A1%80/" class="item-title">动态规划基础</a>
      
      <time datetime="2025-08-29T11:24:22.000Z">
        2025-08-29
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 之前零零散散地接触过一些动态规划的问题，用这篇blog来稍微系统性的记录一下
动态规划的基本步骤
定义数组的基本含义（模板或是灵感）
找到数组元素间的关系（dp的递推式，模板或是灵感）
找到边界的初始值（基本含义定义好了这个通常不难）
递推填表得到需要的元素（结合初始值以及递推式，考虑应该如何进行递推填表，确保新填一个元素需要用到其它元素的时候，其它元素的值已经被填过了）

背包问题01背包（二维解法）问题描述：有n种物品，每种物品只有一个。每个物品有自己的重量和价值。有一个给定容量的背包，问这个背包最多能装的最大价值是多少。
step1定义数组元素的含义
1dp[i][j]//背包容量为j时，考虑1~i种物品，所能承载的最大价值

step2于是我们可以有如下递推式
1dp[i][j] = max(dp[i-1][j], dp[i-1][j-weight[i]] + val[i])

因为从前i-1种物品考虑到第i种物品，只有两种情况：

拿第i种物品，那么前i-1种物品还剩下的可用容量是j-weight[i]，根据数组元素的意义，有dp[i][j] &#x3D; max(dp[i- -->
        <!-- </div> -->

        
        <p><code>之前零零散散地接触过一些动态规划的问题，用这篇blog来稍微系统性的记录一下</code></p>
<h2 id="动态规划的基本步骤"><a href="#动态规划的基本步骤" class="headerlink" title="动态规划的基本步骤"></a>动态规划的基本步骤</h2><ol>
<li>定义数组的基本含义（模板或是灵感）</li>
<li>找到数组元素间的关系（dp的递推式，模板或是灵感）</li>
<li>找到边界的初始值（基本含义定义好了这个通常不难）</li>
<li>递推填表得到需要的元素（结合初始值以及递推式，考虑应该如何进行递推填表，确保新填一个元素需要用到其它元素的时候，其它元素的值已经被填过了）</li>
</ol>
<h2 id="背包问题"><a href="#背包问题" class="headerlink" title="背包问题"></a>背包问题</h2><h3 id="01背包（二维解法）"><a href="#01背包（二维解法）" class="headerlink" title="01背包（二维解法）"></a>01背包（二维解法）</h3><p>问题描述：有n种物品，每种物品只有一个。每个物品有自己的重量和价值。有一个给定容量的背包，问这个背包最多能装的最大价值是多少。</p>
<h4 id="step1"><a href="#step1" class="headerlink" title="step1"></a>step1</h4><p>定义数组元素的含义</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dp[i][j]<span class="comment">//背包容量为j时，考虑1~i种物品，所能承载的最大价值</span></span><br></pre></td></tr></table></figure>

<h4 id="step2"><a href="#step2" class="headerlink" title="step2"></a>step2</h4><p>于是我们可以有如下递推式</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dp[i][j] = max(dp[i<span class="number">-1</span>][j], dp[i<span class="number">-1</span>][j-weight[i]] + val[i])</span><br></pre></td></tr></table></figure>

<p>因为从前i-1种物品考虑到第i种物品，只有两种情况：</p>
<ol>
<li>拿第i种物品，那么前i-1种物品还剩下的可用容量是j-weight[i]，根据数组元素的意义，有dp[i][j] &#x3D; max(dp[i-1][j-weight[i]] + val[i])</li>
<li>不拿第i种物品，前i-1种物品剩下的可用容量是j，根据数组元素的意义，有dp[i][j] &#x3D; dp[i-1][j]</li>
</ol>
<p>所以取两种情况中较大的一者，就是dp[i][j]的结果。<strong>注意，第一种情况应该满足条件j&gt;&#x3D;weight[i]，这是显然成立的，于变成而言不满足这个条件数组会发生越界，于实际意义而言，你要装下物品i，意味着你的背包容量至少要大于等于w[i]</strong></p>
<h4 id="step3"><a href="#step3" class="headerlink" title="step3"></a>step3</h4><p>不难发现边界条件的初始值是</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dp[<span class="number">0</span>][any_j] == <span class="number">0</span> &amp;&amp; dp[any_i][j] == <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h4 id="step4"><a href="#step4" class="headerlink" title="step4"></a>step4</h4><p>根据递推关系式，我们发现在填元素dp[i][j]的时候，使用到的元素的1、2维索引一定分别小于i、j，于是按照最简单的从左往右，从上往下填表即可。</p>
<h4 id="例题与代码实现-01背包（二维解法）"><a href="#例题与代码实现-01背包（二维解法）" class="headerlink" title="例题与代码实现 01背包（二维解法）"></a>例题与代码实现 01背包（二维解法）</h4><p>洛谷：P1060 [NOIP 2006 普及组] 开心的金明</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ll long long</span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line">ll m,n;</span><br><span class="line">ll v[<span class="number">26</span>],w[<span class="number">26</span>];</span><br><span class="line">ll dp[<span class="number">26</span>][<span class="number">30001</span>];</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"> <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= m;i++)</span><br><span class="line"> &#123;</span><br><span class="line">  ll t;</span><br><span class="line">  <span class="built_in">cin</span>&gt;&gt;v[i]&gt;&gt;t;</span><br><span class="line">  w[i] = v[i];</span><br><span class="line">  v[i]*=t;</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= m;i++)</span><br><span class="line"> &#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">1</span>;j &lt;= n;j++)</span><br><span class="line">  &#123;</span><br><span class="line">   <span class="keyword">if</span>(j &gt;= w[i])dp[i][j] = max(dp[i<span class="number">-1</span>][j], dp[i<span class="number">-1</span>][j-w[i]]+v[i]);</span><br><span class="line">   <span class="keyword">else</span> dp[i][j] = dp[i<span class="number">-1</span>][j];</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="built_in">cout</span>&lt;&lt;dp[m][n];</span><br><span class="line"> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="01背包（一维解法）"><a href="#01背包（一维解法）" class="headerlink" title="01背包（一维解法）"></a>01背包（一维解法）</h3><p>根据上面的状态转移式，我们可以发现在填表的过程中，<strong>每新的一行，仅仅依赖于上一行的数据</strong>，所以我们可以考虑使用1维表格。</p>
<p>即数组dp[j]，在二维表格的意义基础上描述对应元素的意义是：当前你正在更新行的元素数据，例如更新到第i行后，那么dp[j]对应就是dp[i][j]。当然这只是粗略的描述。</p>
<p>实际上，假设你当前正在更新第i行，并考虑更新dp[j]，在其更新之前，其对应的应该是dp[i-1][j]，更新完成后才是dp[i][j]。<strong>理解这一点很关键</strong>，有如下两点原因。</p>
<ol>
<li>dp[i][j]更新只依赖于i-1行的数据，而根据这个更新过程，i-1行的数据是可以同时被保存于这个一维表格的，那么只使用这个一维表格是可能的；</li>
<li>由于dp[i][j]的更新，从列上来看，其依赖的有1）dp[i][j-1]，在dp[j]于第i行更新中没有完成时，其代表的就是第i-1行的元素，所以dp[i-1][j]可以在需要时从表格中获取；2）dp[i-1][j-w[i]]，这就要求在dp[j]于第i行更新时，任何小于j的列k（0&lt;&#x3D; k &lt; j）没有完成更新，即dp[k]还保存的i-1行的元素，<strong>所以我们要从后往前更新表格</strong></li>
</ol>
<p>在第2点的基础上，只要我们从后往前更新1维表格，就可以确保<strong>表格中每个数据更新的时候，其需要的数据都存在于表格中（关键点）</strong>，于是使用一维数组替换二维数组是可行的。</p>
<p><em>这也是一般的dp需要考虑填表的方式的原因，你知道了递推式，你需要考虑如何递推才能满足，在求解一个元素的时候其它需要的元素一定是已经求解过了。</em></p>
<h4 id="例题与代码实现-01背包（一维解法）"><a href="#例题与代码实现-01背包（一维解法）" class="headerlink" title="例题与代码实现 01背包（一维解法）"></a>例题与代码实现 01背包（一维解法）</h4><p>洛谷：P1060 [NOIP 2006 普及组] 开心的金明</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ll long long</span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line">ll m,n;</span><br><span class="line">ll v[<span class="number">26</span>],w[<span class="number">26</span>];</span><br><span class="line">ll dp[<span class="number">30001</span>];</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"> <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= m;i++)</span><br><span class="line"> &#123;</span><br><span class="line">  ll t;</span><br><span class="line">  <span class="built_in">cin</span>&gt;&gt;v[i]&gt;&gt;t;</span><br><span class="line">  w[i] = v[i];</span><br><span class="line">  v[i]*=t;</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= m;i++)</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> j = n;j &gt;= <span class="number">0</span>;j--)<span class="comment">//注意从后往前递推</span></span><br><span class="line">   <span class="keyword">if</span>(j &gt;= w[i])dp[j] = max(dp[j],dp[j-w[i]]+v[i]);</span><br><span class="line">   <span class="comment">//else dp[j] = dp[j]，对应的就是dp[j] = dp[j-1]，当然没有写的必要 </span></span><br><span class="line"> <span class="built_in">cout</span>&lt;&lt;dp[n];</span><br><span class="line"> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="完全背包"><a href="#完全背包" class="headerlink" title="完全背包"></a>完全背包</h3><p>01背包之所以叫01背包，是因为对于每种物品只有1个，或选或不选；而完全背包唯一区别于01背包的一点就是，每一种可以选择的物品都是无限的。</p>
<p>采用与01背包相同的dp数组定义，可以想到以下递推式</p>
<p>即考虑前i种物品时对于第i种物品，考虑选择其数量为0到正无穷的情况，对此进行枚举</p>
<p>$dp[i][j] &#x3D; max^∞_{k&#x3D;0}(dp[i - 1][j - k<em>w[i]]+ k</em>v[i])$</p>
<p>当然对于每一次枚举，我们有终止条件</p>
<p>$j&#x2F;k &gt; w[i]$</p>
<p>但是这样的算法复杂度是$n^3$，通常会TLE</p>
<p>可以考虑优化</p>
<p>$dp[i][j] &#x3D; max(dp[i-1][j],dp[i][j-w[i]]+v[i])$</p>
<p>这里涉及两个情况</p>
<ol>
<li>不拿第i种物品的时候$dp[i][j] &#x3D; dp[i-1][j]$显然成立</li>
<li>拿第i种物品的时候，拿1件物品i时的值，已经由$dp[i][j-2*w[i]]$更新过了，依次类推，拿任意件物品i（至于边界情况，拿尽可能多）对应的情况都被考虑在其中了。而$dp[i][j-w[i]]$的更新一定在$dp[i][j]$之前（直接考虑顺序递推），所以可行。</li>
</ol>
<p>上面的第二点，从朴素一点的角度，可以从你定义好数组的含义之后，填表更新的过程来理解，填$dp[i][j-w[i]]$的时候，根据状态转移方程的情况2，就需要考虑$dp[i][j-2*w[i]]$，而后者一定是比前者先填好的。</p>
<h4 id="例题与代码实现"><a href="#例题与代码实现" class="headerlink" title="例题与代码实现"></a>例题与代码实现</h4><p>第37次CCF CSP认证 Task2 机器人饲养指南</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ll long long</span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line">ll n,m;</span><br><span class="line">ll v[<span class="number">101</span>];</span><br><span class="line">ll w[<span class="number">101</span>];</span><br><span class="line">ll dp[<span class="number">101</span>][<span class="number">100001</span>];</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"> <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m;</span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= m;i++)</span><br><span class="line"> &#123;</span><br><span class="line">  <span class="built_in">cin</span>&gt;&gt;v[i];</span><br><span class="line">  w[i] = i;</span><br><span class="line"> &#125; </span><br><span class="line"> </span><br><span class="line"> <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= m;i++)</span><br><span class="line"> &#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">1</span>;j &lt;= n;j++)</span><br><span class="line">  &#123;</span><br><span class="line">   <span class="keyword">if</span>(j &gt;= w[i])dp[i][j] = max(dp[i<span class="number">-1</span>][j],dp[i][j-w[i]]+v[i]);<span class="comment">//记住转移方程，其它按部就班即可</span></span><br><span class="line">   <span class="keyword">else</span> dp[i][j] = dp[i<span class="number">-1</span>][j];</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line"> <span class="built_in">cout</span>&lt;&lt;dp[m][n];</span><br><span class="line"> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这道题就是一个完全背包的模板，理解题意还原到完全背包，苹果的数量就是容量，投喂的数量就是物品的重量，投喂数量对应的受益就是物品的价值。</p>

        


        <span>
          <a class="article-read" href="/2025/08/29/动态规划基础/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/08/25/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="item-title">联邦学习基础知识</a>
      
      <time datetime="2025-08-25T08:55:39.000Z">
        2025-08-25
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 我正在学习一个用来跑PFL算法的代码框架，读代码的同时用这篇blog记录一些有关联邦学习的基础知识；以及一些python、pytorch的知识
数据集划分的平衡与不平衡含义在联邦学习中，平衡和不平衡主要指数据量上的分布情况：
平衡数据（Balanced Data）：每个客户端拥有的数据量大致相同。例如，如果有10个客户端和1000个数据样本，那么每个客户端分配到的数据约为100条。
不平衡数据（Unbalanced Data）：不同客户端拥有的数据量差别很大。例如，10个客户端中，某些客户端可能分配到300条数据，而另一些可能只有10条。这种情况在实际场景中很常见，比如边缘设备中，每台设备的用户数量或活跃度可能不同，导致本地数据量差异。
影响平衡与不平衡的影响：
平衡的数据划分更容易训练，且模型收敛更快。
不平衡的数据划分会导致联邦学习中的“客户端漂移”问题，即全局模型更倾向于数据量大的客户端，而忽略数据量较小的客户端。
人为划分IID or Non-IID的数据集IID划分方法将整个数据集随机打乱后，均匀划分到每个客户端。
例如，MNIST 数据集有 60000 张图片，可以随机将它 -->
        <!-- </div> -->

        
        <p><code>我正在学习一个用来跑PFL算法的代码框架，读代码的同时用这篇blog记录一些有关联邦学习的基础知识；以及一些python、pytorch的知识</code></p>
<h2 id="数据集划分的平衡与不平衡"><a href="#数据集划分的平衡与不平衡" class="headerlink" title="数据集划分的平衡与不平衡"></a>数据集划分的平衡与不平衡</h2><h3 id="含义"><a href="#含义" class="headerlink" title="含义"></a>含义</h3><p>在联邦学习中，平衡和不平衡主要指数据量上的分布情况：</p>
<p>平衡数据（Balanced Data）：每个客户端拥有的数据量大致相同。例如，如果有10个客户端和1000个数据样本，那么每个客户端分配到的数据约为100条。</p>
<p>不平衡数据（Unbalanced Data）：不同客户端拥有的数据量差别很大。例如，10个客户端中，某些客户端可能分配到300条数据，而另一些可能只有10条。这种情况在实际场景中很常见，比如边缘设备中，每台设备的用户数量或活跃度可能不同，导致本地数据量差异。</p>
<h3 id="影响"><a href="#影响" class="headerlink" title="影响"></a>影响</h3><p>平衡与不平衡的影响：</p>
<p>平衡的数据划分更容易训练，且模型收敛更快。</p>
<p>不平衡的数据划分会导致联邦学习中的“客户端漂移”问题，即全局模型更倾向于数据量大的客户端，而忽略数据量较小的客户端。</p>
<h2 id="人为划分IID-or-Non-IID的数据集"><a href="#人为划分IID-or-Non-IID的数据集" class="headerlink" title="人为划分IID or Non-IID的数据集"></a>人为划分IID or Non-IID的数据集</h2><h3 id="IID划分方法"><a href="#IID划分方法" class="headerlink" title="IID划分方法"></a>IID划分方法</h3><p>将整个数据集随机打乱后，均匀划分到每个客户端。</p>
<p>例如，MNIST 数据集有 60000 张图片，可以随机将它们分成 10 份，每份 6000 张，分配给 10 个客户端。</p>
<h3 id="Non-IID划分方法"><a href="#Non-IID划分方法" class="headerlink" title="Non-IID划分方法"></a>Non-IID划分方法</h3><p>常见的方法：</p>
<ol>
<li>按类别划分：MNIST 有 10 个类别，可以让每个客户端只拥有 1-2 个类别的数据。例如，客户端 A 拥有类别 0 和 1 的数据，客户端 B 拥有类别 2 和 3 的数据。</li>
<li>狄利克雷分布（Dirichlet Distribution）：通过狄利克雷分布生成权重，控制每个客户端拥有的类别比例</li>
<li>数量不平衡：对每个客户端分配不同数量的数据，进一步增加数据分布的不均衡性。</li>
</ol>
<h3 id="狄利克雷划分法（Non-IID）"><a href="#狄利克雷划分法（Non-IID）" class="headerlink" title="狄利克雷划分法（Non-IID）"></a>狄利克雷划分法（Non-IID）</h3><h4 id="关于狄利克雷分布"><a href="#关于狄利克雷分布" class="headerlink" title="关于狄利克雷分布"></a>关于狄利克雷分布</h4><p>狄利克雷分布是一种概率分布，用于生成一组非负数，使它们的和为 1。它常用于 Non-IID 数据划分中，控制每个客户端拥有数据类别的比例。</p>
<p>狄利克雷分布是一种“分布的分布” (a distribution on probability distribution) ，由两个参$\mathcal{G}_0,\alpha$ 确定，即$\mathcal{G} \sim DP(\alpha,\mathcal{G}_0)$，$\alpha$是分布参数(concentration or scaling parameter)，其值越大，分布越接近于均匀分布，其值越小，分布越concentrated。$\mathcal{G}_0$是基分布(base distribution)。</p>
<p>具体步骤：</p>
<ol>
<li>假设有 $K$ 个类别，客户端数为 $N$，狄利克雷分布的超参数为 $\alpha$。</li>
<li>对于每个客户端 $i$，从狄利克雷分布中采样一个向量 $p_i$，表示该客户端对 $K$ 个类别的偏好。</li>
<li>根据 $p_i$分配数据样本。例如，如果某个客户端 $i$ 的 $p_i &#x3D; [0.7, 0.2, 0.1]$，则它的样本中 70% 来自类别 1，20% 来自类别 2，10% 来自类别 3。</li>
<li>调整 $\alpha$ 值，可以控制 Non-IID 的程度：$\alpha$ 越小，每个客户端的类别分布差异越大（更偏向 Non-IID）。$\alpha$ 越大，类别分布差异越小（更接近 IID）。</li>
</ol>
<h3 id="其它一些划分方式（Non-IID）"><a href="#其它一些划分方式（Non-IID）" class="headerlink" title="其它一些划分方式（Non-IID）"></a>其它一些划分方式（Non-IID）</h3><ol>
<li>固定类别划分：每个客户端只分配特定的类别。例如，客户端 A 只分到类别 0，客户端 B 只分到类别 1。适用于模拟极端 Non-IID 分布。</li>
<li>聚类划分：对数据集进行聚类，将每个聚类的数据分配给一个客户端。这种方法可以模拟数据具有某种特定模式的情况。</li>
<li>概率抽样：给每个客户端分配不同的类别概率分布，然后根据概率分布抽样数据。比如，客户端 A 的类别分布是 [0.9, 0.1, 0.0]，客户端 B 的类别分布是 [0.3, 0.3, 0.4]。</li>
<li>基于地理或时间划分：按照数据生成的时间或地理位置来划分数据。例如，某些客户端的数据来自特定地区，模拟真实场景下的数据分布。</li>
</ol>
<h3 id="数据的异质性-Heterogeneity"><a href="#数据的异质性-Heterogeneity" class="headerlink" title="数据的异质性(Heterogeneity)"></a>数据的异质性(Heterogeneity)</h3><p>指的是Non-IID and unbalanced</p>
<h3 id="客户端漂移"><a href="#客户端漂移" class="headerlink" title="客户端漂移"></a>客户端漂移</h3><p>由于数据分布的差异，每个客户端的本地模型更新（梯度）可能会在方向和大小上有所不同。当这些更新被聚合时，可能会导致全局模型更新的方向和大小并不是所有客户端所需要的最佳方向。这种现象称为客户端漂移。</p>
<h3 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h3><p>CUDA（Compute Unified Device Architecture）是由 NVIDIA 开发的并行计算平台和编程模型。它允许开发者使用 NVIDIA 显卡（GPU）进行通用计算，即不仅仅用于图形处理，还可以用于科学计算、机器学习、深度学习等大量需要并行计算的任务。</p>
<p>通常cuda设备就是指GPU</p>
<h2 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h2><h3 id="Py的for循环"><a href="#Py的for循环" class="headerlink" title="Py的for循环"></a>Py的for循环</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _, train_data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, <span class="number">0</span>):</span><br><span class="line">    trainset.data, trainset.targets = train_data</span><br></pre></td></tr></table></figure>

<p>enumerate函数返回一个(索引，值)的元组，_是常用的占位符（我们知道这里有值，但是我们不使用），这里_存储的是索引值；train_data是由Dataloader将原始的数据集对象分批后得到的新的“数据集对象列表”trainloader中的元素，作为enumerate元组的值，其是一个数据集对象。</p>
<p>上面的赋值语句是将一个数据集对象train_data（本身是一个元组）中的两个元素，分别赋值给数据集对象trainset的两个属性元素。</p>
<h3 id="Py，range函数"><a href="#Py，range函数" class="headerlink" title="Py，range函数"></a>Py，range函数</h3><p>range(n)，生成一个迭代器，依次返回0，1，2，3，…，n-1</p>
<h3 id="Py，np-array函数"><a href="#Py，np-array函数" class="headerlink" title="Py，np.array函数"></a>Py，np.array函数</h3><p>numpy库中的array函数用于将输入的数据转换为一个NumPy数组，该数组是一种高效的多维数组对象，提供了许多用于数学和科学计算的功能。</p>
<h3 id="Py迭代器"><a href="#Py迭代器" class="headerlink" title="Py迭代器"></a>Py迭代器</h3><p>在Python中，迭代器是一种遵循迭代协议的对象，具有 iter() 和 next() 方法。迭代器允许程序员遍历一个集合，如列表或字符串，一次访问一个元素。生成器是一种特殊的迭代器，它使用 yield 关键字在每次迭代时返回值，而不是一次性返回所有值。</p>
<h4 id="一种迭代器的实现方式"><a href="#一种迭代器的实现方式" class="headerlink" title="一种迭代器的实现方式"></a>一种迭代器的实现方式</h4><p>把一个类作为一个迭代器使用需要在类中实现两个方法 __iter__() 与 __next__() 。</p>
<p>如果你已经了解的面向对象编程，就知道类都有一个构造函数，Python 的构造函数为__init__(), 它会在对象初始化的时候执行。</p>
<p>__iter__() 方法返回一个特殊的迭代器对象， 这个迭代器对象实现了 __next__() 方法并通过 StopIteration 异常标识迭代的完成。</p>
<p>__next__() 方法（Python 2 里是 next()）会返回下一个迭代器对象。</p>
<p><em>一个具体的例子：</em></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyNumbers</span>:</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="variable language_">self</span>.a = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span></span><br><span class="line"> </span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">    x = <span class="variable language_">self</span>.a</span><br><span class="line">    <span class="variable language_">self</span>.a += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"> </span><br><span class="line">myclass = MyNumbers()</span><br><span class="line">myiter = <span class="built_in">iter</span>(myclass)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(myiter))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(myiter))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(myiter))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(myiter))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(myiter))</span><br></pre></td></tr></table></figure>

<p><em>输出结果是：</em></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">5</span></span><br></pre></td></tr></table></figure>

<h3 id="Py使用布尔数组索引元素"><a href="#Py使用布尔数组索引元素" class="headerlink" title="Py使用布尔数组索引元素"></a>Py使用布尔数组索引元素</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">idxs = np.array(<span class="built_in">range</span>(<span class="built_in">len</span>(dataset_label)))</span><br><span class="line">idx_for_each_class = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">    idx_for_each_class.append(idxs[dataset_label == i])</span><br></pre></td></tr></table></figure>

<p>其中idxs是一个索引数组。</p>
<p>dataset_label &#x3D;&#x3D; i会生成一个布尔数组，对于dataset_label中的元素等于i的，该元素的位置对应布尔数组中True元素的位置，布尔数组中其它位置元素是False。例如，dataset_label &#x3D; [1, 2, 1, 2, 1]，i &#x3D; 1；那么对应布尔数组为[True, False, True, False, True]</p>
<p>idxs[dataset_label &#x3D;&#x3D; i]使用布尔数组进行索引，将布尔数组中为True的元素的位置对应到idxs中元素的位置。例如，idxs &#x3D; [1, 2, 3, 4, 5]，根据前面的布尔数组，返回[1, 3, 5]</p>
<h3 id="Py列表生成式"><a href="#Py列表生成式" class="headerlink" title="Py列表生成式"></a>Py列表生成式</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class_num_per_client = [class_per_client <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_clients)]</span><br></pre></td></tr></table></figure>

<p>其中[class_per_client for _ in range(num_clients)]是一个列表生成式；</p>
<p>用range迭代num_clients次，每次迭代的过程中添加一个元素为class_per_client；</p>
<p>最终得到一个长度为num_clients，每个元素都是class_per_client的列表；</p>
<p>实际意义是创建一个列表，其中每个元素代表每个客户端拥有的类别数量</p>
<h3 id="Py列表截取"><a href="#Py列表截取" class="headerlink" title="Py列表截取"></a>Py列表截取</h3><p>常见的列表截取操作如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a[start:stop] <span class="comment"># 从索引start开始到索引stop-1结束</span></span><br><span class="line">a[start:] <span class="comment"># 从索引start开始到列表末尾</span></span><br><span class="line">a[:stop] <span class="comment"># 从列表开头到索引stop-1结束</span></span><br><span class="line">a[:] <span class="comment"># 获取整个列表</span></span><br></pre></td></tr></table></figure>

<p>又如</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">selected_clients = selected_clients[:<span class="built_in">int</span>(np.ceil((num_clients/num_classes)*class_per_client))]</span><br></pre></td></tr></table></figure>

<p>np.ceil的作用告诉向上取整，再用int()转换为整数，又从0截取到stop-1</p>
<h3 id="Py，利用enumerate的for循环"><a href="#Py，利用enumerate的for循环" class="headerlink" title="Py，利用enumerate的for循环"></a>Py，利用enumerate的for循环</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> idx, train_dict <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_data):  <span class="comment"># 这种循环的作用是idx是train_data的索引，train_dict是train_data的元素（即存有训练数据的字典）</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(train_path + <span class="built_in">str</span>(idx) + <span class="string">&#x27;.npz&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        np.savez_compressed(f, data=train_dict)</span><br></pre></td></tr></table></figure>

<p>enumerate返回一个元组(index, element)的迭代器，常用于for index, element in enumerate(list)的循环中</p>
<h3 id="Py，argparse模块"><a href="#Py，argparse模块" class="headerlink" title="Py，argparse模块"></a>Py，argparse模块</h3><p>argparse 模块是 Python 标准库中的一个模块，它用于解析命令行参数。通过 argparse，我们可以方便地从命令行中获取参数并将其传递给程序。</p>
<h4 id="argparse的用法"><a href="#argparse的用法" class="headerlink" title="argparse的用法"></a>argparse的用法</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser()  <span class="comment"># 这是创建一个新的 ArgumentParser 对象，用于处理命令行参数。</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;-go&#x27;</span>, <span class="string">&quot;--goal&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;test&quot;</span>, </span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;The goal for this experiment&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>add_argument 方法用于定义程序可以接受的命令行参数，在上面的例子中：</p>
<ol>
<li>-go 和 –goal 是参数的名称（短名称和长名称）。</li>
<li>type&#x3D;str 指定参数的类型为字符串。</li>
<li>default&#x3D;”test” 指定参数的默认值。</li>
<li>help 提供该参数的帮助信息，会在使用 –help 时显示。</li>
</ol>
<p>类似的参数定义方法：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;-dev&#x27;</span>, <span class="string">&quot;--device&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;cuda&quot;</span>,</span><br><span class="line">                    choices=[<span class="string">&quot;cpu&quot;</span>, <span class="string">&quot;cuda&quot;</span>])</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-did&#x27;</span>, <span class="string">&quot;--device_id&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;0&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-data&#x27;</span>, <span class="string">&quot;--dataset&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;MNIST&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;-itk&#x27;</span>, <span class="string">&quot;--itk&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4000</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;The iterations for solving quadratic subproblems&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>最后解析参数，得到一个Namespace对象，用来访问各个参数</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure>

<p>parse_args 方法会解析命令行参数，并返回一个包含参数值的 Namespace 对象。可以通过 args 对象来访问这些参数，例如 args.goal、args.device 等。</p>
<p>综合来看，argparse的主要用法就是<strong>创建对象，定义参数，解析参数</strong></p>
<h3 id="Py张量"><a href="#Py张量" class="headerlink" title="Py张量"></a>Py张量</h3><p>一般是指用于数值计算的高效多维数组，可能是一个比较抽象的概念。</p>
<p>具体而言Py内置的list、Numpy库的Numpy数组或者Pytorch中的tensor，在某种程度上都可以被称为张量；但是在一些特定的情况下，张量或许特指后面两者</p>
<h3 id="Py，Dataloader"><a href="#Py，Dataloader" class="headerlink" title="Py，Dataloader"></a>Py，Dataloader</h3><p>在 PyTorch 中，DataLoader 是一个非常常用的类，用于包装数据集，提供批量加载数据的功能。</p>
<p>主要作用：</p>
<ol>
<li>批量加载数据: 根据指定的 batch_size 从数据集中加载数据。</li>
<li>打乱数据: 如果 shuffle&#x3D;True，在每个 epoch 开始时打乱数据。</li>
<li>多线程加载: 通过 num_workers 参数（未在此代码段中指定），可以并行加载数据，提高数据加载速度。</li>
<li>迭代接口: DataLoader 实现了 Python 迭代器协议，可以在训练循环中方便地使用 for batch in dataloader 这样的语法。</li>
</ol>
<p>例子：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="variable language_">self</span>.data = data</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.data[idx]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设 read_client_data 返回一个 SimpleDataset 对象</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_client_data</span>(<span class="params">dataset, client_id, is_train, few_shot</span>):</span><br><span class="line">    <span class="keyword">return</span> SimpleDataset([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyClass</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, batch_size=<span class="number">3</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.batch_size = batch_size</span><br><span class="line">        <span class="variable language_">self</span>.dataset = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.<span class="built_in">id</span> = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.few_shot = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_test_data</span>(<span class="params">self, batch_size=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> batch_size == <span class="literal">None</span>:</span><br><span class="line">            batch_size = <span class="variable language_">self</span>.batch_size</span><br><span class="line">        test_data = read_client_data(<span class="variable language_">self</span>.dataset, <span class="variable language_">self</span>.<span class="built_in">id</span>, is_train=<span class="literal">False</span>, few_shot=<span class="variable language_">self</span>.few_shot)</span><br><span class="line">        <span class="keyword">return</span> DataLoader(test_data, batch_size, drop_last=<span class="literal">False</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 MyClass 加载数据</span></span><br><span class="line">my_class = MyClass()</span><br><span class="line">dataloader = my_class.load_test_data()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> dataloader:</span><br><span class="line">    <span class="built_in">print</span>(batch)</span><br></pre></td></tr></table></figure>

<p>例子将会输出</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">tensor([<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line">tensor([<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
        


        <span>
          <a class="article-read" href="/2025/08/25/联邦学习基础知识/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/08/17/PFL-SRDP/" class="item-title">PFL-SRDP</a>
      
      <time datetime="2025-08-17T09:38:41.000Z">
        2025-08-17
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 最近准备申请一个大创的项目，研究围绕PFL展开，这篇blog用于记录其中的一些思路
PFL相关的基本问题(阶段0)PFL的基本类型(1) 学习单一全局模型并进行微调的方法这些方法首先学习一个全局共享模型，然后在每个客户端上进行本地微调。
例子：FedAvg + 本地微调首先，使用联邦平均（Federated Averaging，FedAvg）算法进行全局模型的训练。FedAvg通过在每个客户端本地训练模型，然后将本地模型参数上传到服务器进行平均化，形成全局模型。
步骤：

每个客户端在本地数据上训练模型若干轮。
将本地模型参数上传到服务器。
服务器对所有客户端上传的模型参数进行平均化，得到新的全局模型。
将新的全局模型分发给每个客户端。
每个客户端在全局模型基础上进行本地微调，使用本地数据继续训练若干轮。

第一类要运用Nash-bargaining game来进行聚合的话，基本上与FL的差异不大，因为都是考虑对客户端训练出的参数在服务器上进行聚合。
(2) 学习额外个性化模型的方法这些方法在全局模型的基础上，为每个客户端学习一个额外的个性化模型。
例子：FedPerFedPer（Fe -->
        <!-- </div> -->

        
        <p><code>最近准备申请一个大创的项目，研究围绕PFL展开，这篇blog用于记录其中的一些思路</code></p>
<h2 id="PFL相关的基本问题-阶段0"><a href="#PFL相关的基本问题-阶段0" class="headerlink" title="PFL相关的基本问题(阶段0)"></a>PFL相关的基本问题(阶段0)</h2><h3 id="PFL的基本类型"><a href="#PFL的基本类型" class="headerlink" title="PFL的基本类型"></a>PFL的基本类型</h3><p>(1) 学习单一全局模型并进行微调的方法<br>这些方法首先学习一个全局共享模型，然后在每个客户端上进行本地微调。</p>
<h4 id="例子：FedAvg-本地微调"><a href="#例子：FedAvg-本地微调" class="headerlink" title="例子：FedAvg + 本地微调"></a>例子：FedAvg + 本地微调</h4><p>首先，使用联邦平均（Federated Averaging，FedAvg）算法进行全局模型的训练。FedAvg通过在每个客户端本地训练模型，然后将本地模型参数上传到服务器进行平均化，形成全局模型。</p>
<p>步骤：</p>
<ol>
<li>每个客户端在本地数据上训练模型若干轮。</li>
<li>将本地模型参数上传到服务器。</li>
<li>服务器对所有客户端上传的模型参数进行平均化，得到新的全局模型。</li>
<li>将新的全局模型分发给每个客户端。</li>
<li>每个客户端在全局模型基础上进行本地微调，使用本地数据继续训练若干轮。</li>
</ol>
<p><code>第一类要运用Nash-bargaining game来进行聚合的话，基本上与FL的差异不大，因为都是考虑对客户端训练出的参数在服务器上进行聚合。</code></p>
<p>(2) 学习额外个性化模型的方法<br>这些方法在全局模型的基础上，为每个客户端学习一个额外的个性化模型。</p>
<h4 id="例子：FedPer"><a href="#例子：FedPer" class="headerlink" title="例子：FedPer"></a>例子：FedPer</h4><p>FedPer（Federated Personalization）方法提出在全局模型的基础上，为每个客户端学习一个个性化的模型头（或最后一层）。</p>
<p>步骤：</p>
<ol>
<li>使用FedAvg算法训练一个共享的全局模型，但仅共享前几层的参数。</li>
<li>每个客户端保持自己的个性化模型头，该模型头仅在本地数据上训练。</li>
<li>在每轮通信中，仅共享和更新全局模型的共享层参数，不包括个性化头部参数。</li>
</ol>
<p>(3) 通过个性化（本地）聚合学习本地模型的方法<br>这些方法通过个性化聚合来进一步捕捉个性化需求，为每个客户端生成特定的模型。</p>
<h4 id="例子：FedProx"><a href="#例子：FedProx" class="headerlink" title="例子：FedProx"></a>例子：FedProx</h4><p>FedProx（Federated Proximal）方法通过在本地训练过程中添加一个正则项，来限制本地模型偏离全局模型过多，从而实现个性化。</p>
<p>步骤：</p>
<ol>
<li>每个客户端在本地数据上训练模型时，在损失函数中添加一个正则项，限制模型参数与全局模型参数的差异。</li>
<li>正则项形式为：loss + μ&#x2F;2 * ||w - w_global||^2，其中w是本地模型参数，w_global是全局模型参数，μ是正则化系数。</li>
<li>通过这种方法，使得模型在本地数据上训练时，仍然保持一定的全局模型特性。</li>
</ol>
<h2 id="设想的算法"><a href="#设想的算法" class="headerlink" title="设想的算法"></a>设想的算法</h2><p><img src="/../_images/MyAlgorithm.jpg" alt="MyAlgorithm"></p>
<h2 id="研究目的"><a href="#研究目的" class="headerlink" title="研究目的"></a>研究目的</h2><ol>
<li>有关联邦学习的内容</li>
<li>为什么需要个性化联邦学习（非独立同分布…）</li>
<li>个性化联邦学习的常见方法（各种方法对应的参考文献）</li>
<li>关于NashBargainingGame的一些基本情况，其与相关学习算法的结合</li>
<li>最终我们的研究目的</li>
</ol>
<h2 id="研究内容"><a href="#研究内容" class="headerlink" title="研究内容"></a>研究内容</h2><ol>
<li>实现基本的FL算法框架（FedAvg）</li>
<li>考虑第三类PFL，引入Nash-bargaining Game设置个性化聚合方法</li>
<li>考虑引入权重α，进一步改进算法</li>
<li>PFL实验评估（通过权威论文，明确PFL算法量化评价指标）</li>
</ol>
<h2 id="一些参考文献"><a href="#一些参考文献" class="headerlink" title="一些参考文献"></a>一些参考文献</h2><p>Advances and Open Problems in Federated Learning 联邦学习领域的权威综述，其中把个性化联邦学习作为联邦学习下一个分支，有所提及。</p>
<h2 id="琐碎的思路-阶段1"><a href="#琐碎的思路-阶段1" class="headerlink" title="琐碎的思路(阶段1)"></a>琐碎的思路(阶段1)</h2><p>如果我们不重点考虑隐私问题，或许可以采用数据中心分布式学习的背景框架。这种背景下，我们是要在一个大而扁平的数据集上训练模型，每个客户端是单个集群或数据中心中的计算结点。数据分配的特点是任何客户端都可以读取数据集任意部分。</p>
<p>可能的学习路线：</p>
<ol>
<li>机器学习入门（基本的线性模型训练过程、梯度下降法）</li>
<li>神经网络（基本的训练模式，前向传递、后向传递）</li>
<li>多任务学习+Nash Bargaining Game（大概读懂论文）</li>
<li>FL+Nash Bargaining Game（理解这种迁移）</li>
<li>理解我们目前大概的思路</li>
</ol>
<h3 id="论文撰写相关"><a href="#论文撰写相关" class="headerlink" title="论文撰写相关"></a>论文撰写相关</h3><h4 id="个性化联邦学习常用的优化目标"><a href="#个性化联邦学习常用的优化目标" class="headerlink" title="个性化联邦学习常用的优化目标"></a>个性化联邦学习常用的优化目标</h4><p>在个性化联邦学习（PFL）中，正则化项的设计非常关键，它能帮助平衡全局模型和各个客户端的个性化模型之间的关系。常见的正则化项主要有以下几种形式：</p>
<p>参数距离正则化： 这种方法通过限制个性化模型参数和全局模型参数之间的距离，来保证个性化模型不会偏离全局模型太远。常见的形式有：<br>L2 正则化（欧氏距离）：<br>$\mathcal{R}(w_k, w_g) &#x3D; |w_k - w_g|^2_2$</p>
<p>L1 正则化：<br>$\mathcal{R}(w_k, w_g) &#x3D; |w_k - w_g|_1$</p>
<p>混合模型正则化： 这种方法通过将全局模型和本地模型进行线性组合，并对这种组合进行约束：$w_k &#x3D; \lambda w_g + (1 - \lambda)\tilde{w}_k$其中，$\lambda$ 是权重系数，$\tilde{w}_k$是客户端 $k$ 自己训练的模型参数。这种方法可以通过控制 $\lambda$ 的大小来调节全局模型和本地模型的影响。</p>
<p>多任务学习正则化： 这种方法将个性化建模视为多任务学习问题，通过对不同任务（客户端）的模型参数进行正则化：$\mathcal{R}(w_k, w_g) &#x3D; |v_k|^2_2$其中，$w_k &#x3D; w_g + v_k$，$v_k$是客户端 $k$ 的个性化参数。</p>
<p>元学习正则化： 元学习方法通过对元模型参数进行调整，以便在少量本地数据上快速适应：$\mathcal{R}(\theta, \mathcal{D}_k) &#x3D; \mathcal{L}<em>k(\theta - \alpha \nabla</em>{\theta} \mathcal{L}_k(\theta; \mathcal{D}_k); \mathcal{D}_k)$其中，$\theta$ 是元模型参数，$\alpha$ 是学习率。</p>
<p>KL 散度正则化： 这种方法通过衡量个性化模型和全局模型的概率分布之间的差异，来进行正则化：$\mathcal{R}(w_k, w_g) &#x3D; D_{KL}(P(w_k) | P(w_g))$其中，$D_{KL}$是 Kullback-Leibler 散度，$P(w_k)$和 $P(w_g)$ 分别是个性化模型和全局模型的概率分布。</p>
<h3 id="实验实现相关"><a href="#实验实现相关" class="headerlink" title="实验实现相关"></a>实验实现相关</h3><p>在Server端使用经典的FedAvg算法进行权重的聚合</p>
<p>在Client端对Server发送过来的权重，结合自己的本地权重，进行正则化</p>
<p>算法的基本流程：</p>
<ol>
<li>（初始化部分）服务器初始化参数，并发送给客户端，作为本地参数</li>
<li>服务器向客户端发送全局参数</li>
<li>客户端使用数据集的一个子集，训练更新本地参数；并使用本地参数与全局参数进行后正则化处理（NBG），得到个性化参数，更新本地参数</li>
<li>客户端向服务器发送个性化参数，服务器对所有的个性化参数使用FedAvg进行聚合，得到新的全局参数</li>
<li>重复2~4</li>
</ol>
<p><strong>算法的基本流程（改）</strong>：</p>
<ol>
<li>（初始化部分）服务器初始化参数，并发送给客户端，作为本地参数</li>
<li>服务器向客户端发送全局参数</li>
<li>客户端使用数据集的一个子集，训练<strong>更新本地参数、全局参数</strong>（梯度下降步，此处的全局参数由本地维护，与客户端的全局参数无关）；并使用本地参数的更新梯度与全局参数的更新梯度进行Nash Bargaining Game，全局模型效用函数为$u_g &#x3D; \nabla\omega_g^T\Delta\omega$，本地模型效用函数为$u_l &#x3D; \nabla\omega_l^T\Delta\omega$，其中Nash Bargaining Game的通解是$\Delta\omega &#x3D; \alpha1\nabla\omega_l+\alpha2\nabla\omega_g $，其中$G^TG\alpha &#x3D; 1$对应$\alpha$权重矩阵</li>
<li>求解Nash Bargaining Game，得到$\alpha$，用于聚合本地参数与全局参数，更新本地参数，使其包含更多的个性化信息$\omega_l &#x3D; \alpha1\omega_l + \alpha2\omega_g$（类似混合模型的方法）</li>
<li>客户端向服务器发送本地参数$\omega_l$，服务器对所有的个性化参数进行加权聚合（以样本量为权重），得到新的全局参数$\omega_g$</li>
<li>重复2~5</li>
</ol>
<p>改代码的思路：</p>
<ol>
<li>实现一个基本的FedAvg算法</li>
<li>实现基本的正则化（混合模型，后正则化）</li>
<li>更改混合模型正则化为Nash Bargaining Game</li>
</ol>
<p>关于实现基本的正则化的思路：</p>
<p>关键是要为client多引入一份模型参数，作为个性化参数</p>
<ol>
<li>本地参数在初始化的时候和个性化参数一起，用全局参数初始化；后续每次send_model的时候，本地参数不再更新，只更新个性化参数；每次都使用本地参数照常训练，并且在3、的个性化参数更新之后，用个性化参数替代本地参数</li>
<li>多引入一个个性化参数成员变量，在初始化本地参数的时候，一并将个性化参数做相同设置（都设置为全局参数）：1、加入成员变量（注意初始化）；2、修改set_parameters函数（只设置个性化参数，不再设置本地参数）</li>
<li>当本地参数训练完成之后（之前的直接复用原代码即可），用个性化参数与本地参数进行正则化处理，得到新的个性化参数（同样也更新本地参数）：1、添加正则化函数（后续在此之上引入NBG）2、更新本地参数</li>
<li>将个性化参数发送回服务器：1、修改send_model函数，使其返回的是新的个性化参数的成员变量（不用再修改了，因为我们正则化得到个性化参数后也会将其设置为本地参数，send_model会返回本地参数）</li>
</ol>
<p>引入Nash Bargaining Game的思路：</p>
<p>Q：Nash Bargaining Game的源代码实现是多个任务的loss进行聚合后，用weighted_loss，反向传播求梯度，然后进行梯度下降；对应的就等价于论文中的，各个任务的loss先反向传播，得到weighted_loss，再进行聚合；而FL中的Nash Bargaining Game一般是将各个客户端期望的更新参数用于聚合，对应到我的PFLNash中，应该是将local model在local dataset上期望的更新参数&amp;global model在dataset上期望的更新参数进行聚合；期望的更新参数实际上就是loss反向传播求得的梯度乘上学习率，所以期望更新参数的聚合，可以等价于loss求得梯度的聚合（也就是源代码先聚合loss再求梯度），也适用于Nash Bargaining Game的源代码（学习率在梯度下降,即.step()操作的时候引入）</p>
<ol>
<li>使用personalized model进行前向传播，并求交叉熵损失得到loss2（loss1已经有了）</li>
<li>使用loss1与loss2进行聚合得到综合loss，并使用综合loss反向传播求梯度</li>
<li>使用梯度进行梯度下降，得到新的model</li>
</ol>
<p>如何确保聚合后的loss，求梯度下降的时候对于两个模型中结构位对应相同的参数一视同仁。有必要做到一视同仁吗？</p>
<p>在MTL中，各个任务的损失函数不同，对应即T1,T2,T3对应同一套参数omega的loss1、loss2、loss3不同，但是均可对omega求梯度，得到的梯度使用Nash Bargaining Game进行聚合，用来更新omega</p>
<p>而在PFL中，只有一个任务&#x2F;损失函数相同，但是有两套参数omega1、omega2，这两套参数可以视作同一个model的两套参数；loss相同（从函数结构上来说），loss对omega1、omega2求梯度，得到的值不同分为loss1、loss2，梯度不同，对应参数的更新方向不同</p>
<p>MTL中如果直接聚合loss1、loss2、loss3得到loss，然后反向传播，loss是对omega求梯度nabla，再梯度下降，oemga会使用nalba更新自己；而如果PFL中直接聚合loss1、loss2，然后反向传播，其会将omega1、omega2当作两个不同的参数，分别求梯度nabla1、nabla2，然后反向传播，omega1会用nabla1更新自己，omega2会用nabla2更新自己，得到omega1’，omega2’</p>
<p>或许我应该再令omega2 &#x3D; omega2 + (omega2’-omega2)+(omega1’-omega1)，这样来完成更新。</p>
<p>实际上我使用的personalized_model来临时存储global_model，所以应该是omega2 &#x3D; omega1 + (omega1’ - omega1) + (omega2’ - omega2)</p>
<p>因为PFL中loss1、loss2聚合的时候Nash Bargaining Game为它们确定的系数会在实质上影响到nabla1、nabla2的值，而最基础的聚合也可以直接看作对nabla1、nabla2求一个加权和</p>
<p>对比最初我的设想是这样的：<code>实际上我这里并没有共享参数，我的loss1是由model1得到的、loss2是由model2得到的，model1与model2是结构完全相同的模型（尽管具体对应参数的数值可能不相同，但在初始化的时候model2是由model1deep copy得到的）；然后此时我想使用这个NashMTL对loss1、loss2进行聚合，完成之后只需要更新model2。</code>但这应该是错误的，聚合后的loss不可能只更新model2，这意为着将model1、model2中结构位相同的参数当作同一个参数进行处理，但这实际上是不行的。假设这是可以的，我们在对结构位相同的参数1求梯度的时候可能需要用到参数2，在相同的结构位上，model1、model2的参数2值可能是不同的，这个时候就无法确定应该用model1还是model2的参数2的值了。所以这是不行的。</p>
<h4 id="最终的实现思路"><a href="#最终的实现思路" class="headerlink" title="最终的实现思路"></a>最终的实现思路</h4><p>一个client保存了4个model，分别是个性化模型、本地模型，以及两个模型的备份（主要是用来备份参数）</p>
<p>为了使用MTL，我将本地模型的参数omega1、个性化模型的参数omega2，拼接成了一个大的共享参数网络(omega1,omega2)，然后传入个性化模型、本地模型分别求得的loss1、loss2，传入作为losses，(omega1,omega2)作为shared_parameters，进行nash_mtl.backward()。内部的运行逻辑是，将loss1、loss2通过Nash Bargaining Game聚合后得到一个loss，用loss分别对(omega1,omega2)中的各个参数求偏导得到梯度，更新(omega1,omega2)（这样，对应相同结构位的参数并不会视作同一个参数，而是当作不同参数处理）。</p>
<p>而在此之前，我将omega1、omega2分别用两个备份模型进行了保存，当omega1、omega2更新完成后，再依次对个性化模型的各个参数进行操作，更新为：omega2 &#x3D; omega2 + (omega2’-omega2)+(omega1’-omega1)。最后将个性化模型深拷贝给本地模型，完成更新</p>
<h2 id="琐碎的思路-阶段2"><a href="#琐碎的思路-阶段2" class="headerlink" title="琐碎的思路(阶段2)"></a>琐碎的思路(阶段2)</h2><p>当前我已经完成的任务：</p>
<ol>
<li>问题的建模（method部分的论文初稿）</li>
<li>编写算法的代码，在MINST数据集上完成了测试，并参照了一些评价指标</li>
</ol>
<p>接下来我需要做的事情是对PFLNash的优点进行论述，老师给了我以下建议：</p>
<h3 id="考虑PFL中的典型评价方式"><a href="#考虑PFL中的典型评价方式" class="headerlink" title="考虑PFL中的典型评价方式"></a>考虑PFL中的典型评价方式</h3><p>通信（次数、复杂性）、收敛性、最优性、精度下限…，具体的需要我进一步查阅资料</p>
<p>通信次数的比较可以通过横向比较，相同通信次数下的收敛率（Loss趋于一个较低的稳定值的情况）</p>
<p>通信复杂性是和通信次数相关的，通常通信复杂性取决于：</p>
<ol>
<li>模型大小（每次通信发送模型参数的数量）</li>
<li>通信的次数</li>
<li>参与客户端个数</li>
</ol>
<p>复杂性可以定义为 R×N×b（通信次数、参与客户端个数、模型参数个数）</p>
<p>优化的方法：</p>
<ol>
<li>通信协议（采用一些压缩技术对模型参数进行压缩，不太了解…）</li>
<li>增加本地模型训练轮数</li>
<li>让客户端部分参与</li>
</ol>
<p>关于收敛性分析或许可以参考一下这个视频<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Ks1PYGEu5/?spm_id_from=333.1387.upload.video_card.click&vd_source=80df09f481ef5f0671e5e0e35d02e33e">联邦学习收敛性分析</a></p>
<h3 id="参考当前方法中不好的点"><a href="#参考当前方法中不好的点" class="headerlink" title="参考当前方法中不好的点"></a>参考当前方法中不好的点</h3><p>考虑我参考方法中的缺点，描述自己是如何在前人基础上进行改进的</p>
<p>具体的方向应该是去找一些有关通过正则化方法实现PFL的算法中存在的缺陷</p>
<h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><p>最后老师提到了自己的研究生曾经做过的一个工作，通过知识蒸馏提取个性化特征，与全局模型进行融合，得到个性化模型。并且告诉我可以思考自己的方法较这个方法的优点是什么，类似于在第二个方向中给了我一个更加具体的方向。值得留意。</p>
<h3 id="当前阶段阅读的一些参考文献"><a href="#当前阶段阅读的一些参考文献" class="headerlink" title="当前阶段阅读的一些参考文献"></a>当前阶段阅读的一些参考文献</h3><h4 id="FedAvgM"><a href="#FedAvgM" class="headerlink" title="FedAvgM"></a>FedAvgM</h4><p>这篇文章主要做了两个工作</p>
<ol>
<li>在服务器端引入了动量来更新权重, 提升了FedAVG算法对非独立同分布数据的训练效果</li>
<li>基于狄利克雷分布，提出了一种Non-IID数据生成的方法，用来对FedAVGM以及FedAVG进行测试</li>
</ol>
<p>主要的优点在于accuracy的提高</p>
<p>给我的一个启发是它的实现，实验测试了通信次数-准确率的表现，并且以centralized learning作为了一个衡量标准（我是否可以把centralized learning最终的结果作为一个optimal accuracy的表现？）</p>
<h4 id="Per-FedAvg"><a href="#Per-FedAvg" class="headerlink" title="Per-FedAvg"></a>Per-FedAvg</h4><p>这篇文章的主要工作是把FedAvg算法与meta-learning的框架结合起来，实现了个性化的效果，比较注重理论，严格地证明了算法的收敛性。</p>
<p>实验方法，主要是对比了accuracy，对比的算法是FedAvg+本地微调与PerFedAvg算法</p>
<h3 id="我的思路"><a href="#我的思路" class="headerlink" title="我的思路"></a>我的思路</h3><p>目前翻阅了多篇较为经典的论文，里面的实验大多数都是聚焦于accuracy这一指标。我大概的想法也是将PFLNash的accuracy与一些basline（混合模型正则化、Fedprox…）做对比。此外，还可以从loss-通信轮次的角度来对比，loss收敛时的通信轮次，来说明通信方法的优点。最后，我可能需要仔细学习一下收敛性证明方法的理论，来对PFLNash是否可以从数学层面进行严格的收敛性证明进行一个评估。</p>
<p>具体来说，于是接下来我有两个主要工作：</p>
<ol>
<li>学习FedAvg算法的收敛性证明，考虑是否可以应用到PFLNash中</li>
<li>实验角度，主要是两个实验，一个是accuracy的，一个是loss的，对比混合模型正则化、Fedprox…</li>
</ol>
<p>最后选定了基线模型之后，还可以考虑一些其它的优点，比如避免了引入一些需要人为设置且变动影响不是很清晰的超参数…</p>
<h4 id="关于收敛性证明"><a href="#关于收敛性证明" class="headerlink" title="关于收敛性证明"></a>关于收敛性证明</h4><p>在三大假设的基础之上，集中数据集中的GD收敛性是可以得到保证的；经典的FedAvg算法实际上是一种分布式数据集上的SGD。于是FedAvg与GD的差异主要来源于两个方面</p>
<ol>
<li>分布式训练参数带来的误差</li>
<li>分布式参数聚合时的误差</li>
</ol>
<p>我们的证明思路可以是先考虑1、中产生的误差存在一个bound，再证明2、中产生的误差也存在一个bound，并且这两个bound都是可以收敛到0的，那么最终FedAvg的训练效果会收敛到集中化数据集下GD的训练效果，于是收敛性可以得到保证。</p>
<p>现在我参考的资料FedAvg的收敛性已经证明完毕，我要考虑PFLNash的收敛性证明，其中多的一项误差可能是NBG带来的。</p>
<h4 id="关于实验"><a href="#关于实验" class="headerlink" title="关于实验"></a>关于实验</h4><p>首先我要选择一些合适的算法作为我的基线模型；从三种PFL的实现思路，分别找三种经典的算法</p>
<ol>
<li>FL+本地微调（FedAvg）</li>
<li>仅使用全局参数，更新本地模型的部分层参数，本地模型有自己的任务头，仅通过本地数据进行训练（FedPer）</li>
<li>使用全局模型与本地模型进行个性化聚合（例如在本地模型训练的过程中在目标函数中加入正则化项）（FedProx）</li>
</ol>
<p>实验部分设想（三类实验）</p>
<ol>
<li>第一类实验使用PFLNash与一些经典的算法，在平均准确率与损失函数收敛上进行横向对比，分析相关的性能表现、实验收敛性以及通信复杂性；</li>
<li>第二类实验，通过调整一些超参数，对比相应情况下PFLNash的各项表现，进行相应的敏感性分析；</li>
<li>第三类实验，类比实际的场景，测试了不同客户端数量下PFLNash的表现，同时考虑了客户端可能掉线的情况。</li>
</ol>
<p>可选用数据集：<br>AGNews、AmazonReview、Camelyon、Cifar10、Cifar100、Country211、COVIDx、Digit5、DomainNet、EMNIST、FashionMNIST、FEMNIST、Flower102、GTSBR、HAR、iWildCam、kvasir、MNIST、Omniglot、PAMAP2、Shakespeare、SogouNews、StanfordCars、TinyImagenet</p>
<p>可选用模型：<br>MLR、CNN、DNN、ResNet18、ResNet10、ResNet34、AlexNet、GooleNet、MobileNet、LSTM、BiLSTM、fastText、TextCNN、Transformer、AmazonMLP、HARCNN</p>
<p>第一类实验使用数据集</p>
<p><strong>图像识别相关数据集</strong>：</p>
<ol>
<li>MNIST</li>
<li>EMNIST</li>
<li>Cifar10</li>
<li>Cifar100</li>
</ol>
<p><strong>文本分类相关数据集</strong>：</p>
<p>AGNews（新闻文本分类数据集）<br>数据类型：新闻文章标题与描述<br>标签：文章类别标签，四类，World、Sports、Business、Sci&#x2F;Tech<br>模型：TextCNN、fastText</p>
<p><strong>医疗和生物数据</strong>：</p>
<p>COVIDx（新冠肺炎检测图像数据集）<br>数据类型：胸部X光片（CXR）图像<br>标签：COVID-19阳性、COVID-19阴性、正常<br>模型：CNN、ResNet34</p>
<p><strong>传感器数据</strong>：</p>
<p>HAR（只能收集传感器数据的人体活动识别数据集）<br>数据类型：只能收集内置加速度计和陀螺仪采集的数据<br>标签：标注为不同的物理活动，包括：走路、上楼、下楼、坐着、站着、躺着<br>模型：LSTM、HARCNN</p>
<p>考虑选用数据集：<br>AGNews、AmazonReview、Camelyon、Cifar10、Cifar100、Country211、COVIDx、Digit5、DomainNet、EMNIST、FashionMNIST、FEMNIST、Flower102、GTSBR、HAR、iWildCam、kvasir、MNIST、Omniglot、PAMAP2、Shakespeare、SogouNews、StanfordCars、TinyImagenet</p>
<p>注：<strong>可以考虑异质性数据（狄利克雷+非平衡划分）和非异质性数据（平衡划分）</strong></p>
<p>具体任务划分</p>
<ol>
<li>租聘云服务器，完成实验环境搭建</li>
<li>学习使用py处理h5文件，完成训练结果的可视化展示</li>
<li>训练比较效果</li>
<li>完成实验部分论文内容</li>
</ol>
<p>下面记录一下经典论文中的实验信息</p>
<p>FedAvg+本地微调（FedAvgM）：</p>
<p>客户端数量：40<br>通信次数：10000<br>本地训练次数：1~5<br>模型：CNN<br>数据集：CIFAR-10<br>观测指标：acc-round、best_acc-local_epoch</p>
<p>个性化任务头</p>
<p>FedPer</p>
<p>客户端数量：10、10、30<br>通信次数：50、50、20<br>本地训练次数：1<br>模型：ResNet-34、MobileNet-v1<br>数据集：CIFAR-10、CIFAR-100、FLICKR-AES（均有iid划分、non-iid划分）<br>观测指标：acc-rounds（还通过调整网络结构、调整一些参数例如class_num做了对比）</p>
<p>个性化聚合</p>
<p>FedProx：</p>
<p>客户端数量：1000、1000、200、143、772（对应数据集）<br>通信次数：200、100、200、40、800<br>本地训练次数：1<br>模型：LSTM（不同实验外加了许多自己的调整）<br>数据集：Symnthetic、MNIST、FEMNIST、Shakespeare、Sent140<br>观测指标：loss-rounds、acc-rounds</p>
<p>根据我使用的数据集记录实验条件</p>
<p><strong>已经测试过的算法</strong>：</p>
<p>老师要求，再明确一下个性化联邦学习的评价标准是怎样的</p>
<p><strong>FedNash：</strong>mean for best accuracy: 0.995887594242632</p>
<ol>
<li>FedAvg：mean for best accuracy: 0.99011348192059012</li>
<li>FedProx：mean for best accuracy: 0.9911355198267598</li>
<li>FedPer：mean for best accuracy: 0.99323784539187598</li>
<li>FedAS：mean for best accuracy: 0.992348979183749142</li>
<li>FedALA：mean for best accuracy: 0.9945739090701393(*)</li>
<li>Ditto：mean for best accuracy: 0.9917751884852639(*)</li>
<li>FedPAC：mean for best accuracy: 0.9921178889650446(*)</li>
<li>MOON：mean for best accuracy: 0.9611606122915238</li>
<li>FedPep：mean for best accuracy: 0.9936600411240576</li>
<li>FedFomo：mean for best accuracy: 0.9911469042723327</li>
</ol>
<p><strong>Cifar100</strong>：<br>local epoch 1；global epoch：100；<br>client nums：20；joining rotio：100%；<br>class nums：10；Model：CNN（2conv、2fc）；<br>partition：non-iid（dir）；non-blance；<br>learning-rate：0.005 (ldg 0.99)<br>model：CNN</p>
<p><strong>已经测试过的算法</strong>：</p>
<p><strong>PFLNash：</strong>mean for best accuracy: 0.5981476545842217</p>
<ol>
<li>FedAvg: mean for best accuracy: 0.30810234541577824</li>
<li>FedProx：mean for best accuracy: 0.30810234541577824</li>
<li>FedPer：mean for best accuracy: 0.4931369936034115</li>
<li>FedAS：mean for Best accuracy. 0.4542910447761194</li>
<li>FedALA：mean for best accuracy: 0.5360474413646056（*）</li>
<li>Ditto：mean for best accuracy: 0.4754131130063966</li>
<li>FedPAC: mean for best 0.5436433901918977（*）</li>
<li>MOON: mean for best accuracy: 0.25912846481876334</li>
<li>FedPep：mean for best accuracy: 0.5059968017057569</li>
<li>FedFomo：mean for best accuracy: 0.44869402985074625（*）</li>
</ol>
<p><strong>MNIST</strong>：<br>local epoch 1；global epoch：30；<br>client nums：20；joining rotio：100%；<br>class nums：10；Model：CNN（2conv、2fc）；<br>partition：non-iid（dir）；non-blance；<br>learning-rate：0.005 (ldg 0.99)<br>model：CNN</p>
<p><strong>实验选择的对比算法：</strong></p>
<p>FedProx、FedPer、FedAvg（经典的）<br>FedAS、FedALA、Ditto、FedPAC、MOON、FedRep、FedPHP、FedFomo、pFedME</p>
<p><strong>各算法准确率测试标准</strong>：</p>
<p>(AAAI)FedALA：个性化准确率<br>(ICLR)FedPAC：泛化准确率</p>
<h2 id="实验部分论文"><a href="#实验部分论文" class="headerlink" title="实验部分论文"></a>实验部分论文</h2><p><code>这里先统一都用文字阐释，写到overleaf里面的时候再做修改，在需要的地方补充数学符号，显得更加专业</code><br><code>让AI帮忙写的时候先学习一下经典论文的文风</code></p>
<p>我们对PFLNash做了许多测试，在多个数据集上均取得了较好的效果，在这一部分我们对实验的细节情况进行说明。我们一共设置了三类实验，第一类实验使用PFLNash与一些经典的算法，在平均准确率与损失函数收敛上进行了横向对比，分析了相关的性能表现、实验收敛性以及通信复杂性；第二类实验我们通过调整一些超参数，对比相应情况下PFLNash的各项表现，进行了相应的敏感性分析；第三类实验，我们充分类比了实际的场景，测试了不同客户端数量下PFLNash的表现，同时考虑了客户端可能掉线的情况。</p>
<p>PFLNash与经典算法的对比</p>
<p>我们挑选了一些个性化联邦学习的经典算法，包括FedProx，该算法与PFLNash类似，并不直接使用全局参数更新本地参数，而是为本地训练的过程中引入了一个正则化项，来限制本地参数在训练的过程中过远的偏离全局参数，在此基础上尽可能地使用本地数据训练本地参数，从而达成个性化的效果。与该算法相比PFLNash所作的是后正则化，并不在训练的过程中考虑本地参数与全局参数的偏差，而是在本地训练完成之后使用Nash Bargaining Game让本地参数与全局参数协商出一个平衡的结果。FedPer，该算法通过仅让本地参数与全局参数共享网络的前几层参数，而保留个性化任务头的参数，来实现个性化的效果。FedAvg+本地微调，这是为了实现个性化最经典的做法，在全局模型的基础上用本地数据进一步训练。实际上对比的这几种算法对应了三种实现个性化联邦学习的常见策略，即个性化聚合的方法、学习额外个性化模型的方法、全局训练结合本地微调的方法，具有典型的代表作用。</p>
<p>为了评估模型的个性化情况，我们测试的平均准确率是个性化准确率，即每个客户端个性化模型的准确率按照样本数量进行加权平均。我们使用的测试数据集包括MNIST、EMNIST、Cifar100、Cifar10，我们分别考虑服从独立同分布的数据情况以及具有异质性的数据情况。后者是使用狄利克雷方法对数据集进行非平衡的划分，最终使各个客户端持有的数据集不服从独立同分布性，且数据集大小不一。</p>
<p>对于MNIST数据集，我们考虑了20个客户端，每个客户端每次迭代进行E轮本地训练，$E\in[1,5]$。本地训练使用SGD，设置batch_size大小为10，本地学习率设置为0.005。全局模型进行30轮迭代，每轮全局迭代之后对模型进行评估，测试当前的准确率以及损失函数的大小。使用的模型是经典的CNN网络，其具有两个卷积层，两个全连接层，可以用来完成简单的图像分类工作。</p>
<h2 id="会议-期刊"><a href="#会议-期刊" class="headerlink" title="会议&#x2F;期刊"></a>会议&#x2F;期刊</h2><h3 id="会议"><a href="#会议" class="headerlink" title="会议"></a>会议</h3><p><strong>ICDCS</strong> (IEEE International Conference on Distributed Computing Systems) - CCF-B</p>
<p>相关介绍：ICDCS 是分布式计算领域的会议，联邦学习本质上是分布式机器学习，是其核心关注方向之一。近年来关于联邦学习优化、隐私、效率、个性化（如模型个性化、梯度个性化）的论文非常多。</p>
<p>DDL：ICDCS(2026) 2025-12-13</p>
<p><strong>ECML-PKDD</strong> (European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases) - CCF-B</p>
<p>相关介绍：欧洲顶级的机器学习与数据挖掘联合会议，涵盖面非常广。联邦学习和个性化学习是其核心关注领域的热点方向。论文质量要求很高。</p>
<p>DDL:1st Submission Deadline: 30 October 2025 2nd Submission Deadline: 15 January 2026</p>
<p><strong>BDCAT</strong> (IEEE&#x2F;ACM International Conference on Big Data Computing, Applications and Technologies) - CCF-C</p>
<p>相关介绍：关注大数据计算、应用和技术。联邦学习作为处理分布式、隐私敏感大数据的关键技术，是其核心主题。个性化建模也是大数据应用的重要需求。</p>
<p>DDL：DDL (2026预估)： 主会DDL通常在7月左右</p>
<p><strong>ICA3PP</strong> (International Conference on Algorithms and Architectures for Parallel Processing) - CCF-C</p>
<p>相关介绍： 专注于并行处理的算法和架构。联邦学习涉及分布式并行计算，如果你的工作侧重于底层的并行优化算法（如通信压缩、异步更新、个性化聚合的高效实现）或特定的并行架构适配，则很契合。</p>
<p>DDL：DDL (2026预估)： ICA3PP通常在5月或6月截稿</p>
<h3 id="期刊"><a href="#期刊" class="headerlink" title="期刊"></a>期刊</h3><p>IEEE Transactions on Neural Networks and Learning Systems (TNNLS) - CCF-B</p>
<p>相关介绍：专注于神经网络和机器学习系统。对联邦学习（尤其是优化算法、个性化建模）、分布式学习、自适应学习系统等方向非常友好。</p>
<p>Future Generation Computer Systems (FGCS) - CCF-C (但常被对标更高)</p>
<p>相关介绍：虽然是C类，但其在联邦学习社区非常热门，影响因子和分区(JCR Q1&#x2F;Q2)常优于部分B类期刊。强烈关注未来计算系统，联邦学习及其应用（包括个性化）是其核心。</p>
<h2 id="NBG-代码重写"><a href="#NBG-代码重写" class="headerlink" title="NBG 代码重写"></a>NBG 代码重写</h2><p>在实验过程中遇到了一个比较严峻的问题，我在复用MTL-Nash代码的过程，最终将NBG的一般解转换为了一个优化问题，优化问题的结果是一个<strong>更新梯度</strong>的权重矩阵。</p>
<p>出现的问题是：</p>
<p>1）梯度爆炸<br>2）权重矩阵最后始终呈现出1，1的异常值，即最终的更新梯度（同样也是更新向量），会直接相加；<br>3）我通过一系列debug发现原因在NBG转换为优化问题了之后，优化问题无法成功求解，一直用异常处理令alpha_param &#x3D; prevs_alpha_param，导致权重实际上一直处于初始值</p>
<p>我分析代码，注意到 我复用的代码-我起初设想的算法-我最终敲定的算法 三者间皆存在差距，但最有问题的是复用即实验的代码与我最终敲定的算法存在差距</p>
<p>由于在小型模型上，实验代码呈现出了不错的效果，所以起初我没有注意到这个问题，或许是因为对于小型模型异常的更新方式不足以导致梯度爆炸</p>
<p>尝试了许多debug的方法，最终更换了一个优化器，初步解决了问题，不知道有没有其它隐患，我查看了权重alpha的值，看起来表现得是比较正常的</p>
<p>但是对于Cifar100数据集，梯度爆炸的问题仍然存在，先停止debug，先做一些其它种类数据集上的实验</p>
<p><strong>经过一系列debug之后让代码可以按照我的逻辑正确执行，但是取得的效果并不好</strong>！</p>
<h2 id="最终的修改方案"><a href="#最终的修改方案" class="headerlink" title="最终的修改方案"></a>最终的修改方案</h2><p><strong>对原来的算法进行了修改：</strong>记录每次epoch中的得到的聚合权重，累加之，再归一化到[0,1]区间上，最后用于全局模型与本地模型的聚合，得到个性化模型。<br>（原来的算法是对全局模型与本地模型使用本地数据集训练时得出的更新向量进行聚合，然后得到一个个性化模型的个性向量，用来更新维护的个性化模型）</p>
<p>关键修改：</p>
<p>$\omega_p &#x3D; \alpha_1 \omega_g + \alpha_2 \omega_l$</p>
<p>$\omega_p \leftarrow \omega_p + \Delta\omega_p$</p>
<p>$\quad \Delta\omega_p &#x3D; \alpha_1 \Delta\omega_g + \alpha_2 \Delta\omega_l$</p>
<p>为修改做一些理论上的说明：</p>

        


        <span>
          <a class="article-read" href="/2025/08/17/PFL-SRDP/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/08/06/PFL2/" class="item-title">PFL2</a>
      
      <time datetime="2025-08-06T07:17:24.000Z">
        2025-08-06
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 这篇blog用来记录我读的第二篇有关联邦学习的文献，其中也使用了nash bargaining game
基本概念Representation Collapse Entanglement表示崩塌纠缠：这是指在联邦无监督学习（FUSL）过程中，由于某个本地模型的表示崩塌（即该模型的特征表示不再具有区分度），会影响到全局模型和其他本地模型的表示能力。这种崩塌会导致整个系统的表示能力下降，使得模型在处理非独立同分布（non-IID）数据时效果不佳。
Flexible Uniform RegularizerFUR：灵活均匀正则化器，这是FedU2方法中的一个组件，旨在每个客户端上避免表示崩塌。通过均匀分散样本，使得模型的表示不集中在特定区域，从而保持特征空间的多样性。通过强制模型学习到更加均匀分布的特征，FUR可以防止表示崩塌，提高模型的泛化能力。
Efficient Unified AggregatorEUA：高效统一聚合器，这是FedU2方法中的另一个组件，部署在服务器端，用于在聚合客户端模型时促进统一的表示空间。该聚合器通过约束客户端模型的更新，确保各客户端模型在特征空间上的一致性。
I -->
        <!-- </div> -->

        
        <p><code>这篇blog用来记录我读的第二篇有关联邦学习的文献，其中也使用了nash bargaining game</code></p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="Representation-Collapse-Entanglement"><a href="#Representation-Collapse-Entanglement" class="headerlink" title="Representation Collapse Entanglement"></a>Representation Collapse Entanglement</h3><p>表示崩塌纠缠：这是指在联邦无监督学习（FUSL）过程中，由于某个本地模型的表示崩塌（即该模型的特征表示不再具有区分度），会影响到全局模型和其他本地模型的表示能力。这种崩塌会导致整个系统的表示能力下降，使得模型在处理非独立同分布（non-IID）数据时效果不佳。</p>
<h3 id="Flexible-Uniform-Regularizer"><a href="#Flexible-Uniform-Regularizer" class="headerlink" title="Flexible Uniform Regularizer"></a>Flexible Uniform Regularizer</h3><p>FUR：灵活均匀正则化器，这是FedU2方法中的一个组件，旨在每个客户端上避免表示崩塌。通过均匀分散样本，使得模型的表示不集中在特定区域，从而保持特征空间的多样性。通过强制模型学习到更加均匀分布的特征，FUR可以防止表示崩塌，提高模型的泛化能力。</p>
<h3 id="Efficient-Unified-Aggregator"><a href="#Efficient-Unified-Aggregator" class="headerlink" title="Efficient Unified Aggregator"></a>Efficient Unified Aggregator</h3><p>EUA：高效统一聚合器，这是FedU2方法中的另一个组件，部署在服务器端，用于在聚合客户端模型时促进统一的表示空间。该聚合器通过约束客户端模型的更新，确保各客户端模型在特征空间上的一致性。</p>
<h3 id="Inactivated-neurons"><a href="#Inactivated-neurons" class="headerlink" title="Inactivated neurons"></a>Inactivated neurons</h3><p>非活化神经元：：在人工神经网络（如深度学习模型）中，某些神经元可能在特定输入或训练阶段不被激活。激活函数（如ReLU、Sigmoid等）会根据输入值决定某个神经元是否被激活。</p>
<h3 id="Unbalanced-Optimal-Transport-Divergence"><a href="#Unbalanced-Optimal-Transport-Divergence" class="headerlink" title="Unbalanced Optimal Transport Divergence"></a>Unbalanced Optimal Transport Divergence</h3><p>非平衡最优传输散度：是一种测量分布之间差异的方法，特别适用于处理具有不同质量或总质量不守恒的分布。它是传统最优传输（Optimal Transport, OT）理论的扩展，传统最优传输通常假设两个分布具有相同的总质量，这样可以通过寻找最优运输计划来最小化从一个分布到另一个分布的“运输成本”。非平衡最优传输散度放宽了传统最优传输的总质量守恒假设，允许处理不同质量或存在质量损失的分布。它引入了一个正则项来惩罚质量的创建和销毁，从而可以在更广泛的应用场景中使用。</p>
<p>在FUR中的应用：最小化客户端数据与均匀随机样本（如来自同一球形高斯分布的样本）之间的非平衡最优传输散度。FUR强制每个客户端的数据分布更接近一个统一的参考分布，从而避免了表示崩塌并促进更均匀的特征表示。</p>
<p>注意：在最小化非平衡最优传输散度的过程中，通常并不会直接删除客户端的数据点，而是通过调整模型的训练过程来使数据的特征表示与统一的参考分布对齐。这是通过优化目标函数和引入正则化项来实现的，而不是通过直接修改原始数据。</p>
<p>具体实现方法：在训练过程中，优化目标函数时会加入非平衡最优传输散度作为正则化项。这一项会惩罚客户端数据分布与参考分布之间的差异。</p>
<p>公式：假设 $\mathcal{L}$ 是原始损失函数，$\text{UOT}(P, Q)$ 是非平衡最优传输散度项，那么新的优化目标可以表示为：<br>$\mathcal{L}_{\text{total}} &#x3D; \mathcal{L} + \lambda \cdot \text{UOT}(P, Q)$</p>
<h2 id="翻译"><a href="#翻译" class="headerlink" title="翻译"></a>翻译</h2><p>divergent 不同的，分歧的；（级数）发散的</p>
<p>suppress 抑制；封锁；压制</p>
<p>decorrelate 去相关</p>
<p>discrepant 有差异的；矛盾的</p>
<p>threshold 阈；门槛</p>
<p>deviation 偏离</p>
<p>dual 双重的</p>

        


        <span>
          <a class="article-read" href="/2025/08/06/PFL2/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/07/29/PFL/" class="item-title">PFL</a>
      
      <time datetime="2025-07-29T07:33:06.000Z">
        2025-07-29
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 这篇blog用于记录我阅读论文《 Improve global generalization for personalized federated learning within a Stackelberg game》过程中学习到的一些基础知识。
基本概念PFL个性化联邦学习：在联邦学习(FL)的基础上， PFL的目标是为每个客户端训练一个个性化模型，适应每个客户端的特定数据分布和需求。PFL适用于各客户端数据分布差异较大，且每个客户端需要一个定制化模型的场景。不同于FL训练一个全局共享的模型，希望是该模型在所有客户端上表现良好。
PFL分类“Towards Personalized Federated Learning”一文将个性化联邦学习（PFL）分为两类：

全局模型个性化（Global Model Personalization）：第一阶段，训练一个共享的全局FL模型；第二阶段，在本地的数据上进行额外的训练，达到适应个性化的目的。在这一类模型中，关注与第一阶段全局FL模型在non-IID数据上的训练能力。
学习个性化模型（Learning Personalized Model） -->
        <!-- </div> -->

        
        <p><code>这篇blog用于记录我阅读论文《 Improve global generalization for personalized federated learning within a Stackelberg game》过程中学习到的一些基础知识。</code></p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="PFL"><a href="#PFL" class="headerlink" title="PFL"></a>PFL</h3><p>个性化联邦学习：在联邦学习(FL)的基础上， PFL的目标是为每个客户端训练一个个性化模型，适应每个客户端的特定数据分布和需求。PFL适用于各客户端数据分布差异较大，且每个客户端需要一个定制化模型的场景。<strong>不同于FL训练一个全局共享的模型，希望是该模型在所有客户端上表现良好。</strong></p>
<h4 id="PFL分类"><a href="#PFL分类" class="headerlink" title="PFL分类"></a>PFL分类</h4><p>“Towards Personalized Federated Learning”一文将个性化联邦学习（PFL）分为两类：</p>
<ol>
<li>全局模型个性化（Global Model Personalization）：第一阶段，训练一个共享的全局FL模型；第二阶段，在本地的数据上进行额外的训练，达到适应个性化的目的。在这一类模型中，关注与第一阶段全局FL模型在non-IID数据上的训练能力。</li>
<li>学习个性化模型（Learning Personalized Model）：在训练阶段，就达到模型个性化的效果。个人理解：区别于上种二阶段的PFL，这一类方法在一阶段就实现了PFL（但这样理解的话似乎把Regularization based的方法归入architecture更合理）。</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/497934969">参考资料</a></p>
<h2 id="词汇"><a href="#词汇" class="headerlink" title="词汇"></a>词汇</h2>
        


        <span>
          <a class="article-read" href="/2025/07/29/PFL/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/07/16/Joint-Local-Relational-Augmentation-and-Global-Nash-Equilibrium-for-Federated-Learning-with-Non-IID-Data/" class="item-title">Joint Local Relational Augmentation and Global Nash Equilibrium for Federated Learning with Non-IID Data</a>
      
      <time datetime="2025-07-16T02:39:55.000Z">
        2025-07-16
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 这篇blog用于记录我学习一篇有关运用Nash博弈解决联邦学习有关问题的论文时，学习到的相关知识
基础概念Federated Learning基本架构联邦学习的基本架构是Server和Clients
Server通常没有数据，可以有一些用于评估模型的数据，但是在普通联邦学习中Server没有任何数据
Clients持有实际的训练数据，Clients的数量取决于有多少分布式的数据要参与训练。Clients会在各自的本地数据集上进行实际训练。
服务器和客户端都拥有自己的模型副本，前者的称为全局模型，后者的称为局部模型。
训练过程
服务器初始化全局模型参数
将该参数发送给客户端
客户端在本地进行训练，训练较短时间，通常是一个周期（所以不一定达到收敛）
客户端将改进后的模型参数发送回服务器，服务器收到五个模型参数，考虑不同的权重，进行聚合
检查是否收敛，否则重复步骤2

更加规范化的表述是
1） Initialization:Server initializes the global model
2） Communication Round:
For each communication ro -->
        <!-- </div> -->

        
        <p><code>这篇blog用于记录我学习一篇有关运用Nash博弈解决联邦学习有关问题的论文时，学习到的相关知识</code></p>
<h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><h3 id="Federated-Learning"><a href="#Federated-Learning" class="headerlink" title="Federated Learning"></a>Federated Learning</h3><h4 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h4><p>联邦学习的基本架构是Server和Clients</p>
<p>Server通常没有数据，可以有一些用于评估模型的数据，但是在普通联邦学习中Server没有任何数据</p>
<p>Clients持有实际的训练数据，Clients的数量取决于有多少分布式的数据要参与训练。Clients会在各自的本地数据集上进行实际训练。</p>
<p>服务器和客户端都拥有自己的模型副本，前者的称为全局模型，后者的称为局部模型。</p>
<h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><ol>
<li>服务器初始化全局模型参数</li>
<li>将该参数发送给客户端</li>
<li>客户端在本地进行训练，训练较短时间，通常是一个周期（所以不一定达到收敛）</li>
<li>客户端将改进后的模型参数发送回服务器，服务器收到五个模型参数，考虑不同的权重，进行聚合</li>
<li>检查是否收敛，否则重复步骤2</li>
</ol>
<p>更加规范化的表述是</p>
<p>1） Initialization:<br>Server initializes the global model</p>
<p>2） Communication Round:</p>
<p>For each communication round:<br> Server sends the global model to participating clients</p>
<p> Each client receives the global model</p>
<p>3）Client Training and Model Update:<br>For each participating client:</p>
<p> Client trains the received model on its local dataset</p>
<p> Client sends its locally updated model to the server</p>
<p>4） Model Aggregation:<br>Server aggregates the updated models received from all clients using Aggregation Algorithm (for instance, FedAvg)</p>
<p>5） Convergence Check:<br>If convergence criteria are met, end the FL process</p>
<p>If not, proceed to the next communication round (step 2)</p>
<h3 id="non-IID-data"><a href="#non-IID-data" class="headerlink" title="non-IID data"></a>non-IID data</h3><p>在联邦学习（Federated Learning, FL）的背景下，non-IID数据是指数据不是独立同分布（Independent and Identically Distributed, IID）的。IID数据假设每一条数据都是相互独立的，并且来自相同的分布。这种假设在很多传统的机器学习方法中是成立的，但在联邦学习中通常不成立</p>
<h4 id="可能的原因"><a href="#可能的原因" class="headerlink" title="可能的原因"></a>可能的原因</h4><p>数据来源的异质性：在联邦学习中，数据是分布在不同的客户端（如不同的用户设备）上的。每个客户端的数据可能由于用户的行为、兴趣、地理位置、设备类型等因素不同，从而导致数据分布的差异。</p>
<p>分布不均衡：某些客户端可能拥有更多的数据，而其他客户端可能只有少量的数据。数据的量级和类别在不同客户端之间可能是高度不均衡的。</p>
<p>标签分布差异：某些客户端可能只包含特定类别的数据，而其他客户端可能包含不同类别的数据。这种情况下，每个客户端的数据标签分布也是不同的。</p>
<h3 id="Intra-client-inconsistencies-And-Inter-client-inconsistencies"><a href="#Intra-client-inconsistencies-And-Inter-client-inconsistencies" class="headerlink" title="Intra-client inconsistencies And Inter-client inconsistencies"></a>Intra-client inconsistencies And Inter-client inconsistencies</h3><p>Intra-client Inconsistencies客户端内部不一致性 指的是单个客户端内部的数据分布问题，主要包括以下几个方面：</p>
<p>数据不平衡：单个客户端内部的不同类别的数据分布可能非常不均衡。例如，某个客户端可能有大量的类别A的数据，但只有少量的类别B的数据。这种不平衡会导致模型在训练过程中对某些类别的泛化能力不足。</p>
<p>数据稀疏性：客户端内部可能存在数据量不足的问题，特别是对于一些罕见类别的数据，这会影响模型的训练效果和泛化能力。</p>
<p>数据噪声：客户端内部的数据可能包含噪声或错误标注，这会影响模型的准确性和稳定性。</p>
<p>Inter-client Inconsistencies客户端之间不一致性 指的是不同客户端之间的数据分布差异，包括以下几个方面：</p>
<p>数据分布差异：不同客户端的数据可能来自不同的分布。例如，一个客户端可能主要包含城市环境下的数据，而另一个客户端可能主要包含农村环境下的数据。这种分布差异会导致全局模型在不同客户端上的表现不一致。</p>
<p>标签分布差异：不同客户端的数据类别分布可能不同。例如，一个客户端可能主要关注某些特定类别，而另一个客户端可能关注完全不同的类别。这会导致全局模型难以在所有客户端上都表现良好。</p>
<p>数据量差异：一些客户端可能拥有大量的数据，而其他客户端可能数据量很少。这种数据量差异也会影响全局模型的训练效果。</p>
<h3 id="Local-Relational-Augmentation"><a href="#Local-Relational-Augmentation" class="headerlink" title="Local Relational Augmentation"></a>Local Relational Augmentation</h3><p>LRA（局部关系增强）模块的目标是解决客户端内部的不一致性问题。</p>
<p>数据增强：通过生成或变换现有数据，使得每个客户端的数据分布更加均衡和丰富。这有助于改进模型在少数类别数据上的表现。</p>
<p>关系建模：在客户端内部建立数据样本之间的关系网络，利用这些关系来增强模型的学习过程。例如，可以通过图神经网络（Graph Neural Networks, GNN）来捕捉数据样本之间的相似性和相关性，从而提升模型的泛化能力。</p>
<p>摘一段原文的内容：</p>
<p>LRA first computes the similarity among a batch of data samples, and finds the neighbors of data samples based on the similarity.</p>
<p>Then LRA enhances the data feature representation via attentive message passing among the neighbors of data samples.</p>
<p>Besides, LRA conducts contrastive discrimination to maintain the representations correspondence before and after augmentation, for the same sample.</p>
<h3 id="Global-Nash-Equilibrium"><a href="#Global-Nash-Equilibrium" class="headerlink" title="Global Nash Equilibrium"></a>Global Nash Equilibrium</h3><p>GNE模块的目标是解决客户端之间的不一致性问题。纳什均衡在博弈论中是指在某种策略组合下，没有任何参与者能够通过单方面改变自己的策略来获得更好的结果。</p>
<p>摘一段原文的内容</p>
<p>Specifically, GNE collects the updating deviations from different clients to server.</p>
<p>Then GNE not only seeks a global optimization direction that maximizes the consistency among discrepant local model deviations, but also maintains clients’ optimizations towards their local optimums.</p>
<h4 id="在联邦学习中，全局纳什均衡的常见作用"><a href="#在联邦学习中，全局纳什均衡的常见作用" class="headerlink" title="在联邦学习中，全局纳什均衡的常见作用"></a>在联邦学习中，全局纳什均衡的常见作用</h4><p>平衡客户端贡献：在模型更新过程中，使各个客户端的贡献达到一种平衡状态，即没有任何一个客户端的更新会对全局模型产生过度的偏差。</p>
<p>优化全局模型：通过博弈论的方法，找到一种策略组合，使得全局模型在各个客户端的数据分布上都能表现良好。这可能涉及到权重调整、梯度校正等技术。</p>
<h3 id="representation"><a href="#representation" class="headerlink" title="representation"></a>representation</h3><p>“representation” 通常指的是数据在模型内部某一层次上的表达方式或特征表示。</p>
<p>特征表示（Feature Representation）：在深度学习模型中，输入数据（如图像、文本、音频等）经过多个层的变换后，每一层都会生成不同的特征表示。这些特征表示是原始数据在模型内部的抽象和高维度表示，能够捕捉到数据的关键特征和模式。</p>
<p>隐层表示（Hidden Layer Representation）：在神经网络中，隐层（即非输入层和非输出层）会生成中间表示，这些表示是原始输入数据通过网络层级传递和变换后的结果。这些隐层表示在分类、聚类或其他任务中具有重要作用。</p>
<p>嵌入表示（Embedding Representation）：在自然语言处理（NLP）等领域，词嵌入（如Word2Vec、GloVe）是常见的表示形式，它们将高维的稀疏数据（如单词的一个热编码）映射到低维的稠密向量空间中，从而捕捉词与词之间的语义关系。</p>
<h3 id="SLIM-method"><a href="#SLIM-method" class="headerlink" title="SLIM method"></a>SLIM method</h3><p>Sparse Linear Methods (SLIM) 是一种在推荐系统中广泛应用的技术，旨在通过稀疏线性模型来挖掘项目与项目之间的关系。SLIM 的核心思想是通过学习一个稀疏的线性权重矩阵来捕捉项目之间的相似性，从而提高推荐的准确性和效率。</p>
<h4 id="相关基本概念"><a href="#相关基本概念" class="headerlink" title="相关基本概念"></a>相关基本概念</h4><p>稀疏性（Sparsity）：SLIM 假设推荐系统中的大多数项目之间并没有直接的关联，只有少数项目之间存在显著的相似性。因此，SLIM 通过稀疏矩阵来表示这种稀疏性，从而减少计算复杂度和存储需求。</p>
<p>线性模型（Linear Model）：SLIM 使用线性模型来表示项目与项目之间的关系。具体来说，它通过一个线性组合来预测用户对一个项目的评分，该组合是基于用户对其他相关项目的评分加权得到的。</p>
<p>低秩性（Low-Rankness）：SLIM 还利用了数据的低秩特性，假设项目之间的关系可以用一个低秩矩阵来近似。这种低秩性有助于捕捉数据中的潜在结构和模式。</p>
<h4 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h4><p>构建相似度矩阵：首先，SLIM 构建一个项目与项目之间的相似度矩阵，可以基于统计相似性（如皮尔逊相关系数）来计算。</p>
<p>学习稀疏线性权重：然后，SLIM 通过优化算法学习一个稀疏的线性权重矩阵。这个矩阵的每个元素表示一个项目对另一个项目的线性关系权重。</p>
<p>预测评分：最后，使用学习到的权重矩阵和用户的历史评分数据，SLIM 可以预测用户对未评分项目的评分。</p>
<h3 id="Pearson-Correlation-Matrix"><a href="#Pearson-Correlation-Matrix" class="headerlink" title="Pearson Correlation Matrix"></a>Pearson Correlation Matrix</h3><p>皮尔逊相关矩阵（Pearson Correlation Matrix） 是一种用于度量数据集中各个变量之间线性关系强度的矩阵。它通过皮尔逊相关系数来衡量不同变量（或数据样本）之间的相关性。相关系数的值范围从 -1 到 +1，其中：</p>
<p>+1 表示完全正相关，即两个变量的变化方向完全一致。</p>
<p>0 表示没有线性相关性，即两个变量之间没有任何线性关系。</p>
<p>-1 表示完全负相关，即两个变量的变化方向完全相反。</p>
<h4 id="皮尔逊相关系数的计算公式"><a href="#皮尔逊相关系数的计算公式" class="headerlink" title="皮尔逊相关系数的计算公式"></a>皮尔逊相关系数的计算公式</h4><p>皮尔逊相关系数（$r$）的计算公式为：</p>
<p>$r &#x3D; \frac{\sum (X_i - \bar{X})(Y_i - \bar{Y})}{\sqrt{\sum (X_i - \bar{X})^2 \sum (Y_i - \bar{Y})^2}}$</p>
<p>其中：</p>
<p>$X_i$和 $Y_i$分别是样本 $X$ 和 $Y$ 的第 $i$ 个观测值；<br>$\bar{X}$和 $\bar{Y}$分别是样本 $X$ 和 $Y$ 的均值。</p>
<h4 id="皮尔逊相关矩阵的应用"><a href="#皮尔逊相关矩阵的应用" class="headerlink" title="皮尔逊相关矩阵的应用"></a>皮尔逊相关矩阵的应用</h4><p>特征选择：在机器学习中，相关矩阵可以帮助识别高度相关的特征，进而去除冗余的特征，从而提升模型的性能。</p>
<h3 id="Frobenius-norm"><a href="#Frobenius-norm" class="headerlink" title="Frobenius norm"></a>Frobenius norm</h3><p>弗罗贝尼乌斯范数：一种用于衡量矩阵大小的范数，计算方法是将矩阵中所有元素的平方和开平方。</p>
<h3 id="KKT-conditions"><a href="#KKT-conditions" class="headerlink" title="KKT conditions"></a>KKT conditions</h3><p>KKT条件（Karush-Kuhn-Tucker Conditions）是非线性规划问题的一组必要条件，用于找到约束优化问题的最优解。</p>
<p>对于一个优化问题：</p>
<p>$\begin{aligned}<br>&amp; \min f(\mathbf{x}), \<br>&amp; \text{subject to} \ g_i(\mathbf{x}) \leq 0, \ i &#x3D; 1, \ldots, m, \<br>&amp; \ \ \ \ \ \ \ \ \ \ \ \ \ h_j(\mathbf{x}) &#x3D; 0, \ j &#x3D; 1, \ldots, p,<br>\end{aligned}$</p>
<p>KKT条件包括以下几个部分：</p>
<p>拉格朗日函数：</p>
<p>构造拉格朗日函数 $L(\mathbf{x}, \mathbf{\lambda}, \mathbf{\mu})$：<br>$L(\mathbf{x}, \mathbf{\lambda}, \mathbf{\mu}) &#x3D; f(\mathbf{x}) + \sum_{i&#x3D;1}^{m} \lambda_i g_i(\mathbf{x}) + \sum_{j&#x3D;1}^{p} \mu_j h_j(\mathbf{x})$</p>
<p>Stationarity（驻点条件）：</p>
<p>$\frac{\partial L(\mathbf{x}, \mathbf{\lambda}, \mathbf{\mu})}{\partial \mathbf{x}} &#x3D; 0$</p>
<p>Primal Feasibility（原始可行性）：</p>
<p>$g_i(\mathbf{x}) \leq 0, \quad i &#x3D; 1, \ldots, m$</p>
<p>$h_j(\mathbf{x}) &#x3D; 0, \quad j &#x3D; 1, \ldots, p$</p>
<p>Dual Feasibility（对偶可行性）：</p>
<p>$\lambda_i \geq 0, \quad i &#x3D; 1, \ldots, m$</p>
<p>Complementary Slackness（互补松弛性）：</p>
<p>$\lambda_i g_i(\mathbf{x}) &#x3D; 0, \quad i &#x3D; 1, \ldots, m$</p>
<h2 id="词汇"><a href="#词汇" class="headerlink" title="词汇"></a>词汇</h2><p>decentralized：分散管理的</p>
<p>discrepant：有差异的；矛盾的</p>
<p>deviation：偏离；偏差</p>
<p>distributed：分布式的</p>
<p>paradigm：典范</p>
<p>unified：一致的</p>
<p>simultaneously：同时的</p>
<p>hinder：阻碍</p>
<p>variance：分歧，不一致；方差（统计学）</p>
<p>empirical：经验主义的</p>
<p>conventionally：照惯例</p>
<p>distinguishable：可辨识的</p>
<p>sparse：稀少的</p>
<p>refine：精炼；改善</p>
<p>contamination：污染</p>
<p>alleviate：减轻，缓和</p>
<p>contrastive：对比的</p>

        


        <span>
          <a class="article-read" href="/2025/07/16/Joint-Local-Relational-Augmentation-and-Global-Nash-Equilibrium-for-Federated-Learning-with-Non-IID-Data/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/07/13/Reforcement-learning%E5%85%A5%E9%97%A8/" class="item-title">Reforcement learning入门</a>
      
      <time datetime="2025-07-13T02:51:41.000Z">
        2025-07-13
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 这篇blog用于记录我进行强化学习入门时学习到的基础知识
基本概念一些基本要素：

Agent：进行“学习”的主体，会通过学习到的经验与环境交互，并在与环境交互的过程中进一步学习。
Environment：Agent交互的对象，客观存在，例如智能驾驶捕捉到的一张图片
State：Agent观察当前自己所处环境，获取到的局部环境信息
Action：Agent根据State结合自己以往的经验做出的行动，行动会改变Environment（Action可能是离散值，也可能是连续值，处理方法是不同的）
Reward：Agent执行Action改变Environment后，Environment给到Agent的反馈，可以用于反映Action的好坏，同时为Agent累积“经验”

进一步，关于Reward的作用：例如将Agent当作一个neural network，其经验就是权重参数θ，坏的Action应该产生一个Reward将θ向“反向”调节，好的Action应该产生一个Reward将θ向“正向”调节。
基本的工作流程强化学习算法的基本工作流程就是，根据Environment产生State输入Ag -->
        <!-- </div> -->

        
        <p><code>这篇blog用于记录我进行强化学习入门时学习到的基础知识</code></p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>一些基本要素：</p>
<ol>
<li>Agent：进行“学习”的主体，会通过学习到的经验与环境交互，并在与环境交互的过程中进一步学习。</li>
<li>Environment：Agent交互的对象，客观存在，例如智能驾驶捕捉到的一张图片</li>
<li>State：Agent观察当前自己所处环境，获取到的局部环境信息</li>
<li>Action：Agent根据State结合自己以往的经验做出的行动，行动会改变Environment（Action可能是离散值，也可能是连续值，处理方法是不同的）</li>
<li>Reward：Agent执行Action改变Environment后，Environment给到Agent的反馈，可以用于反映Action的好坏，同时为Agent累积“经验”</li>
</ol>
<p>进一步，关于Reward的作用：<br>例如将Agent当作一个neural network，其经验就是权重参数θ，坏的Action应该产生一个Reward将θ向“反向”调节，好的Action应该产生一个Reward将θ向“正向”调节。</p>
<h3 id="基本的工作流程"><a href="#基本的工作流程" class="headerlink" title="基本的工作流程"></a>基本的工作流程</h3><p>强化学习算法的基本工作流程就是，根据Environment产生State输入Agent，Agent做出Action，改变Environment，获得Reward，反馈调整Agent，不断重复。直到满足退出条件</p>
<h3 id="关于计算机眼中的环境"><a href="#关于计算机眼中的环境" class="headerlink" title="关于计算机眼中的环境"></a>关于计算机眼中的环境</h3><p>通常情况下，计算机眼中的环境是一张图像。</p>
<p>例如，环境就是各种可能的画面，State就是当前捕捉到的画面，State输入给Agent(NN)，然后由Agent(NN的参数与结构)计算产生Action(决策，或是各种决策的概率)；进一步，也可以理解成State是由画面经过GNN处理后的特征信息…</p>
<h3 id="强化学习的一个关键问题"><a href="#强化学习的一个关键问题" class="headerlink" title="强化学习的一个关键问题"></a>强化学习的一个关键问题</h3><p>通过前面的基本概念，看似只需要训练一个输入为State，输出为Action的神经网络就可以了，但是事实并非如此。</p>
<p>因为本质上，这个神经网络不是一个纯粹的有监督学习，并非用于分类与回归的网络，处理的数据没有标签，对于每一个State处理后得到的Action无法立刻得知True or False（类比分类），没有办法直接地对神经网络的参数进行更新，取而代之的是产生一个Good or Bad的Reward，我们最终的目标总是要去最大化这个Reward。（当然，以一个游戏做类比，在进行一系列Action后，我们最终能够得知游戏的结果是胜利或失败，对应True or False，所以说不是纯粹的有监督学习）。</p>
<p>所以强化学习算法的关键是要有对于每种Action给出合理Reward的方案，并且要有根据Reward去更新模型参数的方案。</p>
<p>关于<strong>强化学习对比深度学习</strong>例如给出老虎的图片做分类</p>
<p>深度学习可以用CNN去提取特征，然后根据当前模型参数计算出分类标签，根据估计的标签和真实标签的差异情况，计算损失，根据损失更新模型参数，就完成了一次学习。</p>
<p>而强化学习对于给出的图片是先由Agent，得出Action，然后有Action与Reward，再去想办法更新模型参数。</p>
<p>所以，<strong>如何训练一个网络，可以根据Action和Reward进行更新</strong>是强化学习最关键的问题。</p>
<h2 id="PPO-Proximal-Policy-Optimization-算法"><a href="#PPO-Proximal-Policy-Optimization-算法" class="headerlink" title="PPO(Proximal Policy Optimization)算法"></a>PPO(Proximal Policy Optimization)算法</h2><h3 id="介绍背景"><a href="#介绍背景" class="headerlink" title="介绍背景"></a>介绍背景</h3><p>此部分根据一个飞船降落的小游戏，介绍PPO算法，这个小游戏是一个下降的飞船，玩家应该根据left or right去操作飞船的左右行动，最终让飞船落地时在两个小旗帜中间，即降落在正确的位置。</p>
<h3 id="再次从深度学习的视角看"><a href="#再次从深度学习的视角看" class="headerlink" title="再次从深度学习的视角看"></a>再次从深度学习的视角看</h3><p>关于神经网络NN（θ）</p>
<ol>
<li>输入：使用NN神经网络，输入是当前游戏的图片</li>
<li>输出：两个Action，左或右</li>
</ol>
<p>如果我们使用深度学习，看起来这是一个二分类的问题，很简单。如果说θ作为权重参数会控制，对于每一张图片的分类结果，左或右，代表应该怎样玩。那么我们最终的目标应该是求出一个合适的θ，可以对每一张图片给出合理的决策，其中可以用到梯度下降等等一些常见的方法。</p>
<p>但是，我们不得不面临一些非常困难的问题，标签（tag）、梯度（gradient）、损失函数（loss function）应该怎样去确定，这是强化学习需要考虑的问题。</p>
<p>因为不是每一步Action都有一个对应的“正确的”tag，告诉我们的决策是否正确，我们每轮训练，只有一系列的Action，以及最终的一个结果，胜利或失败（或许可以称为tag），那么我们应该如何去定义损失函数？<strong>这就是PPO算法考虑的关键问题，即目标函数的定义方法&amp;如何进行求解</strong></p>
<h3 id="PPO算法"><a href="#PPO算法" class="headerlink" title="PPO算法"></a>PPO算法</h3><h4 id="episod"><a href="#episod" class="headerlink" title="episod"></a>episod</h4><p>一个完整的过程，其中具有许多的State，Agent根据每个State做出Action，改变环境在此处即根据Action进入下一个State，直到停止的退出条件即完成了一个episod。</p>
<h4 id="常见的退出条件"><a href="#常见的退出条件" class="headerlink" title="常见的退出条件"></a>常见的退出条件</h4><p>max_step，最大迭代次数，Agent最多只能进行max_step次Action的产生，完成后退出episod；其它退出条件，对于具体的游戏可能需要设置不同的退出条件，例如此处就是飞机落到地面上，episod就完成了。</p>
<h4 id="整个生命周期的奖励"><a href="#整个生命周期的奖励" class="headerlink" title="整个生命周期的奖励"></a>整个生命周期的奖励</h4><p>$R &#x3D; \sum^{T}_{t&#x3D;1} r_t$，如果考虑退出条件为设置max_step &#x3D; 1000，那么对于Action（$a_1, a_2, \dots, a_1000$），有Reward（$r_1, r_2, \dots, r_1000$），求和后即整个episod的Reward(R)。</p>
<p>奖励可以类比于标签（用于衡量每次Action的好坏），在一些简单的实验中我们可以使用openAI的工具包gym，其中按照一些经典的小游戏的游戏规则，会<strong>给定好每种Action的Reward</strong>。</p>
<p>奖励是由当前一步的Action与State共同决定的，预先确定好后，作为游戏规则是不能改变的</p>
<p>（当然奖励的设置仍然是强化学习的关键，只是在这一部分，对于PPO算法的学习，我们更加关注于<strong>神经网络的设置、目标函数的定义、参数更新的方法</strong>）</p>
<h4 id="一次游戏的记录结果"><a href="#一次游戏的记录结果" class="headerlink" title="一次游戏的记录结果"></a>一次游戏的记录结果</h4><p>即每一步的状态与行动（trajectory），$\tau &#x3D; {s_1,a_1,s_2,a_2,\dots,s_T,a_T}$（在此基础上，我们需要考虑如何给出每一步的行动，让总的奖励达到最大，即训练一个网络模型$\pi_\theta(a_t|s_t)$，其输入是状态State，输出是Action，由所有的模型参数来根据输入决定输出，训练参数的目标是要让奖励尽可能的大）</p>
<p>游戏记录的表达式是：</p>
<p>$p_theta(s_1,a_1,\dots,s_T,a_T) &#x3D; p(s_1)\prod^{T}<em>{t&#x3D;1}\pi_\theta(a_t|s_t)p(s</em>{t+1}|s_t,a_t)$</p>
<p>含义是得到游戏记录，初始状态是$s_1$执行action，$a_1$，切换到状态，$s_2$执行action，$a_2$，…切换到状态$s_T$执行action，$a_T$的概率是：初始状态是$s_1$的概率连乘上模型在该状态下给出对应action的概率和根据游戏规则，在当前状态下执行相应action后切换到下一对应状态的概率</p>
<h4 id="Action的产生与作用"><a href="#Action的产生与作用" class="headerlink" title="Action的产生与作用"></a>Action的产生与作用</h4><p>关于Action的产生$p_\theta(a_t|s_t)$，由当前状态确定某一行为的概率，对应Action产生的概率，是模型输出的结果，同时是我们应该关注的问题</p>
<p>关于Action的作用，$p(s_{t+1}|s_t,a_t)$在某一状态下做出某Action，会切换到下一个状态，这是根据游戏的规则确定的，与我们的模型无关</p>
<h4 id="一般的强化学习算法的目标与训练过程"><a href="#一般的强化学习算法的目标与训练过程" class="headerlink" title="一般的强化学习算法的目标与训练过程"></a>一般的强化学习算法的目标与训练过程</h4><p>我们的目标是得到一个合适的模型参数 $\theta^{*} &#x3D; argmax_\theta E_{\tau \sim p_\theta(\tau)}[\sum_t r(s_t,a_t)]$</p>
<p><em>相关理解：</em></p>
<p>其中$p_\theta(\tau)$表示在策略$\pi_\theta$下，产生轨迹$\tau$的概率分布，即$p_\theta(\tau)$是轨迹 $\tau$ 的概率，其依赖于策略的参数$\theta$。</p>
<p>在优化目标 $\theta^{*} &#x3D; \arg\max_\theta E_{\tau \sim p_\theta(\tau)}\left[\sum_t r(s_t, a_t)\right]$中，$E_{\tau \sim p_\theta(\tau)}$表示在策略 $\pi_\theta$下，对所有可能的轨迹 $\tau$ 进行期望（期望值的计算）。具体来说，$\tau \sim p_\theta(\tau)$这个下标的含义是：轨迹 $\tau$ 是根据策略 $\pi_\theta$产生的。也就是说，我们考虑的是在当前策略 $\pi_\theta$下，每个轨迹 $\tau$ 出现的概率，并对其累计奖励 $\sum_t r(s_t, a_t)$进行加权平均（即期望值）。</p>
<p>进一步，根据大数定律</p>
<p>$E_{\tau \sim p_\theta(\tau)} \approx \frac{1}{N}\sum_{i}\sum_{t}r(s_{i,t},a_{i,t})$其中$N$趋近于$∞$，我们将该期望记作$\mathcal{J}_\theta$</p>
<p>或者是，期望的展开</p>
<p>这里直接将$\pi_\theta$记作$\tau$的分布概率，将$\tau$对应的奖励，即刚才的$\sum_t r(s_t, a_t)$记作$r(\tau)$，对期望展开如下:</p>
<p>$\mathcal{J}(\theta) &#x3D; E_{\tau \sim \pi_\theta(\tau)}[r(\tau)] &#x3D; \int \pi_\theta(\tau)r(\tau)d\tau$</p>
<p>在期望展开的基础上，我们计算对于参数的梯度</p>
<p>$\nabla_\theta \mathcal{J}<em>\theta &#x3D; \int \nabla_\theta \pi_\theta (\tau)r(\tau)d\tau &#x3D; \int \pi_\theta(\tau)\nabla_\theta log\pi_\theta(\tau)r(\tau)d\tau &#x3D; E</em>{\tau \sim \pi_\theta(\tau)}[\nabla_\theta log \pi_{\theta}(\tau)r(\tau)]$</p>
<p>最后，再使用大数定律展开</p>
<p>$\nabla_\theta \mathcal{J}(\theta) \approx \frac{1}{N}\sum^{N}<em>{i&#x3D;1}(\sum^{T}</em>{t&#x3D;1}\nabla_\theta log \pi_{\theta}(a_{i,t}|s_{i,t}))(\sum^T_{t&#x3D;1}r(s_{i,t},a_{i,t}))$</p>
<p>注意，这里把得到轨迹$\tau$的概率展开了，把其对应的奖励也展开了</p>
<p>我们训练的过程就是使用<strong>梯度上升</strong>更新参数，对应为：</p>
<p>$\theta$ &lt;- $\theta + \alpha \nabla_\theta \mathcal{J}(\theta)$</p>
<h2 id="蒙特卡洛方法"><a href="#蒙特卡洛方法" class="headerlink" title="蒙特卡洛方法"></a>蒙特卡洛方法</h2><h3 id="Motivating-example"><a href="#Motivating-example" class="headerlink" title="Motivating example"></a>Motivating example</h3><p>Q：我们如何能够不依赖于模型，进行一些预测<br>A：最简单的思想就是，Monte Carlo estimation</p>
<h4 id="一个例子——抛掷硬币"><a href="#一个例子——抛掷硬币" class="headerlink" title="一个例子——抛掷硬币"></a>一个例子——抛掷硬币</h4><p>定义一个变量$X$，如果正面朝上则$X &#x3D; 1$，否则$X &#x3D; -1$，我们现在要考虑的是如何计算期望$E(X)$</p>
<p>显然，当我们拥有一个模型（概率分布）的时候，即$X \sim p(X), p(X&#x3D;1)&#x3D;0.5, P(X&#x3D;-1)&#x3D;0.5$，那么我们可以根据期望的定义$E(X) &#x3D; \sum_x xp(x)$快速地求出均值。</p>
<p>但是当我们没有这个模型的时候呢？即Model-free的情况</p>
<p>Monte Carlo estimation：进行多次实验，用平均数近似期望</p>
<p>$E(X) &#x3D; \frac{1}{n}\sum^n_{i&#x3D;1}x_i$</p>
<p>数学上的支撑就是我们的大数定律（Law of Large Numbers）</p>
<p>我们知道state value、action value的定义本身就是期望expectations，所以后续我们会用Mente Carlo在Model free的条件下去求state value、action value，并得出相应的策略</p>
<h3 id="MC-Basic"><a href="#MC-Basic" class="headerlink" title="MC Basic"></a>MC Basic</h3><p>Key quesition：How to convert the policy iteration algorithm to be model-free</p>
<h4 id="Policy-Iteration"><a href="#Policy-Iteration" class="headerlink" title="Policy Iteration"></a>Policy Iteration</h4><p>策略迭代（Policy Iteration）是强化学习中的一种经典算法，用于解决马尔可夫决策过程（MDP）问题。其目标是找到一个最优策略，使得在该策略下的长期累积奖励最大化。策略迭代由两个主要步骤组成：策略评估（Policy Evaluation）和策略提升（Policy Improvement）。</p>
<p>策略迭代的步骤</p>
<p>初始化</p>
<p>初始化一个任意策略 $\pi$。</p>
<p>策略评估（Policy Evaluation）</p>
<p>在策略评估阶段，我们计算当前策略 $\pi$ 的状态价值函数 $V^{\pi}(s)$<br>，即在策略 $\pi$ 下，从状态 $s$ 开始的期望累积奖励。</p>
<p>通过贝尔曼期望方程迭代地更新 $V^{\pi}(s)$<br>：<br>$  V^{\pi}(s) &#x3D; \sum_{a} \pi(a|s) \sum_{s’} P(s’|s,a) [R(s,a,s’) + \gamma V^{\pi}(s’)]$</p>
<p>其中，$P(s’|s,a)$是从状态 $s$ 执行动作 $a$ 转移到状态 $s’$的概率，$R(s,a,s’)$是从状态 $s$ 执行动作 $a$ 并转移到状态 $s’$所得到的奖励， $\gamma$ 是折扣因子。</p>
<p>策略提升（Policy Improvement）</p>
<p>在策略提升阶段，我们使用当前价值函数 $V^{\pi}(s)$来改进策略 $\pi$。<br>通过贪心策略提升来生成一个新的策略 $\pi’$，使得在每个状态下选择使得期望累积奖励最大的动作：</p>
<p>$  \pi’(s) &#x3D; \arg\max_{a} \sum_{s’} P(s’|s,a) [R(s,a,s’) + \gamma V^{\pi}(s’)]<br> $</p>
<p>检查收敛<br>如果新的策略 $\pi’$等于旧的策略 $\pi$（即策略不再变化），则策略迭代过程结束，当前策略即为最优策略。</p>
<p>否则，更新策略 $\pi \ne \pi’$，继续迭代。</p>
<h4 id="key-point"><a href="#key-point" class="headerlink" title="key point"></a>key point</h4><p>在Policy Iteration的策略提升过程中，实际上我们不止考虑一个针对当前state的最优action，而是会考虑一系列action，即最优的策略，可以写作：</p>
<p>$\pi’(s) &#x3D; argmax_\pi \sum_a \pi(a|s) [\sum_r p(r|s,a)r + \gamma \sum_{s’}p(s’|s,a)v_{\pi_k}(s’)] &#x3D; argmax_\pi \sum_a \pi(a|s)q_{\pi_k}(s,a), s \in S$</p>
<p>问题的关键就在于$q_{\pi_k}(s,a)$这个状态动作值函数，而$\pi(a|s)$为状态s下采取动作a的概率，这在mento carlo考虑的场景下是已知的</p>
<p>我们回到状态值函数的定义</p>
<p>$q_{\pi_k}(s,a) &#x3D; E[G_t|S_t &#x3D; s,At &#x3D; a]$</p>
<p>其中$G_t$是状态s下做出动作a后的累积的奖励；可以看到其本质是一个期望，所以可以用mento carlo的方法来估计它</p>
<h4 id="具体求解"><a href="#具体求解" class="headerlink" title="具体求解"></a>具体求解</h4><p>1）从任意状态$(s,a)$出发，根据当前策略$\pi_k$，生成一个episode</p>
<p>2）返回episode的累积奖励$g(s,a)$，这里$g(s,a)$本质上就是状态值函数期望函数中的变量$G_t$的一个采样（sample）</p>
<p>3）进行多轮采样，令$q_{\pi_k}(s,a) &#x3D; \frac{1}{N}\sum^{N}_{i&#x3D;1}g^{(i)}(s,a)$</p>
<p>得到了$q_{\pi_k}(s,a)$之后，我们就可以和policy iteration中的第二步一样，去根据这个状态值函数，更新我们的最优策略。<strong>所以mento carlo与policy iteration两者最大的不同就在于值函数的求解，policy iteration不是model-free的，相关的概率是已知的，可以直接根据期望的定义求解，而mento carlo做不到。</strong></p>
<h2 id="奖励设置"><a href="#奖励设置" class="headerlink" title="奖励设置"></a>奖励设置</h2><p><code>这一部分介绍有关栅格迷宫问题可以使用的奖励设置</code></p>
<h3 id="目标导向"><a href="#目标导向" class="headerlink" title="目标导向"></a>目标导向</h3><p>当智能体成功到达目标位置时，给予一个较大的正奖励；反之，每一步移动没有到达目标点，可以给予一个较小的负奖励。</p>
<p>从而让智能体更快地到达目标位置。</p>
<h3 id="常见的惩罚"><a href="#常见的惩罚" class="headerlink" title="常见的惩罚"></a>常见的惩罚</h3><ol>
<li>智能体试图移动到不可到达的位置，给予负奖励，防止撞墙</li>
<li>智能体重复访问同一位置的时候，给予负奖励，防止重复访问</li>
</ol>
<h3 id="其它设置"><a href="#其它设置" class="headerlink" title="其它设置"></a>其它设置</h3><p>距离奖励，每步靠近目标给予正奖励；远离目标给予负奖励<br>探索奖励，进入没有探索过的区域给予正奖励，但是逐渐收敛</p>

        


        <span>
          <a class="article-read" href="/2025/07/13/Reforcement-learning入门/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/07/06/Fairness-Aware-Meta-Learning-via-Nash-Bargaining/" class="item-title">Fairness-Aware Meta-Learning via Nash Bargaining</a>
      
      <time datetime="2025-07-06T02:04:38.000Z">
        2025-07-06
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 这篇blog用于记录我阅读的一篇将传统的Game中的方法应用到学习中的论文
论文理解思路：

经典的Meta-learning的框架
Meta-learning在learning with fairness中的运用（框架、典型的方法）
经典方法中存在的问题 &amp; 使用 NBS的改进

Meta-learning的框架在解决机器学习的过程中对于不同group的公平性问题的时候，会使用sensitive-attributed validation set来训练调整模型的参数，这个过程与常规的训练过程相结合通常被套入一个meta-learning framework中。
概念用于记录阅读过程中，遇到的新的、不熟悉的概念
Group-level fairness群体级公平性： 群体级公平性是指在机器学习模型中确保不同群体（如性别、种族、年龄等）在预测结果上受到公平对待。具体来说，这意味着模型的性能（如准确率、误报率等）在不同群体之间应该尽可能一致，避免某些群体受到系统性的偏见或歧视。例如，在招聘系统中，不同性别的候选人应该有相似的通过率，而不是系统性地偏向某一性别。
Fairness o -->
        <!-- </div> -->

        
        <p><code>这篇blog用于记录我阅读的一篇将传统的Game中的方法应用到学习中的论文</code></p>
<h2 id="论文理解"><a href="#论文理解" class="headerlink" title="论文理解"></a>论文理解</h2><p>思路：</p>
<ol>
<li>经典的Meta-learning的框架</li>
<li>Meta-learning在learning with fairness中的运用（框架、典型的方法）</li>
<li>经典方法中存在的问题 &amp; 使用 NBS的改进</li>
</ol>
<h3 id="Meta-learning的框架"><a href="#Meta-learning的框架" class="headerlink" title="Meta-learning的框架"></a>Meta-learning的框架</h3><p>在解决机器学习的过程中对于不同group的公平性问题的时候，会使用sensitive-attributed validation set来训练调整模型的参数，这个过程与常规的训练过程相结合通常被套入一个meta-learning framework中。</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p><code>用于记录阅读过程中，遇到的新的、不熟悉的概念</code></p>
<h3 id="Group-level-fairness"><a href="#Group-level-fairness" class="headerlink" title="Group-level fairness"></a>Group-level fairness</h3><p>群体级公平性： 群体级公平性是指在机器学习模型中确保不同群体（如性别、种族、年龄等）在预测结果上受到公平对待。具体来说，这意味着模型的性能（如准确率、误报率等）在不同群体之间应该尽可能一致，避免某些群体受到系统性的偏见或歧视。例如，在招聘系统中，不同性别的候选人应该有相似的通过率，而不是系统性地偏向某一性别。</p>
<h3 id="Fairness-objectives"><a href="#Fairness-objectives" class="headerlink" title="Fairness objectives"></a>Fairness objectives</h3><p>公平性目标：公平性目标是指在模型训练和评估过程中设定的具体指标，用来衡量和改进模型的公平性。</p>
<p>常见的公平性目标有：</p>
<ol>
<li>Demographic parity：模型的预测结果应该在不同群体之间均匀分布。</li>
<li>Equalized odds：在不同群体中，模型的假正率和假负率应该相同。</li>
<li>Equal opportunity：对于实际正类样本，不同群体的真正率应该相同。</li>
</ol>
<p>补充：<br>Demographically balanced validation set（人口统计学平衡的验证集）：指在机器学习模型的验证过程中，确保验证集中的数据在人口统计学特征（例如：性别、年龄、种族、收入水平、地理位置等）上具有均衡性。这种平衡的目标是使得模型能够在不同群体之间表现一致，从而避免模型在某些群体上产生偏差或不公平的表现。</p>
<h3 id="Sensitive-attributed-validation-set"><a href="#Sensitive-attributed-validation-set" class="headerlink" title="Sensitive attributed validation set"></a>Sensitive attributed validation set</h3><p>敏感属性验证集：敏感属性验证集是指包含敏感属性（如性别、种族、年龄等）的数据集，用于评估模型在这些属性上的表现和公平性。通过在验证集上测试模型的表现，可以确定模型是否对某些群体存在偏见，并据此调整模型参数以提升公平性。例如，如果发现模型在不同种族上的准确率差异较大，可以通过调整模型来减少这种差异。</p>
<h3 id="Meta-learning-framework"><a href="#Meta-learning-framework" class="headerlink" title="Meta-learning framework"></a>Meta-learning framework</h3><p>元学习：指的是“学习如何学习”，即通过学习算法在多个任务上的表现，来调整和优化学习过程本身。在机器学习中，元学习框架通常用于设计模型，帮助它们更好地适应新任务，或者从不同任务中学习出更泛化的知识。</p>
<p>元学习框架：通过一个高层的学习过程，动态地调整模型的参数，以便满足公平性目标。这种框架让机器学习模型不仅仅是对一个固定任务进行学习，还能调整自己的学习策略，以实现更好的公平性目标。</p>
<h4 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h4><p>为什么需要Meta-learning</p>
<p>神经网络在进行猫、狗的图像识别的时候，可能需要数以千计的图片用于训练模型的参数，最终对于新给出的图片神经网络才能给出正确的结果。类比人类的小孩子，在没有见过任何动物的情况下，可能也需要见过许多猫猫狗狗才能正确区分这两种动物。</p>
<p>在此基础上，出现了一只驴子，人类小孩可以结合以前对于识别猫狗的经验，来观察驴子的特征，通过这一只驴子，在未来就可能正确的识别出新的驴子；但是对于神经网络而言无法做到。</p>
<p>Meta-learning的目的就是想赋予神经网络这样的能力——基于过去的学习经验，对于新的学习任务，进行一个快速的学习。</p>
<h4 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h4><p>基本机器学习算法流程：</p>
<ol>
<li>Data1，例如(x, y)，x是特征，y是label，将它们输入模型</li>
<li>Traning1，对Loss求gradient，迭代</li>
<li>Model1，直到收敛，得到一组权重，对应就是Model1</li>
</ol>
<p><em>算法描述：</em></p>
<p>For all $\mathcal{T}_i$ do<br>Evaluate $\nabla_\theta \mathcal{L}(\mathcal{T}_i, f_\theta)$ with respect to $K$ examples.<br>Compute adapted parameters with gradient descent:<br>$\theta’_i &#x3D; \theta - \alpha \nabla_\theta \mathcal{L}(\mathcal{T}_i, f_\theta)$<br>end for</p>
<p>实际上这就是Meta learning的inner part，在此基础上加上outer part就是完整的元学习框架。</p>
<p><em>算法描述：</em></p>
<p>Require：$p(\mathcal{T})$: distribution over tasks<br>Require: $\alpha, \beta$: step size hyperparameters</p>
<ol>
<li>randomly initialize $\theta$</li>
<li>while not done do</li>
<li>Sample batch of tasks $\mathcal{T}_i$~$p(\mathcal{T})$</li>
<li>for all $\mathcal{T}_i do$</li>
<li>Evaluate $\nabla_\theta \mathcal{L}(\mathcal{T}_i, f_\theta)$ with respect to $K$ examples.  </li>
<li>Compute adapted parameters with gradient descent:<br>$\theta’_i &#x3D; \theta - \alpha \nabla_\theta \mathcal{L}(\mathcal{T}_i, f_\theta)$  </li>
<li>end for</li>
<li>Update $\theta$&lt;-$\theta - \beta \nabla_{\theta} \sum_{\mathcal{T}<em>i ~ p(\mathcal{T})}\mathcal{L}</em>{\mathcal{T}<em>i}(f</em>{\theta’_{i}})$</li>
<li>end while</li>
</ol>
<p>元学习有两个loop，inner loop对应for，outer loop对应while</p>
<p>inner loop会从很多个模型挑出几个进行训练，$\theta_i$就对应第i个模型（训练器）</p>
<p>$p(\mathcal{T})$就是所有的Task<br>$\alpha, \beta$是学习率，前者是对每个模型学习的学习率，后者是元学习的学习率</p>
<p>Update $\theta$&lt;-$\theta - \beta \nabla_{\theta} \sum_{\mathcal{T}<em>i ~ p(\mathcal{T})}\mathcal{L}</em>{\mathcal{T}<em>i}(f</em>{\theta’_{i}})$是最关键的一步，结合inner loop中的所有loss，定义新的loss，再求梯度，用来更新$\theta$。其体现出的是元学习模型是要学习各种小模型的平均能力。</p>
<p>其好处是你最终得到的$\theta$（对应的各种weights），可以用于作为未来你要训练的用于一个新的任务的小模型时$\theta_{new}$的初始值（新的任务与过去的各种小模型对应的任务相似），这样由于初始的权重天然对应各种小模型的平均能力，其在学习的过程中可以很快地收敛，加快训练速度。</p>
<h3 id="Hypergradient"><a href="#Hypergradient" class="headerlink" title="Hypergradient"></a>Hypergradient</h3><p>超梯度： 在元学习中，<strong>超梯度（hypergradient）</strong>是指对学习过程本身的梯度进行计算。简单来说，元学习需要优化的目标不仅仅是模型的参数（如权重），还包括学习规则或算法本身的参数（例如学习率）。</p>
<p>超梯度冲突：在元学习过程中，当不同的子群体（如不同性别或种族的群体）需要不同的调整来实现公平性目标时，这些调整可能会产生冲突。例如，为了在某个群体上实现某个公平性目标，可能需要对模型的某个参数进行特定的调整，但对另一个群体却可能会产生不利影响，导致不同的公平性目标之间无法兼容。这样的冲突会导致模型优化过程的不稳定，甚至可能使得模型的性能和公平性都受到影响。</p>
<h3 id="validation-loss"><a href="#validation-loss" class="headerlink" title="validation loss"></a>validation loss</h3><p>验证损失：在验证集上评估模型性能时计算得到的损失值。它衡量了模型在验证集上的预测误差。通常来说，训练过程中，我们希望看到训练损失（training loss）和验证损失（validation loss）都逐渐降低，这表明模型在不断学习和提高性能。</p>
<p>损失（loss）：是模型预测结果与实际标签之间差异的度量。它通常表示为一个数值，表示模型在进行预测时的“错误程度”。常见的损失函数有均方误差（MSE）、交叉熵损失（Cross-Entropy Loss）等。</p>
<p>验证集：一个与训练集和测试集不同的数据集，通常用于在训练过程中对模型进行评估和调优。验证集用于检查模型的泛化能力——即模型能否在没有见过的数据上表现良好。</p>
<p>注：<strong>如果验证损失开始增加，而训练损失继续降低，可能表明模型在训练数据上过拟合，即模型学习了训练数据中的噪声和不相关的细节，而不是学到了一般性的规律。</strong></p>
<h3 id="social-context-of-a-learning-system"><a href="#social-context-of-a-learning-system" class="headerlink" title="social context of a learning system"></a>social context of a learning system</h3><p>Environment： 在传统的机器学习中，环境通常指的是模型与之交互并从中获取数据的外部系统或空间。例如，在强化学习中，智能体（agent）通过与环境交互来学习和优化其决策策略。在这个语境下，“环境”通常被视为一个相对抽象的、无差别的对象，包含了所有外部因素，模型仅通过这些因素进行训练。</p>
<p>Scarcity：稀缺性指的是资源（如时间、金钱、机会等）在社会中是有限的。在机器学习系统的社交背景下，稀缺性涉及到社会资源的分配问题，如何在有限的资源中做出选择，尤其是在多个利益相关方或群体之间进行权衡。</p>
<p>Conflict：冲突指的是在社会环境中，由于利益、目标或观点的差异，可能会出现对立或争执。在机器学习中，这个概念可以指不同利益相关者之间（如不同用户、群体、公司等）在使用技术时可能产生的矛盾与对立。例如，算法可能会在某些群体之间造成不平等，从而引发冲突。</p>
<p>Social norms：社会规范是指在某一社会群体中广泛接受和遵守的行为标准和价值观。它们定义了个体之间的行为预期。例如，公平性和诚信可能是许多社会群体的核心规范。机器学习系统在部署时需要考虑这些社会规范，以避免做出违反社会价值观的决策。</p>
<p>Communication：在机器学习的社会背景中，沟通通常指的是人与人、人与机器之间的信息交换。在机器学习系统中，沟通可能涉及模型与用户或开发者之间的反馈机制，以及如何有效地传达模型的意图、预测和决策。</p>
<p>Trust： 信任是指个体或群体对系统、技术或他人的可靠性和诚实性的信念。在机器学习系统中，信任至关重要，尤其是在人们需要依赖算法做出决策时。例如，如果用户不信任推荐系统或自动驾驶车辆的决策，那么这些系统的使用将受到限制。信任的缺失可能导致模型的抵制或不使用。</p>
<p>Fairness：公平性是指在决策或资源分配过程中，各方是否受到平等对待。机器学习中的公平性问题通常与算法可能对特定群体或个体产生不公正的偏见有关。例如，性别、种族、年龄等因素可能影响模型的预测结果。解决机器学习中的公平性问题，通常需要确保不同群体在模型中的待遇是平等的，避免不必要的偏见和歧视。</p>
<h3 id="Bi-level-optimization"><a href="#Bi-level-optimization" class="headerlink" title="Bi-level optimization"></a>Bi-level optimization</h3><p>双层优化：一种优化问题，其中的优化过程分为两个层级：上层优化和下层优化。每一层都有自己的优化目标和约束条件，而下层优化的解通常会影响上层优化的目标函数。</p>
<p>上层优化：这是优化问题的“外层”或“主层”，目标是优化一个总体目标，这通常是由下层优化问题的解所决定的。</p>
<p>下层优化：这是优化问题的“内层”或“子问题”，其目标是最小化或最大化一个局部目标。这个问题通常是通过上层优化问题中的参数来定义的，或者说下层优化问题的解是上层优化问题的约束之一。</p>
<p>在元学习中的应用：假设我们有一个双层优化问题，其中上层优化的目标是选择最优的模型参数，而下层优化则通过训练模型来优化模型的性能。这种结构常见于元学习（Meta-learning）和模型调优等问题中。例如，在元学习中，上层优化可能是学习一个优化策略，而下层优化则是针对特定任务的参数优化。</p>
<p>形式化：<br>双层优化问题通常可以用以下数学表达式来表示：</p>
<p>上层问题（Outer problem）：<br>$  \min_{\theta} , F(\theta, \mathbf{z}^*(\theta))$</p>
<p>其中，$\theta$ 是上层优化的决策变量，$\mathbf{z}^*(\theta)$<br>  是下层优化问题的最优解，它依赖于$\theta$。</p>
<p>下层问题（Inner problem）：<br>$  \min_{\mathbf{z}} , G(\mathbf{z}, \theta)$</p>
<p>其中，$\mathbf{z}$ 是下层优化的决策变量，$G(\mathbf{z}, \theta)$ 是下层优化问题的目标函数，$\theta$ 是从上层优化传递下来的参数。</p>
<h3 id="minibatch"><a href="#minibatch" class="headerlink" title="minibatch"></a>minibatch</h3><p>在机器学习和深度学习中，一种将大型数据集分割成较小的子集进行训练的方法。这种方法可以加速训练过程，同时减少计算资源的需求。</p>
<h2 id="词汇"><a href="#词汇" class="headerlink" title="词汇"></a>词汇</h2><p>aggregation：聚合</p>
<p>monotonic：单调的</p>
<p>steer：引导</p>
<p>navigate the issue：解决</p>
<p>validation：验证</p>
<p>emerging applications：新兴应用</p>
<p>lump：整合、混淆</p>
<p>deployment：部署</p>
<p>amplification：扩大、引申</p>
<p>clarity：清晰</p>
<p>align with：保持一致</p>
<p>address：解决</p>
<p>integrate：整合、合并</p>
<p>disparity：不一致</p>
<p>demographic：具有某种特征的群体；人口的</p>
<p>epochs：迭代次数</p>
<p>prevalence：流行、普遍存在</p>
<p>intrinsic：固有的</p>
<p>alignment issues：不一致问题</p>
<p>be derived by：由…推导出</p>
<p>untenable：站不住脚的</p>
<p>circumvent：回避</p>
<p>consensus：共识</p>
<p>intermediate：居中的、中等程度的</p>
<p>feasible：可行的、很可能会发生的</p>

        


        <span>
          <a class="article-read" href="/2025/07/06/Fairness-Aware-Meta-Learning-via-Nash-Bargaining/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/05/25/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/" class="item-title">拜占庭将军问题与计算机系统的一致性</a>
      
      <time datetime="2025-05-25T11:06:55.000Z">
        2025-05-25
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 拜占庭将军问题是什么（它阐述了什么）？对于n个将军，将一个视为指挥将军，其它n-1个视作它的副将，指挥将军会向所有副将发送命令。在此基础上，拜占庭将军问题就是考虑一种算法，确保1）所有忠诚的副将将遵守相同的命令；2）如果指挥将军是忠诚的，则每个忠诚的副将都必须遵循他发送的命令。
如何确保忠诚的将军能够达成一致的行动计划？对于只能使用口头消息的时候，在叛徒数少于总数的三分之一的时候，忠诚的将军能够按照下面的方法达成一致的行动：我们将第一个发送决策值的将军看错指挥官；在0个叛徒时，指挥官将决策值传递给副将，副将根据接收到的消息，或默认的撤退，直接做出对应的决策；在m个叛徒时，副将们递归地充当新的指挥官，向其它副将传递决策的值，每递归一次认为叛徒数减少一个；所有递归完成后，最终每位将军都会从其它将军哪里收到一系列决策，从这些决策中采取占多数的作为自己的决策即可。
对于使用带签名消息时可以解决任意叛徒数的情况。将军之间每一次发送信息的时候都附带上自己的签名，这样的话只要出现了篡改信息（B收到A签名的Attack，收到A签名+C签名的Rtreat，C是叛徒）或发送误导信息（B收到C签名的Atta -->
        <!-- </div> -->

        
        <h2 id="拜占庭将军问题是什么（它阐述了什么）？"><a href="#拜占庭将军问题是什么（它阐述了什么）？" class="headerlink" title="拜占庭将军问题是什么（它阐述了什么）？"></a>拜占庭将军问题是什么（它阐述了什么）？</h2><p>对于n个将军，将一个视为指挥将军，其它n-1个视作它的副将，指挥将军会向所有副将发送命令。在此基础上，拜占庭将军问题就是考虑一种算法，确保1）所有忠诚的副将将遵守相同的命令；2）如果指挥将军是忠诚的，则每个忠诚的副将都必须遵循他发送的命令。</p>
<h2 id="如何确保忠诚的将军能够达成一致的行动计划？"><a href="#如何确保忠诚的将军能够达成一致的行动计划？" class="headerlink" title="如何确保忠诚的将军能够达成一致的行动计划？"></a>如何确保忠诚的将军能够达成一致的行动计划？</h2><p>对于只能使用口头消息的时候，在叛徒数少于总数的三分之一的时候，忠诚的将军能够按照下面的方法达成一致的行动：我们将第一个发送决策值的将军看错指挥官；在0个叛徒时，指挥官将决策值传递给副将，副将根据接收到的消息，或默认的撤退，直接做出对应的决策；在m个叛徒时，副将们递归地充当新的指挥官，向其它副将传递决策的值，每递归一次认为叛徒数减少一个；所有递归完成后，最终每位将军都会从其它将军哪里收到一系列决策，从这些决策中采取占多数的作为自己的决策即可。</p>
<p>对于使用带签名消息时可以解决任意叛徒数的情况。将军之间每一次发送信息的时候都附带上自己的签名，这样的话只要出现了篡改信息（B收到A签名的Attack，收到A签名+C签名的Rtreat，C是叛徒）或发送误导信息（B收到C签名的Attack，A收到C签名的Rtreat，C是叛徒）的情况，可以直接判断出谁是判断。排除或减少一定数量的叛徒之后，就可以进一步协商达成一致的行动。</p>
<h2 id="拜占庭将军问题的解决方案能够应用于哪些计算机领域？"><a href="#拜占庭将军问题的解决方案能够应用于哪些计算机领域？" class="headerlink" title="拜占庭将军问题的解决方案能够应用于哪些计算机领域？"></a>拜占庭将军问题的解决方案能够应用于哪些计算机领域？</h2><p>其解决方案主要应用于确保计算机系统的可靠性。尤其是存在故障组件，向系统的不同部分发送冲突信息的情况。具体的相关领域，可以是我们课堂上了解到的，用于确保分布式系统的一致性，用于保障区块链和加密货币中交易的有效性和账本的一致性等等的要求高可靠性的场景。</p>

        


        <span>
          <a class="article-read" href="/2025/05/25/拜占庭将军问题与计算机系统的一致性/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/05/25/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%8E%9F%E5%AD%90%E6%80%A7%E4%B8%8E%E4%B8%80%E8%87%B4%E6%80%A7/" class="item-title">分布式的原子性与一致性</a>
      
      <time datetime="2025-05-25T04:33:42.000Z">
        2025-05-25
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 一次计算机系统工程导论的习题
问题一选择：A
因为小明的客户端到S3之间的网络经常停止工作，每次几分钟，而根据伪代码，在更新S3服务器上的信息的时候，while循环会一直尝试直到rpc_OK被置为true为止。所以CLENTWRITE通常需要花费几分钟（S3导致的）或更长的时间（可能不排除S1、S2也有出问题的可能性），去更新服务器。
问题二返回：Breakfast
因为在系统没有故障的时候，该分布式系统的一致性是有得到保障的，根据题目中串行执行的代码，读取到的内容会是最后一次写入的内容，对应为Breakfast。
问题三选择：AB
对于A，如果客户端计算机是在已经完成最后一次CLENTWRITE操作中对部分服务器的更新，那么当使用CLIENTREAD的时候就可能出现A的结果。
对于B，如果是在CLIENTWRITE (0,11, “Talk to Frans at 11”)刚刚完成的时候，发生了重启，那么使用CLIENTREAD就可能出现B的结果。
对于C，Breakfast at 10意味着最后一次更新服务器已经部分完成，这与 Free at 11是矛盾的。
对于D，与C同理，存在 -->
        <!-- </div> -->

        
        <p><code>一次计算机系统工程导论的习题</code></p>
<h2 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h2><p>选择：A</p>
<p>因为小明的客户端到S3之间的网络经常停止工作，每次几分钟，而根据伪代码，在更新S3服务器上的信息的时候，while循环会一直尝试直到rpc_OK被置为true为止。所以CLENTWRITE通常需要花费几分钟（S3导致的）或更长的时间（可能不排除S1、S2也有出问题的可能性），去更新服务器。</p>
<h2 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h2><p>返回：Breakfast</p>
<p>因为在系统没有故障的时候，该分布式系统的一致性是有得到保障的，根据题目中串行执行的代码，读取到的内容会是最后一次写入的内容，对应为Breakfast。</p>
<h2 id="问题三"><a href="#问题三" class="headerlink" title="问题三"></a>问题三</h2><p>选择：AB</p>
<p>对于A，如果客户端计算机是在已经完成最后一次CLENTWRITE操作中对部分服务器的更新，那么当使用CLIENTREAD的时候就可能出现A的结果。</p>
<p>对于B，如果是在CLIENTWRITE (0,11, “Talk to Frans at 11”)刚刚完成的时候，发生了重启，那么使用CLIENTREAD就可能出现B的结果。</p>
<p>对于C，Breakfast at 10意味着最后一次更新服务器已经部分完成，这与 Free at 11是矛盾的。</p>
<p>对于D，与C同理，存在矛盾。</p>
<h2 id="问题四"><a href="#问题四" class="headerlink" title="问题四"></a>问题四</h2><p>选择：ABD</p>
<p>对于A，如果所有服务器顺利更新，对应为A的结果</p>
<p>对于B，如果客户端重启前已经顺利执行完CLIENTWRITE (0,10,”Talk to Frans at 10”)，对应为B的结果。</p>
<p>对于C，CLIENTWRITE (0,10, “Breakfast at 10”)至少已经对部分服务器完成了更新，这意味着CLIENTWRITE (0,11, “Talk to Frans at 11”)已经对服务器完成了更新，那么不应该出现Free at 11，所以C错误</p>
<p>对于D，如果CLIENTWRITE (0,10,”Talk to Frans at 10”)只是对部分服务器完成更新例如S1、S2，那么S3中对应保存的仍然是Free at 10。当执行CLIENTREAD的时候，如果第一次从S1或S2顺利读取了结果，但是第二次S1、S2的网络出现了问题，从S3读取了结果，则可能出现这样的情况。</p>
<h2 id="问题五"><a href="#问题五" class="headerlink" title="问题五"></a>问题五</h2><p>选择：ACD</p>
<p>对于A，如果所有更新与读取都正常，那么得到的会是A的结果。</p>
<p>对于B，在第二次读取的时候还没有尝试过“Z”的写入，不会读取到“Z”，故错误。</p>
<p>对于C，如果第二次更新尝试没有一个服务器成功更新，其它操作均正常，则可能得到C的结果。</p>
<p>对于D，如果第一次更新均正常，第二次更新部分正常例如S1被更新，第三次没有成功更新任何服务器。第一次读取正常，第二次读取从S1读取到了结果，第三次读取从S2或S3读取到结果，则可能出现这样的情况。</p>
<h2 id="问题六"><a href="#问题六" class="headerlink" title="问题六"></a>问题六</h2><p>选择：A</p>
<p>因为小明原本的系统在CLIENTWRITE的时候对每个服务器使用了while循环来确保rpc_OK&#x3D;true，这意味着要么对服务器完成更新，要么客户端一直执行CLIENTWRITE。所以如果顺利读取到三个结果，只能是正确的结果，即A对应的结果，其它情况都不可能出现。</p>

        


        <span>
          <a class="article-read" href="/2025/05/25/分布式的原子性与一致性/"> Read more -->
          </span>
        </div>

        
      </div>
      


      <div id="recent-posts-paginator">
        <a class="extend prev" rel="prev" href="/"> </a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"> </a>
      </div>

    </div>

<aside id="sidebar">
  
  <div class="widget-box">
  	  <div class="widget-box">
    <h3 class="widget-title-friends">friends</h3>
    <div class="widget">
      
    </div>
  </div>

  </div>
  
  <div class="widget-box">
  	

  </div>
  
  <div class="widget-box">
  	
  <div class="widget-box">
    <h3 class="widget-title-tag">tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/unity/" rel="tag">unity</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" rel="tag">分布式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A7%E5%AD%A6/" rel="tag">大学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" rel="tag">操作系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" rel="tag">数据结构与算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95/" rel="tag">智能算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88MTL%EF%BC%89/" rel="tag">机器学习（MTL）</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%85%83%E5%AD%A6%E4%B9%A0%EF%BC%89/" rel="tag">机器学习（元学习）</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%89/" rel="tag">机器学习（强化学习）</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%89/" rel="tag">机器学习（联邦学习）</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E8%81%9A%E7%B1%BB%EF%BC%89/" rel="tag">机器学习（聚类）</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/" rel="tag">计算机基础</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AF%97%E6%AD%8C/" rel="tag">诗歌</a></li></ul>
    </div>
  </div>


  </div>
  
  <div class="widget-box">
  	
  <div class="widget-box">
    <h3 class="widget-title-archive">archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/11/">November 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/10/">October 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/09/">September 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/08/">August 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/07/">July 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/05/">May 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/04/">April 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">February 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li></ul>
    </div>
  </div>

  </div>
  
  <div class="widget-box">
  	
  <div class="widget-box">
    <h3 class="widget-title-post">recent_posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a class="recent_posts-list-link" href="/2025/11/02/%E6%90%AD%E5%BB%BA%E5%90%84%E7%A7%8D%E7%8E%AF%E5%A2%83%E7%9A%84%E8%AE%B0%E5%BD%95/">搭建各种环境的记录</a>
          </li>
        
          <li>
            <a class="recent_posts-list-link" href="/2025/10/24/Npuzzle/">Npuzzle</a>
          </li>
        
          <li>
            <a class="recent_posts-list-link" href="/2025/10/23/OS/">OS</a>
          </li>
        
          <li>
            <a class="recent_posts-list-link" href="/2025/09/30/DBS/">DBS</a>
          </li>
        
          <li>
            <a class="recent_posts-list-link" href="/2025/09/04/csp%E4%B9%A0%E9%A2%98%E9%9B%86/">csp习题集</a>
          </li>
        
      </ul>
    </div>
  </div>

  </div>
  
</aside>

<!-- <div id="paginator"> -->
<!--   <a class="extend prev" rel="prev" href="/"> </a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"> </a> -->
<!-- </div> -->

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });
      </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });
      </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });
    </script>

    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



			</div>
		</div>

		<div id="bottom-outer">
			<div id="bottom-inner">
				Site by 阳生 | 
				Powered by <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a> |
				theme <a target="_blank" rel="noopener" href="https://github.com/fireworks99/hexo-theme-PreciousJoy">PreciousJoy</a>
			</div>
		</div>

		
	</div>





	
	<!-- scripts list from theme config.yml -->
	
	<script src="/js/jquery-3.5.1.min.js"></script>
	
	<script src="/js/PreciousJoy.js"></script>
	
	<script src="/js/highlight.pack.js"></script>
	
	<script src="/js/jquery.fancybox.min.js"></script>
	
	<script src="/js/search.js"></script>
	
	<script src="/js/load.js"></script>
	
	<script src="/js/jquery.mCustomScrollbar.concat.min.js"></script>
	
	<script src="/js/clipboard.min.js"></script>
	
	

	<script>hljs.initHighlightingOnLoad();</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
