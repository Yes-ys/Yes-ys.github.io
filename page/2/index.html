


<!DOCTYPE html>
<html lang="ch">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<title> [ 代码和诗 ]</title>
	
	
	<!-- stylesheets list from _config.yml -->
	
	<link rel="stylesheet" href="/css/PreciousJoy.css">
	
	<link rel="stylesheet" href="/css/top-bar.css">
	
	<link rel="stylesheet" href="/css/menu-outer.css">
	
	<link rel="stylesheet" href="/css/content-outer.css">
	
	<link rel="stylesheet" href="/css/bottom-outer.css">
	
	<link rel="stylesheet" href="/css/atom-one-dark.css">
	
	<link rel="stylesheet" href="/css/recent-posts-item.css">
	
	<link rel="stylesheet" href="/css/article-sidebar-toc.css">
	
	<link rel="stylesheet" href="/css/jquery.fancybox.min.css">
	
	<link rel="stylesheet" href="/css/search.css">
	
	<link rel="stylesheet" href="/css/toc.css">
	
	<link rel="stylesheet" href="/css/sidebar.css">
	
	<link rel="stylesheet" href="/css/archive.css">
	
	<link rel="stylesheet" href="/css/jquery.mCustomScrollbar.min.css">
	
	<link rel="stylesheet" href="/css/Z-last-cover-others.css">
	
	
	
<meta name="generator" content="Hexo 7.3.0"></head>




<body id="wrapper">

	<div id="">
		
		<div id="top-bar">
			
			<div id="avatar-box">
				<img 
				class="avatar"
				src="/images/my-avatar.jpg" //网站头像
				alt="avatar">
			</div>

			<div id="top-bar-text">
				<div id="top-bar-title">
					阳生。
				</div>
				<div id="top-bar-slogan">
					风毛丛劲节，只上尽头竿。
				</div>
			</div>

		</div>

		<div id="menu-outer">
			<div id="menu-inner">
				
				
				<div class="menu-item">
					<a href="/">Home</a>
				</div>
				
				<div class="menu-item">
					<a href="/about">About</a>
				</div>
				
				<div class="menu-item">
					<a href="/archives">Archives</a>
				</div>
				

				<div class="menu-item menu-item-search">
					
  <span class="local-search local-search-google local-search-plugin">
      <input type="search" placeholder="站内搜索" id="local-search-input" class="local-search-input-cls" style="">
      <div id="local-search-result" class="local-search-result-cls"></div>
  </span>
	
				</div>

			</div>
		</div>

		<div id="content-outer">
			<div id="content-inner">

				

<div id="recent-posts-box">

  
  <div id="recent-posts">
    <!-- <h1>Recent Posts</h1> -->
    
    
    <div class="recent-post-item">

      <a href="/2025/05/15/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6MapReduce/" class="item-title">分布式计算框架MapReduce</a>
      
      <time datetime="2025-05-15T10:53:59.000Z">
        2025-05-15
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 这篇blog用于记录我在学习计算机系统工程导论时所做的一次实验。我阅读了一篇论文，其介绍了一种名为MapReduce的模型，它通过键值对来拆解任务同时并行地处理子任务，达到了提高数据吞吐率从而降低时延提高性能的效果。
实验目的主要实验目的如下：

通过实验，理解MapReduce框架的基本原理，掌握MapReduce框架的Map阶段和Reduce阶段的执行流程，以及数据的划分、传输和聚合过程，具备使用MapReduce进行简单的分布式数据处理，并能通过进一步自学进行更为复杂的分布式数据处理，从而掌握使用MapReduce进行大数据处理的基本系统设计能力。
通过程序验证，理解性能优化中的并发技术对时延和吞吐率的影响，掌握用并发技术提升系统性能的设计思想。
通过观察分析，理解系统的可并行性与不可并行性的差异，理解工程实践中的并行不完备问题，通过思考该问题，训练理解和处理工程实践冲突和设计实现差异的思维能力。
通过实验准备和作业提交过程中的论文查阅（MapReduce2004），逐步掌握外文专业文献的检索、学习和应用能力。

实验过程与习题2.1 WordCount问题1：WordCount -->
        <!-- </div> -->

        
        <p><code>这篇blog用于记录我在学习计算机系统工程导论时所做的一次实验。我阅读了一篇论文，其介绍了一种名为MapReduce的模型，它通过键值对来拆解任务同时并行地处理子任务，达到了提高数据吞吐率从而降低时延提高性能的效果。</code></p>
<h2 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h2><p>主要实验目的如下：</p>
<ol>
<li>通过实验，理解MapReduce框架的基本原理，掌握MapReduce框架的Map阶段和Reduce阶段的执行流程，以及数据的划分、传输和聚合过程，具备使用MapReduce进行简单的分布式数据处理，并能通过进一步自学进行更为复杂的分布式数据处理，从而掌握使用MapReduce进行大数据处理的基本系统设计能力。</li>
<li>通过程序验证，理解性能优化中的并发技术对时延和吞吐率的影响，掌握用并发技术提升系统性能的设计思想。</li>
<li>通过观察分析，理解系统的可并行性与不可并行性的差异，理解工程实践中的并行不完备问题，通过思考该问题，训练理解和处理工程实践冲突和设计实现差异的思维能力。</li>
<li>通过实验准备和作业提交过程中的论文查阅（MapReduce2004），<br>逐步掌握外文专业文献的检索、学习和应用能力。</li>
</ol>
<h2 id="实验过程与习题"><a href="#实验过程与习题" class="headerlink" title="实验过程与习题"></a>实验过程与习题</h2><h3 id="2-1-WordCount"><a href="#2-1-WordCount" class="headerlink" title="2.1 WordCount"></a>2.1 WordCount</h3><h4 id="问题1：WordCount的-init-方法的参数是maptask和reducetask，简单地解释一下这两个变量都控制了什么？"><a href="#问题1：WordCount的-init-方法的参数是maptask和reducetask，简单地解释一下这两个变量都控制了什么？" class="headerlink" title="问题1：WordCount的__init__方法的参数是maptask和reducetask，简单地解释一下这两个变量都控制了什么？"></a>问题1：WordCount的__init__方法的参数是maptask和reducetask，简单地解释一下这两个变量都控制了什么？</h4><p>maptask指定了Map阶段的并行任务数（原始数据分块数），在MapReduce模型中会将数据先进行分块处理，然后在每一块上运行一个Map任务，所以这个参数也间接决定了每一个Map任务需要处理的数据量大小。</p>
<p>reducetask指定了Reduce阶段的并行任务数（中间数据分区数），在模型中会先对Map任务处理完成的中间键值对数据进行分区，在每一个区上运行一个Reduce任务，这个参数也间接决定了每个Reduce任务需要处理的数据量大小。</p>
<p>由run方法中线程池使用了这两个参数来启动线程可知，如下图所示。</p>
<p>如图1所示</p>
<h4 id="问题2：简要解释调用run如何触发对WordCount实例的map和reduce方法的调用"><a href="#问题2：简要解释调用run如何触发对WordCount实例的map和reduce方法的调用" class="headerlink" title="问题2：简要解释调用run如何触发对WordCount实例的map和reduce方法的调用"></a>问题2：简要解释调用run如何触发对WordCount实例的map和reduce方法的调用</h4><p>WordCount类继承了MapReduce类，使用<code>wc.run()</code>调用了run方法；</p>
<p>在run方法中使用<code>Pool</code>创建了进程池，并添加了相应的进程数量；</p>
<p>根据maptask、reducetask启动了相应数量的Map和Reduce任务，对应为<code>doMap()</code>和<code>doReduce()</code>函数；（这两个函数相当于MapReduce模型中map和reduce工作结点在调用用户的Map、Reduce函数前所进行的预处理操作）</p>
<p>在doMap函数中调用了<code>Map()</code>，在doReduce函数中调用了<code>Reduce()</code>即WordCount实例的map和reduce方法；</p>
<p>综上，通过run触发了WordCount实例的map和reduce方法的调用。</p>
<p>doMap、doReduce调用Map、Reduce的位置如下图所示。</p>
<p>如图2所示</p>
<h3 id="Map和Reduce"><a href="#Map和Reduce" class="headerlink" title="Map和Reduce"></a>Map和Reduce</h3><h4 id="问题3：WordCount中map方法的参数keyvalue和value代表什么？"><a href="#问题3：WordCount中map方法的参数keyvalue和value代表什么？" class="headerlink" title="问题3：WordCount中map方法的参数keyvalue和value代表什么？"></a>问题3：WordCount中map方法的参数keyvalue和value代表什么？</h4><p>keyvalue代表了当前处理的数据块对应的文本起始位置在整个文本文件中的偏移量。</p>
<p>因为<code>keyvalue = f.readline()</code>，而前面进行Split处理的时候，将整个文本文件按块分割为了多个中间文件，中间文件的起始行由<code>f.write(str(i) + &quot;\n&quot;)</code>记录了当前的偏移<code>i</code>。</p>
<p>value代表了当前处理数据块对应的文本数据。</p>
<p>因为<code>value = f.read()</code>，读取了相应的文本数据赋值给value。</p>
<p>keyvalue、value的赋值情况如下图所示</p>
<p>如图3所示</p>
<h4 id="问题4：WordCount中reduce方法的参数key和keyvalues代表什么？"><a href="#问题4：WordCount中reduce方法的参数key和keyvalues代表什么？" class="headerlink" title="问题4：WordCount中reduce方法的参数key和keyvalues代表什么？"></a>问题4：WordCount中reduce方法的参数key和keyvalues代表什么？</h4><p>每个reduce任务会将自己处理的数据区的键值对按照键聚集起来形成集合，并进行排序。</p>
<p>key代表了当前处理的是第几个键值对集合，keyvalues代表了当前处理的键值对集合中的各个键值对。</p>
<p>注：这里使用“集合”只是形象的表述，由于单词计数的任务特征，实际上同一键值对集合中的各个“元素”都是完全相同的键值对，<code>(str,1)</code>，所以这里的“集合”并不具有“互异性”</p>
<p>key、keyvalues的赋值情况如下图所示。</p>
<p>如图4所示</p>
<h3 id="Map和Reduce的并行"><a href="#Map和Reduce的并行" class="headerlink" title="Map和Reduce的并行"></a>Map和Reduce的并行</h3><h4 id="问题5：doMap有多少调用，doReduce有多少调用？为什么？"><a href="#问题5：doMap有多少调用，doReduce有多少调用？为什么？" class="headerlink" title="问题5：doMap有多少调用，doReduce有多少调用？为什么？"></a>问题5：doMap有多少调用，doReduce有多少调用？为什么？</h4><p>doMap有maptask次调用，doReduce有reducetask次调用。</p>
<p>因为在run方法中，通过线程池的map函数分别按照<code>range(0,self.maptask)</code>和<code>range(0,self.reducetask)</code>分发了maptask个doMap调用、reducetask个doReduce调用。</p>
<h4 id="问题6：假设有足够的内核，哪些调用是并行运行的？"><a href="#问题6：假设有足够的内核，哪些调用是并行运行的？" class="headerlink" title="问题6：假设有足够的内核，哪些调用是并行运行的？"></a>问题6：假设有足够的内核，哪些调用是并行运行的？</h4><p>假设内核是足够的，所有的doMap调用是并行的、所有的doReduce调用是并行的；doMap与doReduce两种调用之间是串行的。</p>
<p>因为doMap由线程池管理的线程一一调用，doReduce同理；而在所有doMap完成之后才开始由线程池管理调用。</p>
<h4 id="问题7：对于maptask和reducetask参数的值，哪一个影响到了程序的运行时间？为什么有的参数不会对程序的运行时间产生影响？（可以通过在代码中创建开始时间和结束时间来计算程序运行时间）"><a href="#问题7：对于maptask和reducetask参数的值，哪一个影响到了程序的运行时间？为什么有的参数不会对程序的运行时间产生影响？（可以通过在代码中创建开始时间和结束时间来计算程序运行时间）" class="headerlink" title="问题7：对于maptask和reducetask参数的值，哪一个影响到了程序的运行时间？为什么有的参数不会对程序的运行时间产生影响？（可以通过在代码中创建开始时间和结束时间来计算程序运行时间）"></a>问题7：对于maptask和reducetask参数的值，哪一个影响到了程序的运行时间？为什么有的参数不会对程序的运行时间产生影响？（可以通过在代码中创建开始时间和结束时间来计算程序运行时间）</h4><p>maptask和reducetask的值理论上都会影响到程序运行的时间。如果有其中之一不会对程序的运行时间产生影响，我认为原因是当前这个参数并非程序运行时间的瓶颈所在。例如当reducetask决定Reduce阶段才是任务执行的瓶颈的时候，增加maptask的数量并不会显著加快程序运行的时间，例如下图中的<strong>2个maptask，2个reducetask和4个maptask，2个reducetask</strong>情况下的对照，可以说明这个问题。</p>
<p>图5（2个maptask，2个reducetask运行情况）</p>
<p>图6（4个maptask，2个reducetask运行情况）</p>
<p>图7（2个maptask，4个reducetask运行情况）</p>
<p>图8（4个maptask，4个reducetask运行情况）</p>
<p>图9（8个maptask，8个reducetask运行情况）</p>
<h2 id="遇到的问题及解决办法"><a href="#遇到的问题及解决办法" class="headerlink" title="遇到的问题及解决办法"></a>遇到的问题及解决办法</h2><p>在进行本次实验的过程中，我主要遇到了以下几个问题：</p>
<ol>
<li><p>在探究WordCount中Map方法的参数keyvalue的时候，我不太理解这个参数存在的意义。虽然通过Split分割文本时，记录了相应的偏移，再在doMap阶段将偏移读入了keyvalue，最终在调用用户的Map的时候将keyvalue传递给了Map方法，但是Map方法并没有使用到keyvalue。所以起初，我认为这个参数没必要存在。后来，我与同学进行了一些讨论，我们发现在MapReduce的文献中，描述该模型的工作规范时，有类似这样的陈述“被分配 map 任务的工作节点读取对应输入分片的内容。它从输入数据中解析出键&#x2F;值对，并将每个对传递给用户定义的 Map 函数。Map 函数产生的中间键&#x2F;值对被缓存在内存中。”于是，我们认为，此处的keyvalue、value对应的正是map任务工作结点解析产生的键值对，后续Map函数将在value中进一步解析产生中间键值对。于是，我们认为此处虽然没有用到keyvalue，但是这是<strong>模型的思想所在</strong>，应当予以规范地保留。</p>
</li>
<li><p>在探究问题7的时候，对于maptask、reducetask的大小和任务执行的快慢，似乎有一些合不上，因为起初我认为应该两个任务分配得越多，并行越多，执行越快。但是可以看到在8个maptask，8个reducetask的情况下，执行时间却是最慢的。于是我查阅相关资料，了解到，这可能有以下几种原因：1）与我的内核数有关，如果系统内核数小于进程数，则会带来频繁地上下文切换，进一步增大时延（这或许就是为什么分配任务数最多的时候，反而最慢的原因）2）Map阶段的输出需要传递给Reduce阶段，如果并行的任务数增加，可能带来更加频繁地数据交换，从而造成I&#x2F;O瓶颈，增大时延（这可能是我单独增大reducetask时，运行变慢的原因）3）最后这个原因比较有趣，我开始完全没有考虑过，即任务之间的负载均衡问题，如果分配数量过多，可能导致有的任务几乎没有数据处理，但是仍然占用了相关的计算机资源，在资源有限的情况下，实际工作的任务分配到的资源减少，同样也会造成执行时间变慢。</p>
</li>
</ol>
<h2 id="课后实验与思考（选做）"><a href="#课后实验与思考（选做）" class="headerlink" title="课后实验与思考（选做）"></a>课后实验与思考（选做）</h2><p>我在原始代码的基础上，新增了一个ReverseIndex类用于替代原来的WordCount类，并在其中添加了类似于先前的Map、Reduce方法。Map方法的主要更改是形成的键值对是(word,offset)，而不再是用于计数的(word,1)，在Reduce中会对中间键值对进行处理，返回的是一个(word,sorted(list))，list中是同一word的各个offset，并且按照从小到大进行了排序。最后再简单处理一下结果，按照word的字典序（a~z），输出前二十组(word,sorted(list))。得到如下图所示的结果。</p>
<p>结果如图10所示</p>
<h2 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h2><p>通过本次实验，在阅读MapReduce文献的基础上，我进一步地理解了这个模型的工作方式，其通过Map、Reduce来便捷地实现任务的并行是模型思想的核心所在，尤其是理解了先前阅读文献时不太理解的map工作阶段、reduce工作阶段和用户的Map、Reduce函数之间的关系以及具体是怎样工作的。此外我还学习到了一些有关Python的知识，例如线程池管理下的简单的多线程编程，还有有关Python类之间继承关系与函数复用的知识。最后我通过课后实验与思考，增强了自己的Python编码能力，同时进一步熟悉了MapReduce的工作方式，收获颇丰。</p>

        


        <span>
          <a class="article-read" href="/2025/05/15/分布式计算框架MapReduce/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/05/11/MapReduce/" class="item-title">MapReduce</a>
      
      <time datetime="2025-05-11T07:41:01.000Z">
        2025-05-11
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 这篇blog用于记录，我在学习计算机系统工程导论，有关性能的章节时，阅读的一篇叫做MapReduce的论文
工程师提出MapReduce的编程模型和实现，他们的性能目标是什么？他们的性能目标是通过MapReduce实现大规模数据专用计算的自动并行化，使得缺少并行与分布式系统经验的程序员可以轻松利用大规模分布式系统资源，从而突破数据处理的时延这一性能瓶颈。
Google是怎么通过实现去满足这些目标的？MapReduce程序主要有用户部分和库部分，前者根据用户的业务逻辑需要在后者的基础上进行编写，而相关的并行化、容错、本地优化和负载均衡的细节被隐藏在后者中。整个系统的工作流程是：MapReduce库分割输入文件为较小块，并启动程序运行于机器集群之上；主结点根据块的分割情况，将map、reduce任务分配给各个机器处理；map任务通过用户的MAP函数建立相应的键值对；reduce任务将map任务处理的结果进行排序从而组合相同键，再通过用户的Reduce进行处理。这样的程序系统可以运行于廉价的PC集群之上，可以显著减少时延。
基于此，Google使用MapReduce程序来进行自己业务要求的实 -->
        <!-- </div> -->

        
        <p><code>这篇blog用于记录，我在学习计算机系统工程导论，有关性能的章节时，阅读的一篇叫做MapReduce的论文</code></p>
<h2 id="工程师提出MapReduce的编程模型和实现，他们的性能目标是什么？"><a href="#工程师提出MapReduce的编程模型和实现，他们的性能目标是什么？" class="headerlink" title="工程师提出MapReduce的编程模型和实现，他们的性能目标是什么？"></a>工程师提出MapReduce的编程模型和实现，他们的性能目标是什么？</h2><p>他们的性能目标是通过MapReduce实现大规模数据专用计算的自动并行化，使得缺少并行与分布式系统经验的程序员可以轻松利用大规模分布式系统资源，从而突破数据处理的时延这一性能瓶颈。</p>
<h2 id="Google是怎么通过实现去满足这些目标的？"><a href="#Google是怎么通过实现去满足这些目标的？" class="headerlink" title="Google是怎么通过实现去满足这些目标的？"></a>Google是怎么通过实现去满足这些目标的？</h2><p>MapReduce程序主要有用户部分和库部分，前者根据用户的业务逻辑需要在后者的基础上进行编写，而相关的并行化、容错、本地优化和负载均衡的细节被隐藏在后者中。整个系统的工作流程是：MapReduce库分割输入文件为较小块，并启动程序运行于机器集群之上；主结点根据块的分割情况，将map、reduce任务分配给各个机器处理；map任务通过用户的MAP函数建立相应的键值对；reduce任务将map任务处理的结果进行排序从而组合相同键，再通过用户的Reduce进行处理。这样的程序系统可以运行于廉价的PC集群之上，可以显著减少时延。</p>
<p>基于此，Google使用MapReduce程序来进行自己业务要求的实现：重写了生成Google网页搜索服务所需数据结构的生产索引、生成流行查询报告的数据提取、用于新实验和产品的网页属性提取等等。</p>
<h2 id="MapReduce为什么选择这样实现，而没有走其它技术道路？"><a href="#MapReduce为什么选择这样实现，而没有走其它技术道路？" class="headerlink" title="MapReduce为什么选择这样实现，而没有走其它技术道路？"></a>MapReduce为什么选择这样实现，而没有走其它技术道路？</h2><p>因为许多类型的问题都可以轻松地用MapReduce这种模型进行表示，从而被并行化地计算，所以其泛用性很好；基于这种模型的处理方式具有很强的可拓展性，考虑增加相应的工作结点，就可以用较低的代价换取较高的性能提升，通过合适的Map、Reduce函数也可以带来更加个性化的工作方式；这样的实现充分考虑了故障的可能，以及潜在的风险，并设计了相对应的处理方式，使得其可靠性较强，这一点从文献中提供的相关数据也可以看出。</p>

        


        <span>
          <a class="article-read" href="/2025/05/11/MapReduce/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/05/08/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8D%9A%E5%BC%88%E8%AE%BA%E7%9A%84%E5%A4%8D%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0/" class="item-title">论文精读：基于博弈论的复任务学习</a>
      
      <time datetime="2025-05-08T06:32:32.000Z">
        2025-05-08
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 这篇文献的原名是《Multi-Task Learning as a Bargaining Game》，这是我第一次尝试直接通篇阅读英文原文的文献，中间或许会遇到许多困难。我通过这篇blog来记录阅读的过程中遇到的概念，以及简单地对文章整体的脉络进行梳理。最终我希望对论文提到的算法进行复现，这篇blog将会是一个参考。
概念部分这一部分用于记录阅读时遇到的概念型词汇，并做一些补充解释。困难在于，有的词汇我并不清楚是否是概念型的专业词汇，亦或是只需理解表面含义的词汇...
gradients梯度，包含某函数相对自身所有自变量的偏导数。
对于损失函数$L$梯度$\nabla L$，描述损失函数在参数空间中变化率最快的方向。
在机器学习中，训练的模型时常需要最小化损失函数，这时常用的方法就是梯度下降算法，通过计算损失函数的梯度，模型可以知道应该如何调整参数，从而减小预测误差。
梯度冲突，一个任务的梯度指示减小参数，另一个梯度指示增加参数，相互矛盾，最终得不出一个较好的结果。
multiple MTL benchmarks指的是多个被广泛认可的基准测试数据集或任务，这些任务用于评估多任务学习模型 -->
        <!-- </div> -->

        
        <p><code>这篇文献的原名是《Multi-Task Learning as a Bargaining Game》，这是我第一次尝试直接通篇阅读英文原文的文献，中间或许会遇到许多困难。我通过这篇blog来记录阅读的过程中遇到的概念，以及简单地对文章整体的脉络进行梳理。最终我希望对论文提到的算法进行复现，这篇blog将会是一个参考。</code></p>
<h2 id="概念部分"><a href="#概念部分" class="headerlink" title="概念部分"></a>概念部分</h2><p><code>这一部分用于记录阅读时遇到的概念型词汇，并做一些补充解释。困难在于，有的词汇我并不清楚是否是概念型的专业词汇，亦或是只需理解表面含义的词汇...</code></p>
<h3 id="gradients"><a href="#gradients" class="headerlink" title="gradients"></a>gradients</h3><p>梯度，包含某函数相对自身所有自变量的偏导数。</p>
<p>对于损失函数$L$梯度$\nabla L$，描述损失函数在参数空间中变化率最快的方向。</p>
<p>在机器学习中，训练的模型时常需要最小化损失函数，这时常用的方法就是梯度下降算法，通过计算损失函数的梯度，模型可以知道应该如何调整参数，从而减小预测误差。</p>
<p>梯度冲突，一个任务的梯度指示减小参数，另一个梯度指示增加参数，相互矛盾，最终得不出一个较好的结果。</p>
<h3 id="multiple-MTL-benchmarks"><a href="#multiple-MTL-benchmarks" class="headerlink" title="multiple MTL benchmarks"></a>multiple MTL benchmarks</h3><p>指的是多个被广泛认可的基准测试数据集或任务，这些任务用于评估多任务学习模型的性能。这些基准测试可以涵盖不同的应用领域，如自然语言处理、计算机视觉、语音识别等。</p>
<p>benchmark本意是基准</p>
<ol>
<li><p>QM9：QM9是一个化学分子数据集，主要用于分子性质预测任务。它包含了约13万条小分子的数据，每个分子都由其原子结构表示，同时提供了9个分子性质的标签（例如，分子的能量、分子的极化率、分子的稳定性等）。这些性质是通过量子力学计算方法（例如密度泛函理论，DFT）得到的。在化学领域，QM9数据集被广泛用于评估各种机器学习模型在分子性质预测任务上的表现。这个数据集是一个相对复杂的回归问题，用于测试模型在不同分子特征下的泛化能力。</p>
</li>
<li><p>MT10：MT10数据集是一个多任务学习（MTL）基准数据集，通常用于多任务学习研究的测试。它包含了10个任务，这些任务可以是不同的机器学习任务（例如，分类任务、回归任务等），目标是评估模型在同时处理多个任务时的表现。每个任务都共享一些特征，但每个任务有不同的输出目标，因此适合用于测试多任务学习方法的性能。</p>
</li>
</ol>
<h3 id="Cooperative-bargaining-game"><a href="#Cooperative-bargaining-game" class="headerlink" title="Cooperative bargaining game"></a>Cooperative bargaining game</h3><p>合作博弈，是一种博弈论中的模型，旨在分析参与者如何在合作的情况下进行资源分配或达成协议。</p>
<p>在多任务学习（MTL）的上下文中，将梯度组合视为一个合作博弈意味着：</p>
<ol>
<li>多个任务：每个任务可以看作一个玩家，它们通过共享知识和信息来提高整体性能。</li>
<li>梯度组合：不同任务的梯度可以被看作是不同玩家的“要求”，通过合作来找到一个能有效结合这些梯度的方式，从而优化模型的表现。</li>
<li>协商一致：通过合作博弈的方法，任务之间可以“协商”如何平衡彼此的梯度，以减少冲突并提高整体性能。</li>
</ol>
<h3 id="Proportionally-fair"><a href="#Proportionally-fair" class="headerlink" title="Proportionally fair"></a>Proportionally fair</h3><p>（按比例公平）是一个博弈论和分配理论中的概念，主要用于描述一种资源分配或收益分配的方法。在这种分配方式下，任何替代方案的平均相对变化都是负的，这意味着在分配中没有任何参与者会因为其他参与者的利益而遭受显著的损失。</p>
<p>用于MTL中可以：避免主导效应，通过按比例公平的更新，可以确保没有单一任务的梯度（特别是那些较大的梯度）主导更新过程。这可以防止某个任务的影响过大，导致模型在其他任务上的性能下降。<br><strong>Nash bargaining solution就是一种按比例公平的方法</strong></p>
<h3 id="convex"><a href="#convex" class="headerlink" title="convex"></a>convex</h3><p>convex，字面含义是凸性</p>
<p>凸集：<br>一个集合 $C$ 被称为 凸集，如果对于集合中的任意两个点 $x_1$和 $x_2$，连接这两个点的线段上的所有点也都在集合 $C$ 中。在数学上可以表示为：</p>
<p>$\forall x_1, x_2 \in C, \forall \lambda \in [0, 1], \quad \lambda x_1 + (1 - \lambda) x_2 \in C$</p>
<p>凸函数：<br>一个函数 $f: \mathbb{R}^n \to \mathbb{R}$被称为 凸函数，如果其定义域是一个凸集，并且对于任意的 $x_1, x_2$和 $\lambda \in [0, 1]$，都有：<br>$f(\lambda x_1 + (1 - \lambda) x_2) \leq \lambda f(x_1) + (1 - \lambda) f(x_2)$<br>这表示函数的图形在任意两个点之间的连线不会低于函数的值，换句话说，函数呈一个“碗”的形状。<strong>这与我在大一选修工科数学分析学到的相同，当时老师强调了凸有两种含义，显然这里是下凸上凹的那一种。</strong></p>
<p>凸性的性质：<br>局部极小值即全局极小值：对于凸函数，如果在某一点有局部极小值，那么该点也是全局极小值。这是凸优化中非常重要的性质。</p>
<p>非凸的情况：<br>与凸函数相对的是 非凸函数，这些函数可能存在多个局部极小值，这使得优化过程更为复杂。在非凸情况下，找到全局最优解可能更具挑战性。</p>
<h3 id="帕累托最优"><a href="#帕累托最优" class="headerlink" title="帕累托最优"></a>帕累托最优</h3><p>多目标优化中解的支配关系：如果解$x$支配$x’$则，$x$在$(l_1,l_2,…,l_k)$的目标函数向量上，有1个或多个分量的结果优于$x’$。</p>
<p>Pareto Optimal：如果在多目标任务的定义域中对于解$x$没有支配自己的其它解，则称该解为帕累托最优</p>
<p>Local Pareto Optimal：在定义域的子集开集中的帕累托最优，称为帕累托局部最优</p>
<p>Pareto Stationary：如果解空间中一个点$x$是帕累托静止点，那么在该点上对于多目标对应的各个函数存在梯度凸组合为0。这意味着在该点的所有目标函数的梯度（导数）在某种程度上是平衡的，没有明显的“倾斜”方向可以改进所有目标。</p>
<p><strong>Pareto stationarity 是 Pareto optimality 的必要条件，但不是充分条件。这意味着一个点如果是 Pareto 最优的，那么它必须是 Pareto stationary 的，但反过来则不一定成立。</strong></p>
<p>凸组合：是指在数学和优化中，利用给定点的加权平均来形成新点的一种方法。具体来说，给定一组点 $x_1, x_2, \ldots, x_n$和对应的非负权重 $\lambda_1, \lambda_2, \ldots, \lambda_n$，如果这些权重的总和为 1，即</p>
<p>$\lambda_1 + \lambda_2 + \ldots + \lambda_n &#x3D; 1$<br><strong>注意这些权重都是非负的</strong></p>
<p>那么我们可以定义一个凸组合 $x$ 为：</p>
<p>$x &#x3D; \lambda_1 x_1 + \lambda_2 x_2 + \ldots + \lambda_n x_n$</p>
<p>凸组合的几何意义：在几何上，凸组合可以被视为在给定点之间的“插值”。例如，在二维空间中，两个点的凸组合会形成这两个点之间的线段，而三个点的凸组合则会形成这三点构成的三角形内部的所有点。</p>
<p>在多目标优化中，凸组合常用于表示不同目标之间的权衡。</p>
<h3 id="一些衡量MTL模型性能的指标"><a href="#一些衡量MTL模型性能的指标" class="headerlink" title="一些衡量MTL模型性能的指标"></a>一些衡量MTL模型性能的指标</h3><p>1)Segmentation（语义分割）</p>
<p>mIoU：平均交并比。这个指标是语义分割中常用的评价标准，计算方式是每个类别的交并比（IoU，Intersection over Union）取平均。交并比是预测结果和真实标签之间的交集与并集的比值。这个指标反映了模型在每个类别上的分割准确性，<strong>值越大表示分割结果越好</strong>。</p>
<p>Pix Acc：像素准确率。这个指标计算的是正确分类的像素点占总像素点的比例。它是一个比较简单的衡量标准，但可能在类别不均衡时会有偏差。</p>
<p>2)Depth（深度估计）相对误差</p>
<p>Abs Err：绝对误差。对于每个像素点，计算其预测深度值和真实深度值之间的差异的绝对值，然后取平均。这个指标越小，表示深度估计越准确。</p>
<p>Rel Err：计算预测深度值与真实深度值之间的相对差异，通常表示为：<br>$  \text{Rel Err} &#x3D; \frac{| \hat{d} - d |}{d} $</p>
<p>3)Surface Normal（表面法线）</p>
<p>Angle Distance：角度距离。这个指标计算的是预测法线方向与真实法线方向之间的角度差异。通常以度数（°）表示，<strong>值越小表示模型的法线估计越准确</strong>。</p>
<p>Within（Within Threshold）：通常指的是预测的法线与真实法线之间的角度差异小于某个阈值的比例。例如，如果设定阈值为$\theta$（例如11.25°、22.5°等），则“Within $\theta$”表示法线估计误差小于该阈值的像素所占比例。这个<strong>指标反映了模型能够准确预测法线的比例</strong>。</p>
<p>4)MR（Mean Rank）</p>
<p>**MR(Mean Rank)**是一个排名相关的指标，常用于排序问题。它通常计算的是模型对预测结果的排名准确度。例如，如果模型的预测最接近真实值，那么它会在排名中处于较高的位置。Mean Rank是计算多个任务或样本的平均排名值。</p>
<p>5)Δm%</p>
<p>Delta m%（Δm%）表示相对于基线模型的性能提升或下降百分比。计算方式通常是：<br>$  \Delta m% &#x3D; \frac{(\text{new performance} - \text{baseline performance})}{100}$</p>
<h3 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h3><p>张量的定义<br>在数学上，张量是一个多维数组，扩展了标量、向量和矩阵的概念。具体来说：</p>
<p>标量（Scalar）: 零阶张量，即一个单一的数值。<br>向量（Vector）: 一阶张量，即一维数组，具有方向和大小。<br>矩阵（Matrix）: 二阶张量，即二维数组，具有行和列的结构。<br>高阶张量（Higher-order Tensor）: 三维及以上的多维数组。</p>
<p>机器学习与深度学习: 训练数据和模型参数通常可以表示为高维张量。比如在深度学习框架（如TensorFlow和PyTorch）中，数据和权重都是以张量的形式存储和操作的。</p>
<h3 id="字面词汇"><a href="#字面词汇" class="headerlink" title="字面词汇"></a>字面词汇</h3><p>alleviate，缓解</p>
<p>negotiate，协商</p>
<p>heuristic，启发式方法</p>
<p>convergence，收敛</p>
<h3 id="文章架构"><a href="#文章架构" class="headerlink" title="文章架构"></a>文章架构</h3><p>这篇文章引入博弈论中的Nash bargaining solution，作为MTL中的aggregation algorithm，对多任务的梯度进行整合，减小gradients conflicts带来的性能影响。</p>
<p>总的来看，文章分为以下几个部分：</p>
<ol>
<li>改进Nash bargaining solution以适应MTL</li>
<li>从理论上对算法进行分析，保证了在convex和non-convex的case下的收敛</li>
<li>在多个领域对算法进行了验证</li>
</ol>
<h3 id="改进Nash-bargaining-solution以适应MTL"><a href="#改进Nash-bargaining-solution以适应MTL" class="headerlink" title="改进Nash bargaining solution以适应MTL"></a>改进Nash bargaining solution以适应MTL</h3><h4 id="Nash-bargaining-solution"><a href="#Nash-bargaining-solution" class="headerlink" title="Nash bargaining solution"></a>Nash bargaining solution</h4><p><code>这一部分简单介绍纳什协商解(Nash bargaining solution)在谈判博弈(bargaining game)中出现的条件</code></p>
<p><strong>谈判博弈问题是指</strong>$K$名玩家，每个玩家有一个效用函数$u_i:  A \cup {B} \rightarrow \mathbb{R}$，所有玩家都追求自身<strong>效用函数的最大化</strong>。其中$A$是所有<strong>可能达成的协议</strong>的集合，$D$是<strong>不能达成的协议</strong>（并非集合），对应的是无法达成$A$中元素对应协议时，玩家会采用<strong>默认策略</strong></p>
<p>定义收益集合$U$与默认收益$d$如下：</p>
<p>$U &#x3D; {u_1(x),…,u_k(x) : x \in A} \subset \mathbb{R}^{k}$<br>$d &#x3D; (u_1(D),…,u_k(D)) \in \mathbb{R}^{k}$</p>
<p>假设$U$满足以下性质：</p>
<ol>
<li>convex 集合是凸的</li>
<li>compact 集合是紧致的，即集合满足<strong>有界性、闭性</strong>，有界意味着集合 $U$ 的所有元素（即所有的解）都位于某个有限范围内，没有元素可以无限远离原点；闭性意味着集合 $U$ 包含它的边界点，也就是说，集合中的任何极限点都属于集合 $U$。</li>
<li>$U$对应的$k$维空间中至少存在一个点$u &#x3D; (u_1,u_2,…,u_k), u \in U$ strictly dominates $d &#x3D; {d_1,d_2,…,d_k}$，即$\forall i &#x3D; 1,…,k: u_i &gt; d_i$</li>
</ol>
<p><strong>注：</strong>（在效用函数确定的时候，$U$中不同的点是由协议或称博弈问题的解$x$所影响，产生的。所以当直接讨论$u$的时候实际上可以看作是在讨论某个解$x$，如果直接讨论$u_1,u_2…,u_n$而没有其作为“分量”的上下文，也可以将其看作对应的某些解$x_1,x_2,…,x_n$，或者直接称$U$是解的集合，其中的元素$u_1,u_2,…u_n$就是解）</p>
<p>则该问题<strong>存在</strong>唯一的解$x$即<strong>最优的策略、协议</strong>，称为<strong>Nash bargaining solution</strong>，且该类博弈具有如下性质：</p>
<ol>
<li>Pareto optimality：唯一解$x$满足帕累托最优，此处指的是不存在其它任何解$y$，可以使得$(u_1(y),…u_k(y))$支配$(u_1(x),…,u_k(x))$<br><del>（这个性质确保了，在这类博弈问题中具有唯一的最优解，因为没有其它任何解可以通过损害某方的利益，增大另一方的利益。）</del></li>
<li>Symmetry： 对称性，交换玩家的排列顺序，最终得到的解仍然是$x$<br><del>（这个性质确保了，这类博弈问题中没有任何特别的角色存在，player的效用函数只于其“所处位置”有关，而与角色自己没有关系。例如player1、palyer2在博弈中扮演character1、character2，则$x$协议下的效用函数对应$(u_1(x),u_2(x))$，交换玩家位置，player1、player2对应character2、character1，同样协议下的效用函数对应$(u_2(x),u_1(x))，效用函数不会因为player的不同而改变，只与character有关$）</del></li>
<li>Independence of Irrelevant Alternatives (IIA)：不相关选择的独立性，如果在解集合$U$中加入其它<strong>不相关</strong>选项，最优解仍然是$(u_1(x),…,u_k(x))$，不会改变。</li>
<li>Invariance to affine transformation：仿射变换的不变性，将每个效用函数 $u_i(x)$转换为 $u_i(x) &#x3D; c_i u_i(x) + b_i$且 $c_i &gt; 0$，那么如果原始协议的效用是 $(y_1,…,y_k)$，则经过变换后的协议效用将是 $(c_1 y_1 + b_1,…, c_k y_k + b_k)$。</li>
</ol>
<p>你问得非常好！我们来深入讨论：</p>
<hr>
<h3 id="🌟-问题聚焦：第二步结论是否在非最优点也成立？"><a href="#🌟-问题聚焦：第二步结论是否在非最优点也成立？" class="headerlink" title="🌟 问题聚焦：第二步结论是否在非最优点也成立？"></a>🌟 <strong>问题聚焦：第二步结论是否在非最优点也成立？</strong></h3><p>回顾第二步的核心结论：</p>
<blockquote>
<p>最优点的梯度满足</p>
<p>$$<br>$$</p>
</blockquote>
<p>\sum_i \frac{1}{\Delta\theta^\top g_i} g_i &#x3D; \lambda \Delta\theta<br>]</p>
<p>这表示目标函数的梯度是与 $\Delta\theta$ <strong>同方向</strong> 的，即在边界上的最优点，梯度“指向径向”，因为我们正最大化一个函数在球面上的值。</p>
<hr>
<h3 id="✅-这是否对任意（非最优）-Delta-theta-成立？"><a href="#✅-这是否对任意（非最优）-Delta-theta-成立？" class="headerlink" title="✅ 这是否对任意（非最优）$\Delta\theta$ 成立？"></a>✅ <strong>这是否对任意（非最优）$\Delta\theta$ 成立？</strong></h3><p><strong>答案：不成立。</strong></p>
<p>这是一个<strong>必要条件</strong>，只在最优解处成立。原因如下：</p>
<hr>
<h3 id="🔍-细致分析"><a href="#🔍-细致分析" class="headerlink" title="🔍 细致分析"></a>🔍 <strong>细致分析</strong></h3><p>我们最大化的目标函数是：</p>
<p>$$<br>f(\Delta\theta) &#x3D; \sum_i \log(\Delta\theta^\top g_i)<br>\quad \text{subject to } |\Delta\theta| \le \epsilon<br>$$</p>
<p>我们引入拉格朗日乘子来处理这个约束：</p>
<p>$$<br>\mathcal{L}(\Delta\theta, \lambda) &#x3D; \sum_i \log(\Delta\theta^\top g_i) - \lambda (|\Delta\theta|^2 - \epsilon^2)<br>$$</p>
<p>对 $\Delta\theta$ 求梯度并令其为 0：</p>
<p>$$<br>\nabla_{\Delta\theta} \mathcal{L} &#x3D; \sum_i \frac{g_i}{\Delta\theta^\top g_i} - 2\lambda \Delta\theta &#x3D; 0<br>\Rightarrow<br>\sum_i \frac{g_i}{\Delta\theta^\top g_i} &#x3D; 2\lambda \Delta\theta<br>$$</p>
<p>我们之前写的是 $\lambda \Delta\theta$，只是缩放不同（也就是说你可以吸收掉常数 $\lambda$，设 $\lambda’ &#x3D; 2\lambda$）。</p>
<p>所以这 <strong>是一个最优性的一阶必要条件</strong>，只有在最优点（stationary point）处才成立。</p>
<hr>
<h3 id="🧠-类比直觉："><a href="#🧠-类比直觉：" class="headerlink" title="🧠 类比直觉："></a>🧠 <strong>类比直觉：</strong></h3><p>就像你在优化一个函数 $f(x)$，你知道在极值点：</p>
<p>$$<br>\nabla f(x^*) &#x3D; 0<br>$$</p>
<p>但你不能说 <strong>任意点</strong> 的梯度都等于 0，对吧？同理，在这个 constrained optimization 问题中，这个</p>
<p>$$<br>\sum_i \frac{g_i}{\Delta\theta^\top g_i} \propto \Delta\theta<br>$$</p>
<p>的关系只在最优点成立。</p>
<hr>
<h3 id="✅-总结回答"><a href="#✅-总结回答" class="headerlink" title="✅ 总结回答"></a>✅ <strong>总结回答</strong></h3><blockquote>
<p>❓<strong>这个结论是否在非最优点也成立？</strong><br>❌ <strong>不成立</strong>。<br>这是一个一阶最优性条件（来自拉格朗日乘子法），<strong>只在最优点才成立</strong>。在非最优点，梯度方向一般不会刚好与 $\Delta\theta$ 对齐。</p>
</blockquote>
<p>如果你想，我们可以用一个二维例子可视化一下这个方向关系的变化。</p>

        


        <span>
          <a class="article-read" href="/2025/05/08/论文精读：基于博弈论的复任务学习/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/05/07/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB/" class="item-title">高斯混合聚类</a>
      
      <time datetime="2025-05-07T07:16:00.000Z">
        2025-05-07
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 简介高斯混合聚类不同于k-means、LVQ利用原型向量刻画聚类结构，而是利用概率来刻画聚类结构。
简单来说，这种算法认为数据集中的每个样本都符合一个多元高斯分布（多元的原因是样本常是多元向量），如下
所有的样本共同符合“混合高斯分布”。混合高斯分布对应的概率密度函数是所有多元高斯分布密度函数的加权量。
多元高斯分布若$x$服从多元高斯分布，对应概率密度函数为
$p(x) &#x3D; \frac{1}{(2\pi)^{\frac{n}{2}}\lvert \Sigma \rvert^{\frac{1}{2}}}e^{-\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu)}$，其中$x$是样本对应的向量，$\Sigma$是协方差矩阵，$\mu$是期望
为了便于理解，参照一元高斯分布
$\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-1}{2}\frac{(x - \mu)^{2}}{\sigma^{2}}}$
协方差矩阵就对应方差、多元高斯分布中期望对应一元中的期望（只是多元高斯分布中期望是一个多维向量）
所以多元高斯分布的情况，由 -->
        <!-- </div> -->

        
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>高斯混合聚类不同于k-means、LVQ利用原型向量刻画聚类结构，而是利用概率来刻画聚类结构。</p>
<p>简单来说，这种算法认为数据集中的每个样本都符合一个多元高斯分布（多元的原因是样本常是多元向量），如下</p>
<p>所有的样本共同符合“混合高斯分布”。混合高斯分布对应的概率密度函数是所有多元高斯分布密度函数的加权量。</p>
<h3 id="多元高斯分布"><a href="#多元高斯分布" class="headerlink" title="多元高斯分布"></a>多元高斯分布</h3><p>若$x$服从多元高斯分布，对应概率密度函数为</p>
<p>$p(x) &#x3D; \frac{1}{(2\pi)^{\frac{n}{2}}\lvert \Sigma \rvert^{\frac{1}{2}}}e^{-\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu)}$，其中$x$是样本对应的向量，$\Sigma$是协方差矩阵，$\mu$是期望</p>
<p>为了便于理解，参照一元高斯分布</p>
<p>$\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-1}{2}\frac{(x - \mu)^{2}}{\sigma^{2}}}$</p>
<p>协方差矩阵就对应方差、多元高斯分布中期望对应一元中的期望（只是多元高斯分布中期望是一个多维向量）</p>
<p>所以<strong>多元高斯分布的情况，由$\Sigma$和$\mu$唯一确定</strong></p>
<h3 id="混合高斯分布"><a href="#混合高斯分布" class="headerlink" title="混合高斯分布"></a>混合高斯分布</h3><p>将多元高斯分布密度函数记作$p(x|\mu,\Sigma)$</p>
<p>可以定义混合高斯分布如下：</p>
<p>若$x$服从混合高斯分布，整个样本空间对应有k种多元高斯分布，对应概率密度函数$p_M &#x3D; \sum^{k}<em>{i&#x3D;1} \alpha_i p(x|\mu_i,\Sigma_i)$，其中$\alpha$是混合系数，$\alpha_i$对应的实际意义是，选择第$i$个混合成分的概率，所以有$\alpha_i &gt; 0$且$\sum^{k}</em>{i&#x3D;1} \alpha_i &#x3D; 1$；而$p(x|\mu_i,\Sigma_i)$对应第i个混合成分的概率密度</p>
<h3 id="样本属于某混合成分的概率"><a href="#样本属于某混合成分的概率" class="headerlink" title="样本属于某混合成分的概率"></a>样本属于某混合成分的概率</h3><p>令数据集$D &#x3D; {x_1,x_2,…,x_m}$随机变量$z_j \in {1,2,…,k}$，$z_j$表征样本$x_j$属于哪个混合成分。</p>
<p>对于$x_j$并不确定的情况下，$z_j$的先验分布为</p>
<p>$p(z_j &#x3D; i) &#x3D; \alpha_i, i &#x3D; {1,2,…,k}$</p>
<p>根据贝叶斯定理，当$x_j$确定时，$z_j$的后验分布记作$p_M(z_j &#x3D; i|x_j)$，为</p>
<p>$p_M(z_j &#x3D; i|x_j) &#x3D; \frac{p(z_j &#x3D; i)p_M(x_j|z_j &#x3D; i)}{p_M(x_j)}$<br>其中，$p(z_j &#x3D; i) &#x3D; \alpha_i$；$p_M(x_j|z_j &#x3D; i) &#x3D; p(x|\mu_i,\Sigma_i)$，因为当确定$z_j &#x3D; i$时除了$\alpha_i &#x3D; 1$其它$\alpha_1,…\alpha_i-1,\alpha_i+1,…,\alpha_k$均为$0$；而$p_M(x_j)$即混合高斯分布的概率密度函数</p>
<p>将$p_M(z_j &#x3D; i|x_j)$简记作$\gamma_{ji}$，这个概率就是$x_j$的分布为$\mu_i,\Sigma_i$所对应的多元高斯分布的概率。</p>
<p>于是我们可以找到令$\gamma_{ji}$最大的$i \in {1,2,…,k}$，令$\lambda_j &#x3D; argmax_{i \in {1,2,…,k}} \gamma_{ji}$，$\lambda_j$即$x_j$的标签。对于每个都进行相同的操作，整个数据集便可被划分为k个多元高斯分布对应的k个簇。</p>
<h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><h4 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h4><p>对于k-means、LVQ的模型训练实际上就是通过训练集获得对应的原型向量，有了原型向量便有了划分为簇的依据，也就完成了模型的训练。</p>
<p>而对于高斯混合聚类，根据前面的描述，我们划分为簇的重要依据就是$\gamma_{ji}$，进一步说实际上是<strong>计算$\gamma_{ji}$的依据</strong>，根据计算公式可知，这个依据实际上就是决定高斯混合分布的参数$\mu_i,\Sigma_i,\alpha_i, i \in {1,2,…,k}$。</p>
<p><strong>于是训练的目的实际上就是要得到它们的值。</strong></p>
<h4 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h4><p>对于模型参数${(\alpha_i,\mu_i,\Sigma_i)|1 \le i \le k}$，我们采用<strong>极大似然</strong>的方法进行求解。</p>
<p>这里引用南瓜书中的一句话：<br>“对于每个样本$x_j$来说，它出现的概率是$p_M(x_j)$既然现在训练集D中确实出现了$x_j$，我们当然希望待求解的参数${(\alpha_i,\mu_i,\Sigma_i)|1 \le i \le k}$能够使这种可能性$p_M(x_j)$最大”</p>
<p>于是根据极大似然方法，我们令<br>$LL(D) &#x3D; ln(\prod^{m}<em>{j&#x3D;1} p_M(x_j)) &#x3D; \sum^{m}</em>{j&#x3D;1} ln(\sum^k_{i&#x3D;1} \alpha_i \cdot p(x_j|\mu_i,\Sigma_i))$<br>为对数似然函数，将其最大化得到对应的参数，就是我们要求解的模型参数。</p>
<h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><p>经过一系列数学运算，我们可以得得到如下结果：</p>
<p>$\mu_i &#x3D; \frac{\sum^{m}_{j&#x3D;1} \gamma_{ji} x_j}{\sum^{m}_{j&#x3D;1} \gamma_{ji}}$</p>
<p>$\Sigma_i &#x3D; \frac{\sum^{m}_{j&#x3D;1} \gamma_{ji} (x_j - \mu_i)(x_j - \mu_i)^{T}}{\sum^{m}_{j&#x3D;1}} \gamma_{ji}$</p>
<p>$\alpha_i &#x3D; \frac{1}{m} \sum^{m}_{j&#x3D;1} \gamma{ji}$</p>
<p>$i &#x3D; 1,2,…,k$</p>
<p>注意结果当中，每一个参数的计算都要用到$\gamma{ji}$，而问题在于计算$\gamma{ji}$的时候又要用到参数本身，这似乎是一个循环的无从下手的问题。这种情况下，我们利用EM算法来求解。</p>
<h3 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h3><p>EM算法(Expectation-Maximization)称为“期望最大化算法”，这种算法最开始应用于：使用极大似然法对模型参数进行估计，但是已知的样本中存在还没有“观测”的变量，这种变量称为隐变量，它的值是不确定的。</p>
<p>令$X,Z,\Theta$分别为已观测变量集、隐变量集、参数集，则应最大化对数似然$LL(\Theta|X,Z) &#x3D; lnP(X,Z|\Theta)$，但是Z是隐变量，所以无法直接求解。</p>
<p>EM算法可以用于估计隐变量，并在这个过程中对参数做最大似然估计。</p>
<p>其基本的思想是这样的：</p>
<ol>
<li>初始化参数$\Theta$，根据参数去估计隐变量的<strong>概率分布</strong>，并利用此概率分布求得隐变量的<strong>期望</strong>——E步</li>
<li>将隐变量的期望作为我们观测到的隐变量本身，于是此时所有样本都已被观测，对$\Theta$做极大似然估计——M步</li>
</ol>
<p>不断重复上述两个过程——迭代，直到满足退出条件，例如$\Theta$收敛</p>
<p>贴一篇介绍EM算法的博客：<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41554005/article/details/100591525">CSDN</a></p>
<h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p>结合EM算法，整个高斯混合聚类算法流程如下：</p>
<p>输入：</p>
<ol>
<li>样本集$D &#x3D; {x_1,x_2,…,x_m}$</li>
<li>高斯混合成分的个数k（当然也就是希望划分出的簇的个数）</li>
</ol>
<p>过程：</p>
<ol>
<li>初始化高斯混合分布的参数${(\alpha_i,\mu_i,\Sigma_i)|i &#x3D; 1,2…,k}$</li>
<li>repeat：</li>
<li>对每个样本$x_j,j &#x3D; 1,2,…,m$估计其属于第$i,i &#x3D; 1,2,…k$个成分的概率：$\gamma_{ji}$</li>
<li>利用公式<br>$\mu_i &#x3D; \frac{\sum^{m}_{j&#x3D;1} \gamma_{ji} x_j}{\sum^{m}_{j&#x3D;1} \gamma_{ji}}$，<br>$\Sigma_i &#x3D; \frac{\sum^{m}_{j&#x3D;1} \gamma_{ji} (x_j - \mu_i)(x_j - \mu_i)^{T}}{\sum^{m}_{j&#x3D;1}} \gamma_{ji}$，<br>$\alpha_i &#x3D; \frac{1}{m} \sum^{m}_{j&#x3D;1} \gamma{ji}$，$i &#x3D; 1,2,…,k$对参数进行更新</li>
<li>until:收敛条件（达到一定轮数 or 参数收敛）</li>
<li>求解$x_j,j &#x3D; 1,2,…,m$的标记$\lambda_j &#x3D; agrmax_{i &#x3D; 1,2,…,k} \gamma_{ji}$</li>
<li>根据标记划分为对应的簇</li>
</ol>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>Data.py:数据集部分</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">D = [</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0.697</span>, <span class="number">0.460</span>], [<span class="number">0.774</span>, <span class="number">0.376</span>], [<span class="number">0.634</span>, <span class="number">0.264</span>], [<span class="number">0.608</span>, <span class="number">0.318</span>], [<span class="number">0.556</span>, <span class="number">0.215</span>],</span><br><span class="line">    [<span class="number">0.403</span>, <span class="number">0.237</span>], [<span class="number">0.481</span>, <span class="number">0.149</span>], [<span class="number">0.437</span>, <span class="number">0.211</span>], [<span class="number">0.666</span>, <span class="number">0.091</span>], [<span class="number">0.243</span>, <span class="number">0.267</span>],</span><br><span class="line">    [<span class="number">0.245</span>, <span class="number">0.057</span>], [<span class="number">0.343</span>, <span class="number">0.099</span>], [<span class="number">0.639</span>, <span class="number">0.161</span>], [<span class="number">0.657</span>, <span class="number">0.198</span>], [<span class="number">0.360</span>, <span class="number">0.370</span>],</span><br><span class="line">    [<span class="number">0.593</span>, <span class="number">0.042</span>], [<span class="number">0.719</span>, <span class="number">0.103</span>], [<span class="number">0.359</span>, <span class="number">0.188</span>], [<span class="number">0.339</span>, <span class="number">0.241</span>], [<span class="number">0.282</span>, <span class="number">0.257</span>],</span><br><span class="line">    [<span class="number">0.748</span>, <span class="number">0.232</span>], [<span class="number">0.714</span>, <span class="number">0.346</span>], [<span class="number">0.483</span>, <span class="number">0.312</span>], [<span class="number">0.478</span>, <span class="number">0.437</span>], [<span class="number">0.525</span>, <span class="number">0.369</span>],</span><br><span class="line">    [<span class="number">0.751</span>, <span class="number">0.489</span>], [<span class="number">0.532</span>, <span class="number">0.472</span>], [<span class="number">0.473</span>, <span class="number">0.376</span>], [<span class="number">0.725</span>, <span class="number">0.445</span>], [<span class="number">0.446</span>, <span class="number">0.459</span>]</span><br><span class="line">]  <span class="comment"># 数据集，1~30，0索引不使用</span></span><br></pre></td></tr></table></figure>

<p>main.py:主函数部分</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Gauss</span><br><span class="line"><span class="keyword">import</span> Data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;高斯混合聚类 的结果&quot;</span>, end=<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    res = Gauss.gauss(Data.D)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">len</span>(res[i]), end=<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(res[i])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Guass.py:高斯混合聚类算法部分</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multi_gauss_distri_p</span>(<span class="params">sigma, mu, n, x</span>):</span><br><span class="line">    <span class="comment"># 计算多元高斯分布下取得x的概率，n是维度</span></span><br><span class="line">    vec_mu = np.array(mu)</span><br><span class="line">    vec_x = np.array(x)</span><br><span class="line">    t1 = vec_x - vec_mu</span><br><span class="line">    <span class="comment">#    t1 = t1.T</span></span><br><span class="line">    det_sigma = np.linalg.det(sigma)</span><br><span class="line">    <span class="keyword">if</span>(det_sigma &lt; <span class="number">1e-10</span>):  <span class="comment"># 当行列式过小时，添加一个较小的正则化项</span></span><br><span class="line">        sigma += np.eye(sigma.shape[<span class="number">0</span>]) * <span class="number">1e-6</span>  <span class="comment"># 添加正则化，避免奇异矩阵</span></span><br><span class="line">    t2 = np.linalg.inv(sigma)</span><br><span class="line">    t3 = vec_x - vec_mu</span><br><span class="line">    t3 = t3.T  <span class="comment"># 西瓜书上的公式里没有转置的向量默认是列向量</span></span><br><span class="line">    log_p = -<span class="number">0.5</span> * (np.dot(np.dot(t1, t2), t3) + np.linalg.slogdet(sigma)[<span class="number">1</span>] + n * np.log(<span class="number">2</span> * np.pi))</span><br><span class="line">    p = np.exp(log_p)</span><br><span class="line"><span class="comment">#    p = 1 / ((2 * np.pi) ** (n / 2) * np.linalg.det(sigma) ** (1 / 2)) * np.e ** (-0.5 * np.dot(np.dot(t1, t2), t3)</span></span><br><span class="line"><span class="comment">#    print(&quot;p:&quot;, p, end=&quot;\n&quot;)</span></span><br><span class="line">    <span class="keyword">if</span> p &lt; <span class="number">1e-10</span>:</span><br><span class="line">        p = <span class="number">1e-6</span>  <span class="comment"># 避免数值问题</span></span><br><span class="line">    <span class="keyword">return</span> p</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">new_mu_i</span>(<span class="params">D, lamda_, i</span>):</span><br><span class="line">    up_sum = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    down_sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">31</span>):</span><br><span class="line">        up_sum[<span class="number">0</span>] += lamda_[j][i] * D[j][<span class="number">0</span>]</span><br><span class="line">        up_sum[<span class="number">1</span>] += lamda_[j][i] * D[j][<span class="number">1</span>]</span><br><span class="line">        down_sum += lamda_[j][i]</span><br><span class="line">    new_mu = [up_sum[<span class="number">0</span>] / down_sum, up_sum[<span class="number">1</span>] / down_sum]</span><br><span class="line">    <span class="keyword">return</span> new_mu</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">new_sigma_i</span>(<span class="params">D, mu, lamda_, i</span>):</span><br><span class="line">    vec_x = np.array(D[i])</span><br><span class="line">    vec_mu = np.array(mu)</span><br><span class="line">    up_sum = np.array([[<span class="number">0.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]])</span><br><span class="line">    down_sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">31</span>):</span><br><span class="line">        t = vec_x - vec_mu</span><br><span class="line">        up_sum += lamda_[j][i] * (np.outer(t.T, t))</span><br><span class="line">        down_sum += lamda_[j][i]</span><br><span class="line">    new_sigma = up_sum / down_sum</span><br><span class="line">    <span class="keyword">return</span> new_sigma</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">new_alpha_i</span>(<span class="params">lambda_, i</span>):</span><br><span class="line">    up_sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">31</span>):</span><br><span class="line">        up_sum += lambda_[j][i]</span><br><span class="line">    new_alpha = up_sum / <span class="number">30</span></span><br><span class="line">    <span class="keyword">return</span> new_alpha</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gauss</span>(<span class="params">D: [[<span class="built_in">float</span>]]</span>):</span><br><span class="line">    <span class="comment">#  定义混合高斯分布参数</span></span><br><span class="line">    sigma = []  <span class="comment"># 协方差矩阵</span></span><br><span class="line">    alpha = []  <span class="comment"># 混合权重</span></span><br><span class="line">    mu = []  <span class="comment"># 期望</span></span><br><span class="line">    <span class="comment">#  初始化参数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>):</span><br><span class="line">        sigma.append(np.array([[<span class="number">0.1</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.1</span>]]))</span><br><span class="line">        alpha.append(<span class="number">1</span>/<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            mu.append(D[<span class="number">6</span>])</span><br><span class="line">        <span class="keyword">elif</span> i == <span class="number">1</span>:</span><br><span class="line">            mu.append(D[<span class="number">22</span>])</span><br><span class="line">        <span class="keyword">elif</span> i == <span class="number">2</span>:</span><br><span class="line">            mu.append(D[<span class="number">27</span>])</span><br><span class="line">    <span class="comment">#  定义xj属于第i种多元高斯分布的概率</span></span><br><span class="line">    lambda_ = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">31</span>):</span><br><span class="line">        lambda_.append([[], [], []])</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">100</span>):  <span class="comment"># 迭代</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">31</span>):  <span class="comment"># 依次对每个xj计算lambda_ji,i = 0，1，2，对应三种多元高斯分布</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>):</span><br><span class="line">                t_sum = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>):</span><br><span class="line">                    t_sum += alpha[l] * multi_gauss_distri_p(sigma[l], mu[l], <span class="number">2</span>, D[j])</span><br><span class="line">                lambda_ji = alpha[i] * multi_gauss_distri_p(sigma[i], mu[i], <span class="number">2</span>, D[j]) / t_sum</span><br><span class="line">                lambda_[j][i] = lambda_ji</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>):  <span class="comment"># 更新混合高斯分布参数</span></span><br><span class="line">            mu[i] = new_mu_i(D, lambda_, i)</span><br><span class="line">            sigma[i] = new_sigma_i(D, mu[i], lambda_, i)</span><br><span class="line">            alpha[i] = new_alpha_i(lambda_, i)</span><br><span class="line"></span><br><span class="line">    result = [[], [], []]  <span class="comment"># 最终的划分结果</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">31</span>):  <span class="comment"># 依次对每个xj计算lambda_ji,i = 0，1，2，对应三种多元高斯分布</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>):</span><br><span class="line">            t_sum = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>):</span><br><span class="line">                t_sum += alpha[l] * multi_gauss_distri_p(sigma[l], mu[l], <span class="number">2</span>, D[j])</span><br><span class="line">            lambda_ji = alpha[i] * multi_gauss_distri_p(sigma[i], mu[i], <span class="number">2</span>, D[j]) / t_sum</span><br><span class="line">            lambda_[j][i] = lambda_ji</span><br><span class="line"></span><br><span class="line">        flag = <span class="number">0</span></span><br><span class="line">        ll = lambda_[j][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>):</span><br><span class="line">            <span class="keyword">if</span> ll &lt; lambda_[j][i]:</span><br><span class="line">                flag = i</span><br><span class="line">        result[flag].append(D[j])</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>进行这一部分的时候让我最大的感悟是，在使用计算机进行数据处理的时候，很可能会出现数据的溢出问题，非常大、非常小的数都在计算机的表示范围之外，就会带来问题。例如在进行协方差矩阵更新的时候，有时它的行列式值虽然不是0，但是已经非常小了，计算机会默认其为0。同样，可能作为除数的数也是一样的，如果太小变为0就会发送除以0的错误。<br><strong>这称为数值稳定性问题</strong></p>
<p>因此代码中有一些涉及处理这些问题的地方（主要是在求第i个多元高斯分布中取得xj这个值的概率的时候，一处是正则化、一处是对数化并添加过小的判断），尽管我现在并不清楚这样处理是否有问题。但是抛开这些细节，作为一次上手的练习，整个混合高斯聚类算法是正确的。<br><strong>不过值得一提的是，EM算法的收敛与迭代的次数没有必然的关系，通常应该使用参数变化的情况来决定是否结束迭代</strong></p>
<p>最后的结果如下：</p>
<blockquote>
<p>高斯混合聚类 的结果<br>2<br>[[0.608, 0.318], [0.359, 0.188]]<br>0<br>[]<br>28<br>[[0.697, 0.46], [0.774, 0.376], [0.634, 0.264], [0.556, 0.215], [0.403, 0.237], [0.481, 0.149], [0.437, 0.211], [0.666, 0.091], [0.243, 0.267], [0.245, 0.057], [0.343, 0.099], [0.639, 0.161], [0.657, 0.198], [0.36, 0.37], [0.593, 0.042], [0.719, 0.103], [0.339, 0.241], [0.282, 0.257], [0.748, 0.232], [0.714, 0.346], [0.483, 0.312], [0.478, 0.437], [0.525, 0.369], [0.751, 0.489], [0.532, 0.472], [0.473, 0.376], [0.725, 0.445], [0.446, 0.459]]</p>
</blockquote>
<p>经过我的观察，第3次迭代之后划分结果基本上就稳定了，第1次的时候分得比较均匀。这或许是数据的原因。（也有可能是我对于数值稳定性的处理不好）</p>
<p>如果将正则化项改大一些结果如下：</p>
<blockquote>
<p>高斯混合聚类 的结果<br>12<br>[[0.608, 0.318], [0.556, 0.215], [0.403, 0.237], [0.481, 0.149], [0.437, 0.211], [0.243, 0.267], [0.245, 0.057], [0.343, 0.099], [0.359, 0.188], [0.339, 0.241], [0.282, 0.257], [0.483, 0.312]]<br>10<br>[[0.634, 0.264], [0.666, 0.091], [0.639, 0.161], [0.657, 0.198], [0.593, 0.042], [0.719, 0.103], [0.748, 0.232], [0.714, 0.346], [0.751, 0.489], [0.725, 0.445]]<br>8<br>[[0.697, 0.46], [0.774, 0.376], [0.36, 0.37], [0.478, 0.437], [0.525, 0.369], [0.532, 0.472], [0.473, 0.376], [0.446, 0.459]]</p>
</blockquote>

        


        <span>
          <a class="article-read" href="/2025/05/07/高斯混合聚类/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/05/06/%E5%AD%A6%E4%B9%A0%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96/" class="item-title">学习向量量化</a>
      
      <time datetime="2025-05-06T15:22:52.000Z">
        2025-05-06
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 这篇blog用于记录我使用python对学习向量量化这种聚类算法的复现
算法简介学习向量量化也成为LVQ(Learning Vector Quantization)，同样属于原型聚类算法，类似于k-means通过希望划分的簇的数量求得相同数量的“簇中心”并以此为原型将数据集划分为对应的簇，LVQ通过求得与希望划分的簇数量相同的“原型向量”，并以此来将数据集划分为对应的簇。
如果说k-means也同样是借助原型向量的话，那么关键就在于两种算法更新原型向量的方法不同。k-means是不断的用原型向量划分簇，又用簇更新原型向量；LVQ则是利用样本的预先标注作为“监督信息”，不断利用样本更新原型向量。
算法详解整个算法的大致流程如下：
输入: $D &#x3D; {(x_1,y_1),(x_2,y_2),…,(x_m,y_m)}, q, {t_1,t_2,…,t_q},\eta \in (0,1)$其中，D是带有标记的数据集，q是原型向量个数，$t_i,i \in {1,2,…,q}$ 对应原型向量的标记，$\eta$是学习率
算法过程：

初始化原型向量${p_1,p_2,…,p_q}$
r -->
        <!-- </div> -->

        
        <p><code>这篇blog用于记录我使用python对学习向量量化这种聚类算法的复现</code></p>
<h2 id="算法简介"><a href="#算法简介" class="headerlink" title="算法简介"></a>算法简介</h2><p>学习向量量化也成为LVQ(Learning Vector Quantization)，同样属于原型聚类算法，类似于k-means通过希望划分的簇的数量求得相同数量的“簇中心”并以此为原型将数据集划分为对应的簇，LVQ通过求得与希望划分的簇数量相同的“原型向量”，并以此来将数据集划分为对应的簇。</p>
<p>如果说k-means也同样是借助原型向量的话，那么关键就在于两种算法更新原型向量的方法不同。k-means是不断的用原型向量划分簇，又用簇更新原型向量；LVQ则是利用样本的预先标注作为“监督信息”，不断利用样本更新原型向量。</p>
<h2 id="算法详解"><a href="#算法详解" class="headerlink" title="算法详解"></a>算法详解</h2><p>整个算法的大致流程如下：</p>
<p>输入: $D &#x3D; {(x_1,y_1),(x_2,y_2),…,(x_m,y_m)}, q, {t_1,t_2,…,t_q},\eta \in (0,1)$其中，D是带有标记的数据集，q是原型向量个数，$t_i,i \in {1,2,…,q}$ 对应原型向量的标记，$\eta$是学习率</p>
<p>算法过程：</p>
<ol>
<li>初始化原型向量${p_1,p_2,…,p_q}$</li>
<li>repeat:</li>
<li>从$D$中随机挑选一个样本$(x_j,y_j)$</li>
<li>找到与$x_j$最近的原型向量$p_i^{*}$</li>
<li>if($t_i^{*}$ &#x3D;&#x3D; $y_j$): $p’ &#x3D; p_i^{*} + \eta(p_i^{*} - x_j)$</li>
<li>else: $p’ &#x3D; p_i^{*} - \eta(p_i^{*} - x_j)$</li>
<li>判断是否到达退出条件</li>
</ol>
<p>整个算法过程的关键就在于5、6，实际上相当于找到距离原型向量最近的样本，如果是同标记的则将该原型向量向该样本“拉近”，如果是不同标记的则“推远”（因为对应的是同标记的在一个簇中可能性较大，不同标记在不同簇中可能性较大）</p>
<p>关于7的退出条件，通常可以设置一个最大迭代轮数，或者是原型向量的更新程度已经小于了一个阈值。</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>使用python对西瓜书上的示例复现代码如下（30个样本，9-21号样本标记为2，其它样本标记为1，随机选择5个样本作为原始向量，标记分别为1、2、2、1、1，学习率为0.1）</p>
<p>Data.py数据集部分:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">D = [</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0.697</span>, <span class="number">0.460</span>], [<span class="number">0.774</span>, <span class="number">0.376</span>], [<span class="number">0.634</span>, <span class="number">0.264</span>], [<span class="number">0.608</span>, <span class="number">0.318</span>], [<span class="number">0.556</span>, <span class="number">0.215</span>],</span><br><span class="line">    [<span class="number">0.403</span>, <span class="number">0.237</span>], [<span class="number">0.481</span>, <span class="number">0.149</span>], [<span class="number">0.437</span>, <span class="number">0.211</span>], [<span class="number">0.666</span>, <span class="number">0.091</span>], [<span class="number">0.243</span>, <span class="number">0.267</span>],</span><br><span class="line">    [<span class="number">0.245</span>, <span class="number">0.057</span>], [<span class="number">0.343</span>, <span class="number">0.099</span>], [<span class="number">0.639</span>, <span class="number">0.161</span>], [<span class="number">0.657</span>, <span class="number">0.198</span>], [<span class="number">0.360</span>, <span class="number">0.370</span>],</span><br><span class="line">    [<span class="number">0.593</span>, <span class="number">0.042</span>], [<span class="number">0.719</span>, <span class="number">0.103</span>], [<span class="number">0.359</span>, <span class="number">0.188</span>], [<span class="number">0.339</span>, <span class="number">0.241</span>], [<span class="number">0.282</span>, <span class="number">0.257</span>],</span><br><span class="line">    [<span class="number">0.748</span>, <span class="number">0.232</span>], [<span class="number">0.714</span>, <span class="number">0.346</span>], [<span class="number">0.483</span>, <span class="number">0.312</span>], [<span class="number">0.478</span>, <span class="number">0.437</span>], [<span class="number">0.525</span>, <span class="number">0.369</span>],</span><br><span class="line">    [<span class="number">0.751</span>, <span class="number">0.489</span>], [<span class="number">0.532</span>, <span class="number">0.472</span>], [<span class="number">0.473</span>, <span class="number">0.376</span>], [<span class="number">0.725</span>, <span class="number">0.445</span>], [<span class="number">0.446</span>, <span class="number">0.459</span>]</span><br><span class="line">]  <span class="comment"># 数据集，1~30，0索引不使用</span></span><br><span class="line"><span class="comment"># 数据集的标记，LVQ使用</span></span><br><span class="line">T = [</span><br><span class="line">    <span class="number">0</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">    <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">    <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">    <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">]</span><br><span class="line"><span class="comment"># 原始向量标记的输入</span></span><br><span class="line">q_vect = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p>main.py主函数部分：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> K_means</span><br><span class="line"><span class="keyword">import</span> LVQ</span><br><span class="line"><span class="keyword">import</span> Data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(): </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;LVQ 的结果&quot;</span>, end=<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    res = LVQ.lvq(Data.D, Data.T, Data.q_vect)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">len</span>(res[i]) - <span class="number">1</span>, end=<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(res[i]) == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;[]&quot;</span>, end=<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(res[i])):</span><br><span class="line">            <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="built_in">print</span>(res[i][j], end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(res[i]) != <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">        main()</span><br></pre></td></tr></table></figure>

<p>LVQ.py学习向量量化算法部分：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lvq</span>(<span class="params">D:[[<span class="built_in">float</span>]], T:[<span class="built_in">int</span>], q_vect:[]</span>):</span><br><span class="line">l_rate = <span class="number">0.1</span></span><br><span class="line"><span class="keyword">import</span> random <span class="keyword">as</span> rd</span><br><span class="line">q_vec_index = rd.sample(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">31</span>), <span class="number">5</span>)  <span class="comment"># 随机选取5个样本作为原型向量</span></span><br><span class="line">q_vec = []  <span class="comment"># 原型向量</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">    q_vec.append(D[q_vec_index[i]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">10000</span>):  <span class="comment"># 迭代10000轮</span></span><br><span class="line">    j_dex = rd.randint(<span class="number">1</span>,<span class="number">30</span>)  <span class="comment"># 随机挑选一个样本，randint函数的参数是一个闭区间！</span></span><br><span class="line">    q = <span class="number">0</span> <span class="comment"># 距离j_dex最近的原型向量的索引</span></span><br><span class="line">    d = (D[j_dex][<span class="number">0</span>] - q_vec[<span class="number">0</span>][<span class="number">0</span>])**<span class="number">2</span> + (D[j_dex][<span class="number">1</span>] - q_vec[<span class="number">0</span>][<span class="number">1</span>])**<span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">5</span>):</span><br><span class="line">        d_i = (D[j_dex][<span class="number">0</span>] - q_vec[i][<span class="number">0</span>])**<span class="number">2</span> + (D[j_dex][<span class="number">1</span>] - q_vec[i][<span class="number">1</span>])**<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> d_i &lt; d:</span><br><span class="line">            q = i</span><br><span class="line">            d = d_i</span><br><span class="line">    <span class="keyword">if</span> q_vect[q] == T[j_dex]:  <span class="comment"># 将原型向量与样本拉近</span></span><br><span class="line">        q_vec[q][<span class="number">0</span>] = q_vec[q][<span class="number">0</span>] + l_rate*(D[j_dex][<span class="number">0</span>] - q_vec[q][<span class="number">0</span>])</span><br><span class="line">        q_vec[q][<span class="number">1</span>] = q_vec[q][<span class="number">1</span>] + l_rate*(D[j_dex][<span class="number">1</span>] - q_vec[q][<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># 将原型向量与样本推远</span></span><br><span class="line">        q_vec[q][<span class="number">0</span>] = q_vec[q][<span class="number">0</span>] - l_rate * (D[j_dex][<span class="number">0</span>] - q_vec[q][<span class="number">0</span>])</span><br><span class="line">        q_vec[q][<span class="number">1</span>] = q_vec[q][<span class="number">1</span>] - l_rate * (D[j_dex][<span class="number">1</span>] - q_vec[q][<span class="number">1</span>])</span><br><span class="line">result = [[], [], [], [], []]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">    result[i].append(q_vec[i])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">31</span>):</span><br><span class="line">    j = <span class="number">0</span></span><br><span class="line">    d = (D[i][<span class="number">0</span>] - q_vec[j][<span class="number">0</span>])**<span class="number">2</span> + (D[i][<span class="number">1</span>] - q_vec[j][<span class="number">0</span>])**<span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">5</span>):</span><br><span class="line">        d_ = (D[i][<span class="number">0</span>] - q_vec[_][<span class="number">0</span>])**<span class="number">2</span> + (D[i][<span class="number">1</span>] - q_vec[_][<span class="number">1</span>])**<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> d_ &lt; d:</span><br><span class="line">            d = d_</span><br><span class="line">            j = _</span><br><span class="line">    result[j].append(D[i])</span><br><span class="line"><span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>

<p><code>捉个一个虫，py中万物皆对象，在初始化q_vec的时候直接将数据集D中的元素append进去，实际上共享了内存，这会导致更新原型向量的时候，数据集中的元素被更新，解决方案是使用深拷贝</code></p>
<p>修改方法：<br>将q_vec初始化的地方：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">q_vec = []  <span class="comment"># 原型向量</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">    q_vec.append(D[q_vec_index[i]])</span><br></pre></td></tr></table></figure>

<p>更改为：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">q_vec = [x.copy() <span class="keyword">for</span> x <span class="keyword">in</span> (D[i] <span class="keyword">for</span> i <span class="keyword">in</span> q_vec_index)]  <span class="comment"># 关键修复点：使用列表拷贝</span></span><br></pre></td></tr></table></figure>

<p>最终运行结果：</p>
<blockquote>
<p>3<br>[0.36, 0.37] [0.478, 0.437] [0.446, 0.459]<br>8<br>[0.634, 0.264] [0.556, 0.215] [0.666, 0.091] [0.639, 0.161] [0.657, 0.198] [0.593, 0.042] [0.719, 0.103] [0.748, 0.232]<br>9<br>[0.403, 0.237] [0.481, 0.149] [0.437, 0.211] [0.243, 0.267] [0.245, 0.057] [0.343, 0.099] [0.359, 0.188] [0.339, 0.241] [0.282, 0.257]<br>5<br>[0.697, 0.46] [0.774, 0.376] [0.714, 0.346] [0.751, 0.489] [0.725, 0.445]<br>5<br>[0.608, 0.318] [0.483, 0.312] [0.525, 0.369] [0.532, 0.472] [0.473, 0.376]  </p>
</blockquote>
<p>对应为5个簇中样本的数量和相应的样本</p>
<p><code>注：理论上应该将数据集D划分为训练集和测试集，通过训练集训练模型（得到所有合理的原型向量），然后利用测试集测试，利用原型向量将测试集划分为对应数量的簇；这样才能完整地体现“机器学习”，但是这里只是一个简单的例子，将数据集D全用作训练集，得到原型向量，再把整个训练集划分为了对应的簇。</code><br><code>有了原型向量之后，划分为簇是很简单的，样本距离哪个原型向量最近，就纳入对应的簇即可。</code></p>

        


        <span>
          <a class="article-read" href="/2025/05/06/学习向量量化/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/05/06/%E5%85%AD%E7%BA%A7%E8%AF%8D%E6%B1%87/" class="item-title">六级词汇</a>
      
      <time datetime="2025-05-06T02:17:16.000Z">
        2025-05-06
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 这篇博客用于记录我在备考英语六级时所做的词汇准备，目前我已经完成了核心词汇的记忆，我会在这里为这些词汇补充一些例句。目前的打算是每天20个词语，此外我会开始着手阅读、听力以及写译的准备，这篇blog中也会用于记录相应的内容
词汇2025.05.061

stabilize  “How can I stabilize the colour of our love, my dear.”

2

manipulate “Your mean is that you can manipualte such a monster machine.”

3

ambiguous “Don’t treat me with such a ambiguous attitude.”

4

interaction “The relationship forms from the interaction among people little by little.”

5

perception “What’s your perception about our future?”

6

strive “I’l -->
        <!-- </div> -->

        
        <p><code>这篇博客用于记录我在备考英语六级时所做的词汇准备，目前我已经完成了核心词汇的记忆，我会在这里为这些词汇补充一些例句。</code><br><code>目前的打算是每天20个词语，此外我会开始着手阅读、听力以及写译的准备，这篇blog中也会用于记录相应的内容</code></p>
<h2 id="词汇"><a href="#词汇" class="headerlink" title="词汇"></a>词汇</h2><h3 id="2025-05-06"><a href="#2025-05-06" class="headerlink" title="2025.05.06"></a>2025.05.06</h3><p>1</p>
<blockquote>
<p>stabilize  “How can I stabilize the colour of our love, my dear.”</p>
</blockquote>
<p>2</p>
<blockquote>
<p>manipulate “Your mean is that you can manipualte such a monster machine.”</p>
</blockquote>
<p>3</p>
<blockquote>
<p>ambiguous “Don’t treat me with such a ambiguous attitude.”</p>
</blockquote>
<p>4</p>
<blockquote>
<p>interaction “The relationship forms from the interaction among people little by little.”</p>
</blockquote>
<p>5</p>
<blockquote>
<p>perception “What’s your perception about our future?”</p>
</blockquote>
<p>6</p>
<blockquote>
<p>strive “I’ll strive to achieve our happiness in future.”</p>
</blockquote>
<p>7</p>
<blockquote>
<p>expense “How much is the expense of our lives in the month?”</p>
</blockquote>
<p>8</p>
<blockquote>
<p>cater “We will cater for the party.”</p>
</blockquote>
<p>9</p>
<blockquote>
<p>summon “I am trying to summon up the courage to love you.” “He was summoning the elevator.”</p>
</blockquote>
<p>10</p>
<blockquote>
<p>plug “The broken bus pluged the traffic.”</p>
</blockquote>
<p>11</p>
<blockquote>
<p>elaspe “I don’t think our love will elapse.”</p>
</blockquote>
<p>12</p>
<blockquote>
<p>authorize “The law won’t autorize anybody to kill.”</p>
</blockquote>
<p>13</p>
<blockquote>
<p>commentary “With a conception about freedom of expression, the commentraies online are too cynic and dirty sometimes.”</p>
</blockquote>
<p>14</p>
<blockquote>
<p>conservative “Some people are still conservative about sex, which’s treasurable.”</p>
</blockquote>
<p>15</p>
<blockquote>
<p>arson “People would arson to destory all the thing of a witch even her body in the middle centery, however many women called wicth are innocent.”</p>
</blockquote>
<p>16</p>
<blockquote>
<p>litre “How much water should a people to drink a day? 2 litres?”</p>
</blockquote>
<p>17</p>
<blockquote>
<p>vengeance “The lifelong traveling of Gess is to make vengeane.”</p>
</blockquote>
<p>18</p>
<blockquote>
<p>expenditure “He is rigorous in his contorl of expenditure.”</p>
</blockquote>
<p>19</p>
<blockquote>
<p>overwhelm “The fear overwhelmed in his mind.”</p>
</blockquote>
<p>20</p>
<blockquote>
<p>surpass “His achievement supasses anybody.”</p>
</blockquote>
<h3 id="2025-05-07"><a href="#2025-05-07" class="headerlink" title="2025.05.07"></a>2025.05.07</h3><p>1</p>
<blockquote>
<p>visualize “If you can visualize your success, you’ll succeed.”</p>
</blockquote>
<p>2</p>
<blockquote>
<p>tension “For several hours tension mounted.”</p>
</blockquote>
<p>3</p>
<blockquote>
<p>shrewd “She is a shrewd bussinesswoman indeed, however she is a kind mother as well.”</p>
</blockquote>
<p>4</p>
<blockquote>
<p>phase “For our aim of happiness, we are staying the phase of adapating to each other.”</p>
</blockquote>
<p>5</p>
<blockquote>
<p>abject “If you are down to abject poverty, you actually get everything.”</p>
</blockquote>
<p>6</p>
<blockquote>
<p>intense “The fight between Gess and Geri is intense.”</p>
</blockquote>
<p>7</p>
<blockquote>
<p>recruit “His dream is to be recruited as a chairman by Tiktok.”</p>
</blockquote>
<p>8</p>
<blockquote>
<p>abolish “The princess will abolish the man’s title of knight, granting a new title of lover to him.”</p>
</blockquote>
<p>9</p>
<blockquote>
<p>reluctant “I don’t want your hug because you are reluctant.”</p>
</blockquote>
<p>10</p>
<blockquote>
<p>vacant “The room is vacant so you can use it.”</p>
</blockquote>
<p>11</p>
<blockquote>
<p>priest “My priest, listen to my confession. Please.”</p>
</blockquote>
<p>12</p>
<blockquote>
<p>transparent “My heart is just like a transparent river.”</p>
</blockquote>
<p>13</p>
<blockquote>
<p>hamper “Why did you hamper me forever?”</p>
</blockquote>
<p>14</p>
<blockquote>
<p>rust “The blank-red rust grow on the sword, saying the pride from the past.”</p>
</blockquote>
<p>15</p>
<blockquote>
<p>sulphur “Whenever I see the word sulphur, I think of my chemistry teacher Mr.Fu.”</p>
</blockquote>
<p>16</p>
<blockquote>
<p>vivid “The birds on the picture is vivid.”</p>
</blockquote>
<p>17</p>
<blockquote>
<p>intensive “You need to keep intensive when you are taking exam.”</p>
</blockquote>
<p>18</p>
<blockquote>
<p>diagnose “The doctor diagnosed him, saying he just need to take a rest.”</p>
</blockquote>
<p>19</p>
<blockquote>
<p>convict “God will convict you!”</p>
</blockquote>
<p>20</p>
<blockquote>
<p>implement “When will we implement this law?”</p>
</blockquote>
<h3 id="2025-05-08"><a href="#2025-05-08" class="headerlink" title="2025.05.08"></a>2025.05.08</h3><p>1</p>
<blockquote>
<p>vertical “The wall is vertical.”</p>
</blockquote>
<p>2</p>
<blockquote>
<p>clinical “Clinical medicine is a difficuilt subject.”</p>
</blockquote>
<p>3</p>
<blockquote>
<p>thrill “When she heared sound like this, she thrilled from the bottom of feet to the upper head.”</p>
</blockquote>
<p>4</p>
<blockquote>
<p>paw “Don’t touch the paw of a cat.”</p>
</blockquote>
<p>5</p>
<blockquote>
<p>conscience “Where are your conscience?”</p>
</blockquote>
<p>6</p>
<blockquote>
<p>scope “This is a scope so you should scope this question to find where is the key.”</p>
</blockquote>
<p>7</p>
<blockquote>
<p>excceed “His power excceed a lot.”</p>
</blockquote>
<p>8</p>
<blockquote>
<p>indicative “How can you speak out with such a indicative tone.”</p>
</blockquote>
<p>9</p>
<blockquote>
<p>mayor “The mayor of the city is a lion.”</p>
</blockquote>
<p>10</p>
<blockquote>
<p>rectify “Should I rectify my teeth?”</p>
</blockquote>
<p>11</p>
<blockquote>
<p>commemorate “People made a sculpture to commemorate this hero.”</p>
</blockquote>
<p>12</p>
<blockquote>
<p>nourish “We are noursihed by the land we stand.”</p>
</blockquote>
<p>13</p>
<blockquote>
<p>lease “I make the lease so I lease the house.”</p>
</blockquote>
<p>14</p>
<blockquote>
<p>flee “She fleed away and will never go back.”</p>
</blockquote>
<p>15</p>
<blockquote>
<p>criterion “Who makes the criterion, whose talking work.”</p>
</blockquote>
<p>16</p>
<blockquote>
<p>credentials “I spend lots of time in my life to study so I got this credentials finally.”</p>
</blockquote>
<p>17</p>
<blockquote>
<p>notable “It’s not a notable thing.”</p>
</blockquote>
<p>18</p>
<blockquote>
<p>secure “Please secure that the ladder is secure so I can feel secure.”</p>
</blockquote>
<p>19</p>
<blockquote>
<p>gear “There is a little gear which is broken so the forth gear of the car can’t be used.”</p>
</blockquote>
<p>20</p>
<blockquote>
<p>axis “Fllow the axis so you can draw anything accurately.”</p>
</blockquote>
<h3 id="2025-05-09"><a href="#2025-05-09" class="headerlink" title="2025.05.09"></a>2025.05.09</h3><p>1</p>
<blockquote>
<p>filter “If you want a cup of clear water, you could use the filter.”<br>2<br>confine “Your imagination will confine your arrival at the further place.”<br>3<br>rumour “If you really love her, you shouldn’t believe the rumour.”<br>4<br>category “There are some categories of people, which means that good people and bad people all exist.”<br>5<br>paradox “Sometimes I think I am the paradox itself, which hurts her a lot.”<br>6<br>transistor “Do you konw about transister? It sounds like some high technology.”<br>7<br>illusion “Give up your illusion and be ready to fight!”<br>8<br>ingredient “I once heard that the ingredients of girl are sweet, flower and any other things of happiness.”<br>9<br>feasible “Your idea is exactly genius and feasible.”<br>10<br>petroleum “If you mention my monitor in high shcool, I will think of petroleum which has relation to her profession.”<br>11<br>revenue “How much was the revenue of our government in the past year.”<br>12<br>transplant “If you want to make the flower alive, you can transplant it to another land to nourish it. If you want to make a people alive, you can give him a transplant.”<br>13<br>earnest “Please don’t hurt him, he is a earnest boy.”<br>14<br>instinct “Animals’ instinct will make them own the capablity to live in wild.”<br>15<br>resort “Whenever I listen to the word resort, I will think of people everywhere.”<br>16<br>solitude “Do you want solitude? Although sometimes you will feel lonely, you are free at all.”<br>17<br>notion “The notions about MTL is not easy.”<br>18<br>silicon “The silicon has a deep relation to the production of CPU.”<br>19<br>provoke “This funtion is used to provoke the next layer of GNN.”<br>20<br>intuition “You can’t do everything based on your intuition and you need to think independently sometimes.”</p>
</blockquote>
<h3 id="2025-05-10"><a href="#2025-05-10" class="headerlink" title="2025.05.10"></a>2025.05.10</h3><p>1</p>
<blockquote>
<p>trial “Do you want to make a trial to chase her?”<br>2<br>dense “Someone will fear something tiny and tense.”<br>3<br>identical “There is no leaf identical to another one on the world.”<br>4<br>feminine “An expert said that sensitive psychology is feminine.”<br>5<br>tuition “The tuition from the teacher is fantastic but the tuition is expensive.”<br>6<br>empirical “I’m a empirical man and I’m not good at intution.”<br>7<br>predominant “A efficient algorithm should be predominant on the advantage of time or space.”<br>8<br>marvellous “Gess is a marvellous man with a life like legend.”<br>9<br>ignite “IGNITE!”<br>10<br>conquest “The conquest over her satisfy my hugury and thirsty.”<br>11<br>tenant “The tenant make lease with me yesterday.”<br>12<br>sphere “A sphere is an abstractive name of a kind of objects like basketball and football.”<br>13<br>negligible “You are actually negligible for me like a tiny sand swaying in the air.”<br>14<br>cynical “If you feel you are injured by the world, you can change it but never be a cynical people.”<br>15<br>tempt “The game is so tempting that he can’t focus on study.”<br>16<br>portion “Can you indentify these words:portion, composition, segment and part.”<br>17<br>competent “He is a competent man and he can be our leader.”<br>18<br>jury “She was finally commited by the lawyer and the jury.”<br>19<br>vibrate “The small tool is vibrating, making her thrilled constantly.”<br>20<br>session “They asked for the thrilling feeling from bottom of their feet to the upper head during the session of such a crazy activity.”</p>
</blockquote>
<h3 id="2025-05-11"><a href="#2025-05-11" class="headerlink" title="2025.05.11"></a>2025.05.11</h3><p>1</p>
<blockquote>
<p>upright “The tower on the hill is upright.”<br>2<br>estate “A beautiful woman was killed in the estate lived by a lot of people.”<br>3<br>symphony “The symphony played by us sounds so smooth.”<br>4<br>medium “His ablity is medium among these people.”<br>5<br>commence “Let’s commence this job.”<br>6<br>exceptional “His advancement is exceptional.”<br>7<br>induce “You can induce him but not persude him.”<br>8<br>drought “This drought lasted 20 years, making no life here again.”<br>9<br>executive “He is recruited as the executive.”<br>10<br>initiative “She offers us a new initiative with the high initiative.”<br>11<br>riot “Tension occurred, society is turbulent and riots always appeared in everywhere.”<br>12<br>affirm “I can make an affirm that she isn’t a girl like that.”<br>13<br>outward “You can touch the outward texture. It’s so soft.”<br>14<br>denial “You can make a denial for me but I’ll never give up.”<br>15<br>faculty “The faculty refers to all the teacher of a colleage.”<br>16<br>supervise “We must make a principle to supervise officers.”<br>17<br>imperative “The task is so imperative that we must handle it now.”<br>18<br>mingle “If you mingle something, you have mixed them.”<br>19<br>obscure “Dying as a well-konwn hero or obscure as normal people, which one would you choose?”<br>20<br>forth “He paced back and forth.”</p>
</blockquote>
<h3 id="2025-05-12"><a href="#2025-05-12" class="headerlink" title="2025.05.12"></a>2025.05.12</h3><p>1</p>
<blockquote>
<p>shuttle “Which shuttle wii you choose, if you want to go to the western coast. The plane shuttles to carry apples?”<br>2<br>personnel “Look at me! Personnel in attendance!”<br>3<br>intensify “What hurts my heart will intensify my power.”<br>4<br>turbulent “Intension occurred and society was turbulent.”<br>5<br>attendant “Two attandants of the KTV saw a monster and the anttendant disaseter.”<br>6<br>prospect “Do you think that we have the prospect of our future.”<br>7<br>texture “The texture of the cloth makes me feel comfortable.”<br>8<br>span “The ache of the wound is spanning and the span has been more than 12 hours.”<br>9<br>tragic “Your targic destiny makes you great.”<br>10<br>commodity “She is not a commodity and you should respect her.”<br>11<br>downfall “The reason of Osman’s downfall began from 2000 years ago.”<br>12<br>timber “We can use the timber to arson.”<br>13<br>accessory “I am not your accessory!”<br>14<br>ridiculous “You want to change her, a selflish woman, which is so ridiculous!”<br>15<br>textile “The country’s prosperity is based on the textile.”<br>16<br>composition “What’s the composition of the liquid.”<br>17<br>bribe “Don’t want to bribe him because he is a judge with justice.”<br>18<br>treaty “There are two treaties between me and Lele.”<br>19<br>archive “The archive showes us his experience of honor.”<br>20<br>retreat “Don’t retreat! We have guts, a very awesome man.”</p>
</blockquote>
<h3 id="2025-05-13"><a href="#2025-05-13" class="headerlink" title="2025.05.13"></a>2025.05.13</h3><p>1</p>
<blockquote>
<p>dazzle “A dazzle dazzles my eyes.”<br>2<br>chronic “I’m so sorry to tell you that you have a chronic disease.”<br>3<br>compromise “I would never make a compromise on the view of love even for you.”<br>4<br>flourish “I hope that you can grow up well like plants flourishing under the sun.”<br>5<br>occupancy “The lasting occupancy of the computer results into the overflow of memory.”<br>6<br>vulnerable “Although his body is weak, his heart is never vulnerable.”<br>7<br>exclusive “For the president, the car is exclusive.”<br>8<br>favourable “Everybody holds a favourable attitude for the decision to recurit him as manager.”<br>9<br>spacecraft “The spacecraft is mainly made by element called Al.”<br>10<br>preserve “We are supposed to preserve the environment.”<br>11<br>analogy “How do you dare to make an analogy between a poor guy and the king.”<br>12<br>orient “You must orient, if you wanna to drive a ship on the ocean.”<br>13<br>warehouse “You can pile your goods in the warehouse.”<br>14<br>testify “I can testify that he is a good man.”<br>15<br>petty “Lele is actually a petty girl.”<br>16<br>cargo “Cargo is another name of goods.”<br>17<br>reckon “Gery reckons as a hero.” 一个本就含有被动语态的词语<br>18<br>bind “Binding a name to a object is the begining of artifical intelligence.”<br>19<br>expertise “The management of stack is the expertise of a CS students.”<br>20<br>conform “I won’t conform you without my principle.” “This action dosen’t conform our rules.”</p>
</blockquote>
<h3 id="2025-05-14"><a href="#2025-05-14" class="headerlink" title="2025.05.14"></a>2025.05.14</h3><p>1</p>
<blockquote>
<p>ego “If you can feel your own ego, you will acquire your real happiness.”<br>2<br>deficiency “The deficiency of your ego results in the regret of your life.”<br>3<br>assemble “We assemble something to get a set.”<br>4<br>punch “He was punched to death.”<br>5<br>irritate “Don’t irritate him otherwise he would kill you.”<br>6<br>patch “The patch on the pant makes her so sexy.”<br>7<br>prompt “A prompt prompt prompts him to give a right answer.”<br>8<br>oblige “I wanna to kiss you but I won’t oblige you until you are relunctant.”<br>9<br>correspondent “The correspondents are essential because they can deliver the information concerning the battle.”<br>10<br>flock “A flock of flock follow the God they trust.”<br>11<br>ponder “Confronted with this problem he pondered all the night.”<br>12<br>provision “The provision of food comfrot us a lot.”<br>13<br>stem “The stem of the flower is so thin.”<br>14<br>anticipate “I have anticipated that you might leave me one day but actually we will never leave each other during the life.”<br>15<br>threshold “The Forward Phase is just a threshold of your lengend jounery to pary for Elden Ring.”<br>16<br>expire “Don’t be unforgettable about your youngest which had expired and be concertrated on present.”<br>17<br>profess “I can’t believe you still profess that you love me even that you betray me.”<br>18<br>severe “She made such a severe worry and he won’t forgive her.”<br>19<br>ornament “We make quantities of bright ornaments to ornament our shop.”<br>20<br>germ “On the place you can’t see do exist lots of germs.”</p>
</blockquote>
<h3 id="2025-05-15"><a href="#2025-05-15" class="headerlink" title="2025.05.15"></a>2025.05.15</h3><p>1</p>
<blockquote>
<p>reconcile “Do you think that I can’t reconcile myself to the prospect of losing you?”<br>2<br>transit “The car to transit money is protected carefully.”<br>3<br>whereas “I don’t want to leave you whereas we can’t reconcile our contradiction.”<br>4<br>prominent “Success in this competition is a prominent achievement.”<br>5<br>mount “You can mount the file system or mount a horse to go out!”<br>6<br>naval “The naval power of the country is strengthful.”<br>7<br>waist “I wanna to hold your waist.”<br>8<br>academy “Don’t look down upon a student of the academy, especially in Germany.”<br>9<br>isolate “She is isolated by all of them.”<br>10<br>acute “This is an acute problem and you should note it in details.”<br>11<br>feeble “Though he is phsically feeble, his soul is strong.”<br>12<br>pledge “You have pledged to me that you won’t leave me forever.”<br>13<br>pension “Don’t use the pension of your parents otherwise you would really make me disappointed.”<br>14<br>terminate “Could we terminate this crazy plan?”<br>15<br>assert “I can assert that I won’t make you lose!”<br>16<br>conceal “Where do you want to conceal yourself? No matter where you go to, I will find you finally.”<br>17<br>skim “If you just skim what I have said or what I have done, you will never really know me.”<br>18<br>authentic “I don’t know what the authentic character of me is because I am a people full of paradox.”<br>19<br>presumably “Presumably, she has never produced heartbeat for you so she can leave you easily.”<br>20<br>masculine “Although you just like a puppy confronted with her, I know you are actually masculine.”</p>
</blockquote>
<h3 id="2025-05-18"><a href="#2025-05-18" class="headerlink" title="2025.05.18"></a>2025.05.18</h3><p>1</p>
<blockquote>
<p>applaud “Everyone at presence applauds for what he has done.”<br>2<br>intrigue “Such a strange thing intrigues him who is curious.”<br>3<br>delicate “You are supposed to treat her carefully because her heart is delicate.”<br>4<br>consolidate “What I have gotten could consolidate my confidence.”o<br>5<br>cable “Stay away from the cable otherwise you will get an electric shock.”<br>6<br>manifest “This is a manifest thing that manifests your loss!”<br>7<br>catastrophe “Looking at the broken world makes me know what a real catastrophe is.”<br>8<br>offensive “I’m so sorry that what I had said is offensive.”<br>10<br>dwell “Where your body dwells in, where your heart is then you will feel happy.”<br>11<br>eliminate “Why do you always want to eliminate who holds a different idea? You won’t be welcome.”<br>12<br>grief “Sometimes leaving from you would result in grief of ours but we all know that it’s the best anwser.”<br>13<br>concede “I’m relieved that you’d like to concede the wrong made by you.”<br>14<br>stagger “He is drunk deeply and he is just staggering.”<br>15<br>colonial “Our country will never be your colonial land!”<br>16<br>liquor “Liquor is a liquid will make you drunk.”<br>17<br>negotiation “The negotiation will be held concerning the theme of convicting the convict.”<br>18<br>peculiar “I’m peculiar sometimes because I am the parodox itself.”<br>19<br>confess “Your confessing will make us relieved.”<br>20<br>hoist “People will hoist a witch.”</p>
</blockquote>
<h3 id="2025-05-19"><a href="#2025-05-19" class="headerlink" title="2025.05.19"></a>2025.05.19</h3><p>1</p>
<blockquote>
<p>breadth “Breadth means a big width.”<br>2<br>convene “We will convene a class meeting after this class.”<br>3<br>tremendous “What a tremendous script.”<br>4<br>toss “You make make a toss to decide which one to be tossed.”<br>5<br>utter “He utters this speaking with an utter justice.”<br>6<br>flap “Don’t use the flap to flap your belly.”<br>7<br>notorious “Don’t stay with her otherwise you will be notorious.”<br>8<br>uphold “Everyone should uphold the pride of constitution.”<br>9<br>cruise “This period of time of cruise makes me unforgettable, crusing on the sea and feeling the wind.”<br>10<br>overlap “You are supposed to notice the overlap among these books, which is important.”<br>11<br>scrape “Stop scraping the blackboard. We can’t stand it!”<br>12<br>insult “Someone is just cheap to like being insulted.”<br>13<br>permeate “Don’t let the virus permeating your blood or you will die.”<br>14<br>liability “Liability is responsibility from some aspects.”<br>15<br>comply “complying somebody means you conform him or her.”<br>16<br>harsh “Sometimes the reallity is harsh.”<br>17<br>stereotype “Nowadays Gaokao in China has become a kind of stereotype.”<br>18<br>generalize “If you can generalize this paper, you will understand it more deeply.”<br>19<br>defect “Her defects are that she is stingy sometimes.”<br>20<br>scheme “I want to see a scheme to explain your plans.”</p>
</blockquote>
<h3 id="2025-05-20"><a href="#2025-05-20" class="headerlink" title="2025.05.20"></a>2025.05.20</h3><p>1</p>
<blockquote>
<p>folklore “The folklore in China is that two people who want to get married with each other should ask the suggestions of their parents.”<br>2<br>drown “The huge and grand water will drown us.”<br>3<br>loose “Don’t touch it! It’s about to loose.”<br>4<br>transaction “If you make a deal, you would make a transaction.”<br>5<br>trivial “Trivial thing is something negligible.”<br>6<br>proportion “This proportion of our enterprise is belong to Mr.L, a beautiful lady.”<br>7<br>concrete “The concrete is concrete thing which isn’t abstract.”<br>8<br>confidential “We all are supposed to protect the confidential material of our country.”<br>9<br>portray “Can you portray the beautiful view of the spring.”<br>10<br>additive “We don’t want the food with lots of additive.”<br>11<br>flip “When you toss the coin is flipped to the air.”<br>12<br>furnish “We can furnish you with some desks and chairs to furnish your home.”<br>13<br>suspicion “I don’t like your suspicion even that I can understand you.”<br>14<br>refute “Don’t incline to refute me and be patient to listen to me.”<br>15<br>migrate “Our ancestors migrated from a very far place to here.”<br>16<br>beam “I want the girl to beam because the smile of her is just like quantities of beam lighten my heart.”<br>17<br>token “There are lots of tokens so you don’t need money.”<br>18<br>navie “Confronted with love we are all navie.”<br>19<br>corporate “As a person recruited by us you are supposed to think of the corporate interests.”<br>20<br>emit “Your smile can emit the beam.”</p>
</blockquote>
<h3 id="2025-05-21"><a href="#2025-05-21" class="headerlink" title="2025.05.21"></a>2025.05.21</h3><blockquote>
</blockquote>
<p>1</p>
<blockquote>
<p>curl “Her hair is curled and she has the curl.”<br>2<br>funeral “I won’t attend your funeral because it would make me sad.”<br>3<br>postpone “This meeting is postponed so we should attend this meeting on next monday.”<br>4<br>polish “He polish his sword so that it is shiny.”<br>5<br>wander “Don’t wander in front of me, which will distract my attention.”<br>6<br>deputy “She is the deputy of the policeman and she is a good assistant.”<br>7<br>coward “He almost fears everything so he is a coward.”<br>8<br>missile “If the country still offends the pride of China, we will treat it with missile.”<br>9<br>allege “If you allege something, you assert something.”<br>10<br>destiny “Don’t just accept the destiny and fight back!”<br>11<br>facilitate “This strategy of our country facilitate our life, which means that it makes our life more convenient.”<br>12<br>revolve “Let us revolve this sphere and you won’t feel anything changed.”<br>13<br>doctrine “Do you want the priest to tell you our doctrine that ‘God always right’.”<br>14<br>distinct “The difference among these distinct species is distinct.”<br>15<br>ascertain “We are supposed to ascertain the truth of this case.”<br>16<br>symptom “If a doctor want to diagnose what’s disease she has, he will be based on the symptom.”<br>17<br>drift “We stay on the small boat and drift in the river.”<br>18<br>inherent “Kindness is an inherent characteristic of her which forms from the experience of her life so it won’t change.”<br>19<br>aggravate “Somking will aggravate the disease in her lung.”<br>20<br>alternative “There are lots of women one of whom will become an alternative of her.”</p>
</blockquote>
<h3 id="2025-05-22"><a href="#2025-05-22" class="headerlink" title="2025.05.22"></a>2025.05.22</h3><blockquote>
</blockquote>
<p>1</p>
<blockquote>
<p>obedient “I am not an obedient person so I won’t comply you.”<br>2<br>lane “There is only a lane which can’t accommodate such a big truck.”<br>3<br>cite “I can cite lots of proofs to prove you never love him.”<br>4<br>tissue “She is crying and I guess that she might need some tissues.”<br>5<br>refrain “You should refrain your desires and keep calm to study continually.”<br>6<br>integrity “Integrity is a quality of mine so I won’t lie to you.”<br>7<br>evaporate “The water had evaporated and there is nothing now.”<br>8<br>fragment “How can we assemble a whole sotry with these fragments.”<br>9<br>antique “This is just an antique legend which began from 5,000 years ago.”<br>10<br>clumsy “Her feet is too clumsy to do this.”<br>11<br>venture “A venture means that some business like adventure but there is possibly a good payoff.”<br>12<br>contaminate “We should protect our environment and not contaminate the river.”<br>13<br>toxic “This water is toxic so you don’t drink it!”<br>14<br>curb “Curb your horse! It are almost crazy!”<br>15<br>ingenious “The CPU is an ingenious product which is full of people’s wisdom.”<br>16<br>intricate “This layout of our estate is intricate so follow me closely otherwise you will miss your direction.”<br>17<br>conspicuous “This is a conspicuous result that she dosen’t love you anymore.”<br>18<br>asset “We should be an asset but not just be a person with lots of asset.”<br>19<br>primitive “The primitive human used the fire to protect themselves.”<br>20<br>embody “You should tell me your advancements to embody your ability.”</p>
</blockquote>
<h3 id="2025-05-23"><a href="#2025-05-23" class="headerlink" title="2025.05.23"></a>2025.05.23</h3><blockquote>
</blockquote>
<p>1</p>
<blockquote>
<p>stationary “I juat want the stationary relation with people.”<br>2<br>radical “You are too radical to find out the radical reason.”<br>3<br>ritual “Following the ritual rule or as a part of the ritual, you should give a hug to each other.”<br>4<br>subtle “A subtle rabbit would have three homes.”<br>5<br>precaution “You should make a good precaution before you have a intimate contact with her.”<br>6<br>roar “The wolf is roaring and you are going to die.”<br>7<br>subordinate “Taiwan is sunordinate to China.”<br>8<br>indignant “He is angry and indignant.”<br>9<br>intrinsic “An intrinsic characteristic is inherent.”<br>10<br>After a period of time, there will be a new prevalent thing being popular among people.<br>11<br>grieve “Don’t grieve because it’s normal about the change of our relation.”<br>12<br>diplomatic “This diplomatic event symbolize the improvement of the relationship between China and the US.”<br>13<br>tuck “Just tuck it into my body and it will thrill me too much.”<br>14<br>alienate “The remote distance won’t alienate us.”<br>15<br>banner “What written on the banner tell us the truth.”<br>16<br>exile “The princess was exiled and was down to be a hooker.”<br>17<br>remedy “This remedy will remedy your condition of the disease.”<br>18<br>preach “The priest is preaching.”<br>19<br>precede “My love to her precede you.”<br>20<br>exert “I will exert myself to make it.”</p>
</blockquote>
<h3 id="2025-05-24"><a href="#2025-05-24" class="headerlink" title="2025.05.24"></a>2025.05.24</h3><blockquote>
</blockquote>
<p>1</p>
<blockquote>
<p>withstand “You can’t withstand the pain.”<br>2<br>deem “Do you deem the reason? I don’t believe it.”<br>3<br>retail “Please retail the condition about the change of the price when we take a way of retail.”<br>4<br>predecessor “He is the predecessor of her.”<br>5<br>flaw “This is just a flaw and don’t deem the mistake.”<br>6<br>destined “Can you take us to our destined room.”<br>7<br>epidemic “This epidemic will destory our country and many people will die because of the disease.”<br>8<br>gossip “Don’t deem the gossip because it is just the rumor.”<br>9<br>ward “Stay away from the ward because the patients were illed by the epidemic and you might be illed as well.”<br>10<br>integrate “If you are not usd to being alone you can integrate yourself into a group.”<br>11<br>tackle “If you can tackle something, you can deal with something.”<br>12<br>perceive “Can you perceive that she don’t understand you.”<br>13<br>fluctuate “Don’t let your emotion fluctuate and calm down to think and exert.”<br>14<br>sediment “Look at the sediment from the water, which shows it’s toxic.”</p>
</blockquote>
<h2 id="阅读"><a href="#阅读" class="headerlink" title="阅读"></a>阅读</h2><h2 id="写译"><a href="#写译" class="headerlink" title="写译"></a>写译</h2><h2 id="听力"><a href="#听力" class="headerlink" title="听力"></a>听力</h2><h3 id="第一套测试题"><a href="#第一套测试题" class="headerlink" title="第一套测试题"></a>第一套测试题</h3><blockquote>
</blockquote>
<p>1</p>
<blockquote>
<p>A and B have conspired to do “A与B共同作用导致了…”<br>2<br>rarely(&#x2F;ˈrerli&#x2F;)对比really(&#x2F;ˈriːəli&#x2F;)<br>3<br>tranquility “安静，安宁”<br>4<br>contemplation  “沉思” contemplate v.<br>5</p>
</blockquote>

        


        <span>
          <a class="article-read" href="/2025/05/06/六级词汇/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/05/03/%E8%AE%A1%E7%BB%84%E5%A4%8D%E4%B9%A0/" class="item-title">计组复习</a>
      
      <time datetime="2025-05-03T08:48:40.000Z">
        2025-05-03
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 我在大二下选修了计算机组成原理，这篇blog用来梳理相关知识点
前言一些学习计算机组成原理之前应该知道的知识…

计算机结构：系统程序员所能见到的硬件特性，指的是计算机的逻辑结构
计算机组成：计算机硬件的具体实现，指的是计算的物理结构
两类汇编语言，RISC &amp; CISC，对应精简与复杂的指令系统，MIPS属于RISC的一种
计算机组成原理涉及：汇编，处理器、内存、IO三者对应的逻辑系统与硬件实现（数据通路），课程定位在整个计算机系统中处于硬件方面的数字电路之上，软件层面的操作系统之内（因为上到汇编），但在编译器之下（编译器同样属于OS的范畴）
核心内容：CPU Organization(data path &amp; controller), Caches
重点内容：MIPS汇编，Virtual Memory
了解内容：I&#x2F;O, Bus

最后请谨记，该门课特点是概念抽象、繁琐…但是“清澈见底”，只要想弄清楚，一定可以！
指令系统指令系统设计这一部分主要是一些有关指令系统设计的知识点
于是，首先看看这三个知识点：

指令：二进制的机器语言
汇编指令：助记符，每种条符 -->
        <!-- </div> -->

        
        <p><code>我在大二下选修了计算机组成原理，这篇blog用来梳理相关知识点</code></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>一些学习计算机组成原理之前应该知道的知识…</p>
<ol>
<li>计算机结构：系统程序员所能见到的<strong>硬件特性</strong>，指的是计算机的<strong>逻辑结构</strong></li>
<li>计算机组成：计算机硬件的<strong>具体实现</strong>，指的是计算的<strong>物理结构</strong></li>
<li>两类汇编语言，RISC &amp; CISC，对应精简与复杂的指令系统，MIPS属于RISC的一种</li>
<li>计算机组成原理涉及：汇编，处理器、内存、IO三者对应的逻辑系统与硬件实现（数据通路），课程定位在整个计算机系统中处于硬件方面的数字电路之上，软件层面的操作系统之内（因为上到汇编），但在编译器之下（编译器同样属于OS的范畴）</li>
<li>核心内容：CPU Organization(data path &amp; controller), Caches</li>
<li>重点内容：MIPS汇编，Virtual Memory</li>
<li>了解内容：I&#x2F;O, Bus</li>
</ol>
<p><strong>最后请谨记，该门课特点是概念抽象、繁琐…但是“清澈见底”，只要想弄清楚，一定可以！</strong></p>
<h2 id="指令系统"><a href="#指令系统" class="headerlink" title="指令系统"></a>指令系统</h2><h3 id="指令系统设计"><a href="#指令系统设计" class="headerlink" title="指令系统设计"></a>指令系统设计</h3><p><code>这一部分主要是一些有关指令系统设计的知识点</code></p>
<p>于是，首先看看这三个知识点：</p>
<ol>
<li>指令：二进制的机器语言</li>
<li>汇编指令：助记符，每种条符号语句都映射到一条二进制的机器代码</li>
<li>ISA：指令系统（指令集体系结构），<strong>软硬件交汇的地方</strong></li>
</ol>
<p>接下来，一条指令应该包含以下信息：</p>
<ol>
<li>操作码（定长 or 变长）</li>
<li>源操作数参照（from where）</li>
<li>目的位置参照（to where）</li>
<li>下一条指令地址（what to do next?）</li>
</ol>
<p>按地址数的指令分类：</p>
<p>零、一、二、三、多地址指令，其中二三是典型的RISC风格。三的特点是显示指定了dst，一或二的dst是隐含的（built-in or src）</p>
<p>指令执行的阶段：</p>
<p>取指令-&gt;译码-&gt;取操作数-&gt;运算（执行）-&gt;存放结果-&gt;取下一条指令<br><strong>不一定所有指令都涉及所有步骤，但是考虑的时候应该按最复杂的来，何尝不是一种设计原则？</strong></p>
<p>指令设计基本原则：<br>完备性，兼容性，均匀性，可扩展性<br><strong>应当明白词语背后的含义</strong></p>
<p>最简单的完备指令系统：<br>load, store, inc, brn</p>
<h3 id="操作数类型"><a href="#操作数类型" class="headerlink" title="操作数类型"></a>操作数类型</h3><p>…</p>
<h3 id="寻址方式"><a href="#寻址方式" class="headerlink" title="寻址方式"></a>寻址方式</h3><p>…</p>
<h3 id="扩展操作码编码"><a href="#扩展操作码编码" class="headerlink" title="扩展操作码编码"></a>扩展操作码编码</h3><p>这是涉及关于如何给操作码编码，以及对应数量关系的问题。<br><strong>核心思想是一种数字状态，一个编码</strong></p>
<p>涉及到的相关信息有：</p>
<ol>
<li>指令字长，例如16位、32位…</li>
<li>地址长度，如6位…</li>
<li>操作码长度，通常不同地址数量的编码不同</li>
<li>不同地址数的指令的条数</li>
</ol>
<p>通常会已知1、2，4中某些地址数的指令条数，求剩余一种地址数的指令<strong>最多</strong>的条数。</p>
<p>关键点是：</p>
<ol>
<li>明确<strong>已知的某些地址数的指令条数——剩下的一种地址数的指令条数</strong>一定存在函数关系</li>
<li>从多地址数的指令开始考虑，考虑它的操作码有多少位，可求得这种指令至多有多少条</li>
<li>利用“已知”的实际条数与至多有多少条，可以求得这种指令的<strong>剩余状态</strong>数量</li>
<li>考虑减少一条地址的指令，对应操作码有多少位，<strong>记得计算操作码长度的时候，不仅是指令字长减去地址长度，还要减去上种指令操作码所用长度</strong></li>
<li>求得这种指令至多有多少条，利用<strong>剩余状态</strong>×<strong>操作码长度</strong></li>
<li>显然这个过程可以反复进行，由地址数量最多的情况，如3个地址码，到最少的情况，如零地址码<br><strong>最后，不一定所有的状态都有使用…</strong></li>
</ol>
<h3 id="指令设计的风格"><a href="#指令设计的风格" class="headerlink" title="指令设计的风格"></a>指令设计的风格</h3><p>尤其关注RISC的风格。</p>
<p>RISC是<strong>load&#x2F;store型指令系统</strong>，特点是只有load、store命令才能访问存储器，其它运算类的指令通通不能访问存储器<br>（值得注意的是这种指令系统，属于<strong>通用寄存器型指令系统</strong>的子集，特点是使用通用寄存器存放临时数据，而不使用累加器）</p>
<p>RISC的特点是：</p>
<ol>
<li>指令数目少</li>
<li>指令格式规整</li>
<li>Load&#x2F;store风格</li>
<li>采用流水线的指令执行方式</li>
<li>采用大量通用寄存器</li>
<li>采用硬连线控制器</li>
<li>采用优化的编译器</li>
</ol>
<h3 id="异常与中断"><a href="#异常与中断" class="headerlink" title="异常与中断"></a>异常与中断</h3><p>…</p>
<h3 id="程序的机器级表示（MIPS指令系统）"><a href="#程序的机器级表示（MIPS指令系统）" class="headerlink" title="程序的机器级表示（MIPS指令系统）"></a>程序的机器级表示（MIPS指令系统）</h3><p><code>这一部分是重点知识，所以会有多级的副标题。请着重掌握！</code></p>
<h4 id="MIPS有关的基础知识"><a href="#MIPS有关的基础知识" class="headerlink" title="MIPS有关的基础知识"></a>MIPS有关的基础知识</h4><p><code>一些零碎的知识点，不好纳入后面的各级标题之中，于是集中在此...</code><br><code>或者说并非无法纳入，而是比较重要...单拎出来也方便记忆</code></p>
<ol>
<li>MIPS指令长度都是32位</li>
<li>MIPS中设计了32个通用寄存器</li>
<li>MIPS使用大端的存储方式</li>
<li>MIPS设计的存储器按照字节编址，1Byte对应一个存储单元，有自己的专属地址</li>
<li>MIPS中人为修改pc的指令，如j、beq等，在机器级存储的转移值是相对转移的指令的条数（即应该修改pc的相对量除以4后的值）</li>
</ol>
<h4 id="MIPS指令的机器级表示"><a href="#MIPS指令的机器级表示" class="headerlink" title="MIPS指令的机器级表示"></a>MIPS指令的机器级表示</h4><p>MIPS中指令格式包括R型、I型、J型。</p>
<h5 id="1-R型指令"><a href="#1-R型指令" class="headerlink" title="1.R型指令"></a>1.R型指令</h5><p>机器级表示:<br>op6+rs5+rt5+rd5+shamt5+func5</p>
<ol>
<li>op是操作码，对于R型来说全是0</li>
<li>shamt是用于处理移位操作的</li>
<li>func是用于区分操作码的</li>
<li>rs, rt为源寄存器1、2</li>
<li>rd为目的寄存器</li>
</ol>
<p><strong>注意，R型指令助记符表示的时候，实际上是 op rd rs rt的顺序，要和机器级位置区分开</strong><br><code>不妨考虑一下，op全为0的好处是什么</code></p>
<h5 id="2-I型指令"><a href="#2-I型指令" class="headerlink" title="2.I型指令"></a>2.I型指令</h5><p>机器级表示：<br>op6+rs5+rt5+imm16</p>
<ol>
<li>常用I型指令：双目运算，rs与imm运算，送至rt，例如<code>addi $2,$1,imm</code></li>
<li>常用I型指令，load、store，采用的<strong>MIPS采用基址+相对位移量</strong>的访存方式，例如<code>lw $2,100($1)</code></li>
<li>常用I型指令，beq、bne，条件分支，例如<code>beq $1,$2,L</code></li>
<li>imm是16位，但是与其运算的寄存器rs是32位的，需要进行扩展，扩展的规则如下：<br>①用于进行双目运算的时候，i是符号扩展imm，iu是零扩展imm<br>②用于load、store的时候，imm总是符号扩展，虽然有u的存在，例如lhu, lbu等，但是这里的u对应的用于0扩展不足32位的存储内容，从而加载到寄存器<br>③用于条件分支的时候，beq、bne应该与slt搭配使用，所以imm通常只与1、0进行相等与否的比较，于是也不存在什么扩展与否的问题<br><strong>注意，实际上slt也可以是I型的，并且很常用，但是也有R型的</strong></li>
</ol>
<h5 id="3-J型指令"><a href="#3-J型指令" class="headerlink" title="3.J型指令"></a>3.J型指令</h5><p>机器级表示：<br>op6+target address26</p>
<ol>
<li>实际的目的地址计算方式，pc高4位:target address:00<br>最后总是00的原因，在于MIPS中指令总是32位的，从0地址开始访存：0,100,1000,1100…（0、4、8、12…），末尾总是00，这个特点在后面设计用于MIPS的CPU的时候也非常有用</li>
<li>显然，这是一种局部寻址的方式</li>
</ol>
<h4 id="MIPS设计的通用寄存器"><a href="#MIPS设计的通用寄存器" class="headerlink" title="MIPS设计的通用寄存器"></a>MIPS设计的通用寄存器</h4><p>MIPS使用32个通用寄存器，我们应该掌握以下有关的知识。</p>
<h5 id="1-两种助记符号的使用"><a href="#1-两种助记符号的使用" class="headerlink" title="1.两种助记符号的使用"></a>1.两种助记符号的使用</h5><ol>
<li>编号：”$”+“数字：0~31”</li>
<li>名称</li>
</ol>
<p><code>程序中一般都使用名称，举例子的时候使用编号多一些。或许，前者体现“助记”，后者体现“通用”</code></p>
<h5 id="2-经常使用的寄存器"><a href="#2-经常使用的寄存器" class="headerlink" title="2.经常使用的寄存器"></a>2.经常使用的寄存器</h5><ol>
<li>zero<br>编号为0，其功能是提供0值，寄存器中始终是全0</li>
<li>v0-v1<br>编号2-3，功能是存放过程调用的返回值</li>
<li>a0-a3<br>编号4-7，功能是存放过程调用的参数</li>
<li>t0-t7<br>编号8-15，功能是存放临时使用的变量</li>
<li>s0-s7<br>编号16-23 被调用者保存的寄存器</li>
<li>t8-t9<br>编号24-25，功能是存放临时使用的变量</li>
<li>sp, fp, ra<br>编号29-31，功能是，栈指针（栈顶），帧指针（栈底），存放调用过程返回地址</li>
</ol>
<p>记忆的方法，“一个过程调用，使用了4个参数a，返回了两个值v，调用者保存了8个寄存器s，被调用者保存了10个寄存器t，关键在于sp、fp与ra”+zero</p>
<h5 id="3-了解的寄存器"><a href="#3-了解的寄存器" class="headerlink" title="3.了解的寄存器"></a>3.了解的寄存器</h5><ol>
<li>at<br>编号为1，保留给编译器使用</li>
<li>k0-k1<br>编号为26-27，保留给系统使用</li>
<li>gp<br>编号为28，全局指针</li>
</ol>
<h4 id="MIPS汇编指令"><a href="#MIPS汇编指令" class="headerlink" title="MIPS汇编指令"></a>MIPS汇编指令</h4><p><code>在开始做这一部分的笔记之前，我思考了一个问题——如何才能更好的记忆MIPS汇编指令。我得出的答案是，一般性规律的记忆+特殊性个例的记忆。对于一般性规律的记忆，其规律包括：指令的助记符+什么类型的指令+指令的特性，前两者可以帮助我们正确地写出指令，后者可以帮助我们正确地理解指令。对于特殊性个例，我们不妨记住全部。在记忆的过程中带着这个思想，或许会容易记忆一些。</code></p>
<p>我们接下来按照指令的类别进行。</p>
<h5 id="1-算术类指令"><a href="#1-算术类指令" class="headerlink" title="1.算术类指令"></a>1.算术类指令</h5><ol>
<li>算术运算包括，加、减、乘、除<br>对应的基本助记符是add、sub、mult、div</li>
<li>加、减有I型和R型，使用I型的时候，如addi、subi</li>
<li>加、减默认会判断溢出，也有不判断溢出，对应u扩展（undo），如addu、subu<br><strong>当然也有addiu、subiu</strong></li>
<li>乘、除比较特殊，仅有R型，但是是双目操作符，因为结果存放在默认寄存器hi，lo（乘法hi，lo分别为高低32位，除法hi为32位余数，lo为32位商）</li>
<li>乘、除分有符号数和无符号数，对应为u扩展（unsigned），如multu、divu<br><strong>注意区分unsigned和undo</strong></li>
</ol>
<p><code>一般性的规律是，助记符：加、减有I、R型，乘、除只有R型</code></p>
<h5 id="2-存储访问"><a href="#2-存储访问" class="headerlink" title="2.存储访问"></a>2.存储访问</h5><p>存储访问，按照访存字节，分为按字（word，MIPS中是32位），按半字（half word，16位），按字节（byte，8位）访问</p>
<p>以及MIPS最有特色的指令<strong>lui</strong></p>
<ol>
<li>lw、sw，按字访问lw&#x2F;sw $1 100($2)，sw是MIPS中唯一一个dst在src之后的指令</li>
<li>lhu、lbu，按半字、字节加载，16位内存到32位存储器涉及扩展，格式与lw、sw相同，内存中数据是按无符号扩展<br><strong>注意，必须加u，这就意味着使用半字或字节的时候，内存中内容只能按字节扩展到寄存器</strong><br><strong>但是imm的扩展只能是符号扩展，没有undo的选择</strong></li>
<li>sh、sb，按半字、字节存储，格式与lw、sw相同，由于是寄存器到存储器，不用考虑扩展。<br><strong>sh、sb同样的只要是访存，imm都是按符号扩展</strong></li>
<li>lui，I型，使用方法，lui rs,imm，将16位imm放置在rs的高16位<br><em>这是一个很能体现MIPS特色的指令，如果程序员，<del>按照自己的想象</del>（这个数字并不存在于任何其它的位置），想要将一个32位的数字放置在寄存器中，就可以按照16位、16位的存放。可以先lui，再addi</em><br><strong>按照自己的想象是很重要的一点！这将lui和lw、lhu、lbu区分开来，因为lui根本没有访存！</strong></li>
</ol>
<p><code>一般性的规律是，助记符；访存都是I型</code></p>
<h5 id="3-逻辑运算"><a href="#3-逻辑运算" class="headerlink" title="3.逻辑运算"></a>3.逻辑运算</h5><p>MIPS中常用的逻辑运算是与、或、异或</p>
<ol>
<li>与，and，有R型、I型，I型对应i扩展，如addi rd,rs,rt</li>
<li>或，or，同与</li>
<li>异或，xor，同与</li>
</ol>
<p><code>一般性的规律是，助记符，逻辑运算有R型、I型</code></p>
<h5 id="4-移位操作"><a href="#4-移位操作" class="headerlink" title="4.移位操作"></a>4.移位操作</h5><p>MIPS中的涉及的移位操作有，逻辑左、右移动，算术右移</p>
<ol>
<li>逻辑左移，sll，I型，如sll rt,rs,imm</li>
<li>逻辑右移，srl，同上</li>
<li>算术右移，sra，同上<br><strong>注意，表示是逻辑还是算术的l和a，放在最后</strong></li>
</ol>
<p><code>一般性的规律是，助记符，移位只有I型</code></p>
<h5 id="5-条件分支"><a href="#5-条件分支" class="headerlink" title="5.条件分支"></a>5.条件分支</h5><p>MIPS中涉及的条件分支，常用的是，slt、beq、bne</p>
<ol>
<li>slt，有R型、I型，如slt rt,rs,imm<br><strong>注意slt的I型，不使用i扩展！</strong></li>
<li>beq，I型，如beq rs,rt,L<br><strong>实际编程中L的位置，通常写label，进一步的处理或许是交给汇编器进行的…</strong></li>
<li>bne，同beq</li>
</ol>
<p><code>一般性的规律是，助记符，slt有R型，其它都是I型</code></p>
<h5 id="6-无条件跳转指令"><a href="#6-无条件跳转指令" class="headerlink" title="6.无条件跳转指令"></a>6.无条件跳转指令</h5><p>MIPS中的跳转指令常用的是j、jr、jal</p>
<ol>
<li>j，J型指令，如j L（实际使用L是label）</li>
<li>jr，J型指令，地址存放在Register中，如j rd</li>
<li>jal，J型指令，<strong>注意这个指令有两个操作</strong>，一个如普通的j一般跳转到L，另一个是$ra &#x3D; PC + 4（存放返回地址，所以这个指令常用于过程调用）</li>
</ol>
<p><code>一般性的规律是，助记符，都是J型</code></p>
<h4 id="MIPS汇编代码"><a href="#MIPS汇编代码" class="headerlink" title="MIPS汇编代码"></a>MIPS汇编代码</h4><p><code>这一小节主要是掌握MIPS汇编代码的编写的常见结构，包括分支结构、循环结构、还有过程调用</code></p>
<h5 id="1-分支结构"><a href="#1-分支结构" class="headerlink" title="1.分支结构"></a>1.分支结构</h5><p>分支结构主要有如下两种：</p>
<ol>
<li><code>if(i == j) or if(i != j)</code>这种等或不等，主要使用<code>bne</code>,<code>beq</code>进行</li>
<li><code>if(i &lt; j)</code>这种大于小于的关系，主要使用<code>slt</code>与<code>bne</code>,<code>beq</code>进行</li>
</ol>
<p>下面是两个例子<br>eg1</p>
<pre><code>if(i == j)f = g + h
else f = g - h
</code></pre>
<p><code>$s1&lt;-i $s2&lt;-j  $s3&lt;-f  $s4&lt;-g $s5&lt;-h</code></p>
<pre><code>start: bne $s1,$s2,else
       add $s3,$s4,$s5
       j exit
else:  sub $s3,$s4,$s5
exit:  ...
</code></pre>
<h5 id="2-循环结构"><a href="#2-循环结构" class="headerlink" title="2.循环结构"></a>2.循环结构</h5><p>这里以while循环为例<br>eg</p>
<pre><code>while(i != k)&#123;
    x = x + a[i];
    i = i + 1;
&#125;
</code></pre>
<p><code>$s1&lt;-x $s2&lt;-i $s3&lt;-k  $s5&lt;-a</code></p>
<pre><code>loop: beq $2,$3,exit
      sll $s7,$s2,2 #注意这行，不能直接将i &lt;&lt;= 2 （Bits -&gt; Byte）
      add $s7,$s5,$s7
      lw $s6,0($7)
      add $s1,$s1,$s6
      addi $s2,$2,1 #注意这行，i = i+1（Bits）
      j loop
exit: ...
</code></pre>
<p>注意，将偏移i换算为地址的时候要乘4，换算成对应按字节编址的情况</p>
<h5 id="3-过程调用"><a href="#3-过程调用" class="headerlink" title="3.过程调用"></a>3.过程调用</h5><p>首先我们应该清楚整个过程调用的执行过程：</p>
<ol>
<li>P保存相应的寄存器（$t）</li>
<li>P将参数放置于Q可以访问的位置（$a）</li>
<li>P将返回位置保存，从而让Q可以执行返回（$ra）</li>
<li>P修改栈帧（$sp $fp）切换到Q的栈帧</li>
<li>Q将P的相关寄存器进行保存（$s、$ra、$fp）</li>
<li>Q为自己的局部变量分配栈帧空间</li>
<li>执行Q的过程</li>
<li>返回P（使用P最开始保存的$ra，或者是Q自己保存的$ra）</li>
</ol>
<p>注意，以上是以最严格、完整的过程来叙述的，实际上都是根据需要来进行。于是可以做以下几点说明：</p>
<ol>
<li>P是根据需要保存$t的，如果可以确保之后不再使用，不保存也行，对应了Q可以随意使用$t</li>
<li>如果参数多于4个，$a不够用了，需要将参数放到相应的栈帧中（如果必要的话$a也可以与$t类似，由P保存）</li>
<li>$ra的保存实际上是用jal来隐式执行的</li>
<li>在MIPS中$fp,$sp不一定都要修改，通常是只修改$sp，然后以其作为参考即可，当$fp需要修改的时候，$fp &#x3D; $sp + 栈帧空间大小</li>
<li>Q也是根据需要保存，如果要使用$s的话必须保存，如果自己还要进行过程调用（会修改$ra、$fp，那么也应该自行保存）</li>
<li>由于MIPS通用寄存器非常多，$t就多达10个，通常不需要将局部变量分配到栈帧中，直接使用寄存器即可</li>
<li>…</li>
<li>返回时总是使用$ra，如果Q中间执行了过程调用修改了$ra，当Q的调用返回时，应该根据Q保存的P的$ra值，将$ra进行还原；并且需要先释放Q的栈帧空间，通常可以使用$sp &#x3D; $fp（如果开始时修改了$fp，同样嵌套调用时若Q修改了$fp，在Q的调用结束时要先将$fp还原，就像$ra一样），或$sp &#x3D; $sp - 栈帧空间，来释放Q的栈帧；最后使用jr $ra返回P的执行。</li>
</ol>
<p>以上几点说明都是针对最开始描述的每一点过程进行的</p>
<p>下面还有一些需要补充的点</p>
<p>Ⅰ MIPS中栈帧是由高地址到低地址，这意味着分配栈帧空间对$sp执行的是减法操作</p>
<blockquote>
<p>eg:在栈帧中分配空间，保存$ra,$a0</p>
</blockquote>
<pre><code>subi $sp,$sp,8
sw $a0,4($sp)
sw $ra,0($sp)
</code></pre>
<p>Ⅱ 一般只有在由数组或结构体等占用空间较大的复杂数据结构的时候才需要使用栈帧分配局部变量（$t不够用）</p>
<p>Ⅲ Q没有进一步嵌套调用其它函数的情况，Q被称为叶子过程。一般的叶子过程通常在MIPS中甚至不需要开辟栈帧，因为有足够多的通用寄存器</p>
<p>Ⅳ 如果$fp不使用（建立当前函数的栈帧时并没有维护$fp），可以将$fp作为$s8来使用</p>

        


        <span>
          <a class="article-read" href="/2025/05/03/计组复习/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/05/01/Py-learning/" class="item-title">Py_learning</a>
      
      <time datetime="2025-05-01T04:55:26.000Z">
        2025-05-01
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 由于我在学习机器学习算法的时候，希望通过Python来对相关的算法进行复现。而自己在此之前其实零零散散不成体系地接触过Python语言，也了解一些基本的东西，但是对于Python中一些语言“特性”方面的东西所知甚少，例如变量的作用域与生命周期，不同模块间的访问等等；此外我对Python风格的代码写法也并不熟悉，其实写什么感觉都是C的味道......于是写下这篇blog用来记录，进一步对相关内容的学习
模块化的Python程序内置变量__name____name__是python模块当中的一个内置变量，每个模块都有。如果你选择当前模块开始执行，那么当前模块内置的__name__会被置为__main__；如果一个模块是被令一个模块import进去的，那么这个模块的__name__会被置为__模块名__，但是不会引入后缀。
模块化通过__name__我们就可以将我整个项目文件模块化的组织起来。将一个模块作为程序的执行入口，并始终自我约束地从这个模块开始启动整个项目程序。这样做的关键在于使用如下代码：
12345def main:    somethingif __name__ == __ma -->
        <!-- </div> -->

        
        <p><code>由于我在学习机器学习算法的时候，希望通过Python来对相关的算法进行复现。而自己在此之前其实零零散散不成体系地接触过Python语言，也了解一些基本的东西，但是对于Python中一些语言“特性”方面的东西所知甚少，例如变量的作用域与生命周期，不同模块间的访问等等；此外我对Python风格的代码写法也并不熟悉，其实写什么感觉都是C的味道......于是写下这篇blog用来记录，进一步对相关内容的学习</code></p>
<h2 id="模块化的Python程序"><a href="#模块化的Python程序" class="headerlink" title="模块化的Python程序"></a>模块化的Python程序</h2><h3 id="内置变量-name"><a href="#内置变量-name" class="headerlink" title="内置变量__name__"></a>内置变量__name__</h3><p>__name__是python模块当中的一个内置变量，每个模块都有。如果你选择当前模块开始执行，那么当前模块内置的__name__会被置为__main__；如果一个模块是被令一个模块import进去的，那么这个模块的__name__会被置为__模块名__，但是不会引入后缀。</p>
<h3 id="模块化"><a href="#模块化" class="headerlink" title="模块化"></a>模块化</h3><p>通过__name__我们就可以将我整个项目文件模块化的组织起来。将一个模块作为程序的执行入口，并始终自我约束地从这个模块开始启动整个项目程序。这样做的关键在于使用如下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>:</span><br><span class="line">    something</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == __main__:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p><strong>关键点即，不要使用判断__name__以外的任何顶层代码</strong></p>
<h3 id="一些特性"><a href="#一些特性" class="headerlink" title="一些特性"></a>一些特性</h3><p>Python是一种解释性语言，特点就是不需要编译，而是在运行时通过解释器逐行读取、分析和执行源代码。对应的特点之一就是交互式的编程环境（可以在命令行中输入代码，并立刻看到执行的结果）</p>
<p>我联想到与这种特点相对应的就是——“顶层代码”，即相关的语句不会被封装在任何函数和类当中，点击运行，便会至上而下地逐行开始执行。</p>
<p><strong>所以一个关键的特性就是，使用import导入模块化后，该模块的顶层代码会立刻执行。</strong></p>
<p>启示：编写规范化的工程代码时，除了判断程序执行入口，不要使用顶层代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#k_means.py</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;this is k_means&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#main.py</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;this is mainn&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == main:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<p><code>this is k_means this is main</code></p>
<h2 id="变量的作用域和生命周期"><a href="#变量的作用域和生命周期" class="headerlink" title="变量的作用域和生命周期"></a>变量的作用域和生命周期</h2><h3 id="单一模块"><a href="#单一模块" class="headerlink" title="单一模块"></a>单一模块</h3><ol>
<li><p>全局变量<br>在同一模块当中，定义于模块层的变量（顶层代码部分），对应的是<code>global varible</code>全局变量，这些变量的作用域是全局可见，生命周期是从程序开始执行开始，执行完毕结束。</p>
</li>
<li><p>局部变量<br>定义于函数中的变量是<code>local varible</code>局部变量，作用域局部可见。对于嵌套函数，外层变量对内层可见，内层对外层不可见。在Python中这种函数嵌套更加的显然。下面是一个例子：</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">outer_function</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;this is outer&quot;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner_function</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;this is inner&quot;</span>)</span><br><span class="line">    inner_function()</span><br></pre></td></tr></table></figure>

<p>对应变量的生命周期，都是从定义自己的函数开始，到函数执行完毕结束。</p>
<p><strong>另外值得一提的是，在上面这个例子当中，inner_function不能从顶层代码调用。</strong><br>3. 内置变量<br><code>Built-in varible</code>内置变量的作用域是在任何地方都可以访问，且生命周期贯穿整个程序的运行期，最开始提到的__name__就是一个很好的例子。<br>4. 访问规则<br>python对于变量遵循<code>LEGB</code>的访问规则，即局部、嵌套、全局、内置。当发现了变量，即刻使用。</p>
<p>最后简单补充以下Python的变量定义规则，变量在“第一次赋值”时被定义。当然这意味着我们要定义一个变量必须考虑一个初始值，如果暂时没有初始值的话可以使用<code>None</code>作为初始值。随后根据需要赋予想要的初始值即可。当然，变量的类型也是根据你赋予的值来确定的。</p>
<h3 id="多模块"><a href="#多模块" class="headerlink" title="多模块"></a>多模块</h3><p>为了理解多模块情况下相关变量的作用域和生命周期，引入以下概念：</p>
<ol>
<li><p>模块对象，在导入模块的时候Python会为模块创建一个对象，这个对象的生命周期由其作用域确定</p>
</li>
<li><p>全局导入，模块对象在全局作用域中导入，此时模块变量生命周期同程序一样。作用域同全局变量。</p>
</li>
<li><p>局部导入，模块对象在局部作用域中导入，此时模块变量生命周期同导入了它的函数。作用域同相应的局部变量。</p>
</li>
<li><p>模块中的顶层代码在被导入时会立刻执行，相应的对应的全局变量会即刻创建，所以对应的全局变量生命周期、作用域，同模块对象。</p>
</li>
</ol>
<p><del>口语化的来说，模块被导入的时候也相当于一个变量（或者是一个类），如果是被主函数所在的模块作为全局变量导入，那么被导入模块的生命周期、作用域同全局变量，如果被作为局部变量导入，也同局部变量。相应的，被导入的时候，被导入模块中的“全局变量”也会即刻被创建，其生命周期同被导入的模块。</del>（毫不精准的表述…）</p>
<h2 id="名称冲突"><a href="#名称冲突" class="headerlink" title="名称冲突"></a>名称冲突</h2><p>在使用以下代码的时候，名称冲突时常发生。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> somemodule <span class="keyword">import</span> somename</span><br></pre></td></tr></table></figure>

<p>这类似是跳过了模块对象，直接导入了其中某个全局变量，自然就很可能与当前模块已有的全局变量、函数发生名称冲突。</p>
<p>常用的解决方法，也是我们使用模块化的常用方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> somemodule</span><br><span class="line">somemodule.somename <span class="comment">#使用模块对象名来访问相应的变量、函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> somemodule <span class="keyword">import</span> somename <span class="keyword">as</span> another_name <span class="comment">#或者是别名</span></span><br></pre></td></tr></table></figure>

<h2 id="列表生成式"><a href="#列表生成式" class="headerlink" title="列表生成式"></a>列表生成式</h2><p>语法如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list_name = [formula <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(start, end)]</span><br><span class="line">list_name = [x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">10</span>)]</span><br></pre></td></tr></table></figure>

<p>这种创建列表的方法成为列表生成式，formula是用于生成列表的表达式，可以是返回一些值的函数，后面的循环是列表中生成元素的次数，循环一次便会调用一次formula。</p>
<p>当然formula也可以直接是数学表达式，例如第二个例子展示的，用于生成1到9的平方的列表。</p>
<p>注意end不被包含在内。</p>
<h2 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h2><p>元组（Tuple）是一种内置的数据结构，属于不可变序列类型，用于存储多个元素。与列表（List）不同，<strong>元组一旦创建，其内容就不能更改（即不可变）</strong>。元组常用于存储一组相关的数据，例如函数返回多个值时，可以使用元组来打包这些值。</p>
<h3 id="元组的创建"><a href="#元组的创建" class="headerlink" title="元组的创建"></a>元组的创建</h3><p>使用<code>()</code>来创建一个元组，例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个空元组</span></span><br><span class="line">empty_tuple = ()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个包含多个元素的元组</span></span><br><span class="line">example_tuple = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="string">&quot;hello&quot;</span>, <span class="number">4.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个单元素的元组（注意逗号）</span></span><br><span class="line">single_element_tuple = (<span class="number">1</span>,)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以省略小括号，直接用逗号分隔元素</span></span><br><span class="line">another_tuple = <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问元素</span></span><br><span class="line"><span class="built_in">print</span>(example_tuple[<span class="number">0</span>])  <span class="comment"># 输出 1</span></span><br><span class="line"><span class="built_in">print</span>(example_tuple[<span class="number">3</span>])  <span class="comment"># 输出 &quot;hello&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取元组的长度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(example_tuple))  <span class="comment"># 输出 5</span></span><br></pre></td></tr></table></figure>

<h3 id="元组的常见用途"><a href="#元组的常见用途" class="headerlink" title="元组的常见用途"></a>元组的常见用途</h3><ol>
<li>多值返回，用于让函数返回多个值</li>
<li>作为字典的键，这是由于元组的不可变性</li>
</ol>
<h2 id="函数的参数以及返回值"><a href="#函数的参数以及返回值" class="headerlink" title="函数的参数以及返回值"></a>函数的参数以及返回值</h2><p>在python中函数的参数不需要提前声明类型，同样的返回值也不需要提前进行声明。但是在大型的项目中为了便于程序的维护，以及提供静态的检查，可以使用注解符号。例如，下面这个例子。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">k_means</span>(<span class="params">D:<span class="type">List</span>[<span class="type">List</span>[<span class="built_in">float</span>]], n:<span class="built_in">int</span>, k:<span class="built_in">int</span></span>) -&gt; <span class="type">Tuple</span>(<span class="type">List</span>[<span class="type">List</span>[<span class="type">List</span>[<span class="built_in">float</span>]]], Lsit[<span class="type">List</span>[<span class="built_in">float</span>]])</span><br></pre></td></tr></table></figure>

<p>其中typing是类型注解使用的包，如果不需要使用类型进行注解可以不使用这个包。</p>
<p>常见的类型注解有：</p>
<ol>
<li>List     eg: List[int]</li>
<li>Tuple    eg: Tuple[float,str]</li>
<li>Dict     eg: Dict[int,str]</li>
<li>Set      eg: Set[str]<br>还有许多可用的…用到再查吧…</li>
</ol>

        


        <span>
          <a class="article-read" href="/2025/05/01/Py-learning/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/04/30/Clustering-learning-route/" class="item-title">Clustering-learning-route</a>
      
      <time datetime="2025-04-30T13:35:10.000Z">
        2025-04-30
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 我从现在开始学习聚类相关的内容，最终目标是希望发表一篇相关的论文。我以现在浅显的眼光给自己定下的学习路线如下1. 完成西瓜书聚类部分的学习，完成的标志是将书上给出的伪代码进行真实地复现2. 阅读综述论文，了解聚类对应的科研领域当前大概的情况3. 阅读聚类有关的顶会论文......我以现在的知识，无法继续制定下面的计划了，因为我并不了解3、往后的真正开始着手科研工作会是怎样的。我目前粗浅的想法是，或许我会了解到一些聚类的具体应用，然后为了完成一篇相关的论文：我也必须将聚类投入到具体的应用当中去，这个时候我不得不学习一些其它领域的知识（当然，目前我并不清楚那些会是什么）；又或许我会做一些对聚类算法进行改进的工作，但是这或许会更加艰难（因为曾经一位厉害的学长告诉我将A运用于B会比将A升级为A+简单许多）此外，我将这篇blog用作自己的学习日志与计划路线
阶段一2025.4.30

学习西瓜书上有关聚类的基础知识（概念、性能指标）
学习“k均值算法”、学习“学习向量量化算法”

 -->
        <!-- </div> -->

        
        <p><code>我从现在开始学习聚类相关的内容，最终目标是希望发表一篇相关的论文。我以现在浅显的眼光给自己定下的学习路线如下</code><br><code>1. 完成西瓜书聚类部分的学习，完成的标志是将书上给出的伪代码进行真实地复现</code><br><code>2. 阅读综述论文，了解聚类对应的科研领域当前大概的情况</code><br><code>3. 阅读聚类有关的顶会论文......</code><br><code>我以现在的知识，无法继续制定下面的计划了，因为我并不了解3、往后的真正开始着手科研工作会是怎样的。我目前粗浅的想法是，或许我会了解到一些聚类的具体应用，然后为了完成一篇相关的论文：我也必须将聚类投入到具体的应用当中去，这个时候我不得不学习一些其它领域的知识（当然，目前我并不清楚那些会是什么）；又或许我会做一些对聚类算法进行改进的工作，但是这或许会更加艰难（因为曾经一位厉害的学长告诉我将A运用于B会比将A升级为A+简单许多）</code><br><code>此外，我将这篇blog用作自己的学习日志与计划路线</code></p>
<h2 id="阶段一"><a href="#阶段一" class="headerlink" title="阶段一"></a>阶段一</h2><p>2025.4.30</p>
<ol>
<li>学习西瓜书上有关聚类的基础知识（概念、性能指标）</li>
<li>学习“k均值算法”、学习“学习向量量化算法”</li>
</ol>

        


        <span>
          <a class="article-read" href="/2025/04/30/Clustering-learning-route/"> Read more -->
          </span>
        </div>

        
    
    <div class="recent-post-item">

      <a href="/2025/04/30/Clustering-watermelon-book/" class="item-title">Clustering-watermelon-book</a>
      
      <time datetime="2025-04-30T11:58:19.000Z">
        2025-04-30
      </time>
      
      <!-- <div class="article-digest"> -->
        <!-- 聚类任务简介简单地说，就是要对一个n维向量元素的集合求一个划分，划分后的子集就是一类的（不相交的簇）。
对于数据集$D &#x3D; {x_1,x_2,…,x_m}$，划分为k个不相交的集合$C_1, C_2, …, C_k$，若$x_i \in C_j$，则$\lambda_i &#x3D; j$，其中$j \in {1,2,…,k}$，对应$\lambda_i$就是$x_i$的标签。聚类任务要做的是就是求出一个聚类结果$\lambda &#x3D; (\lambda_1,\lambda_2,…,\lambda_m)$，其中$\lambda$为数据集的簇标记向量，第$i$个分量标记了$x_i$属于哪一个簇。
性能度量怎样的聚类是好的：

簇内的样本尽量相似
簇间的样本尽量不同

外部指标外部指标：将聚类结果和某个“参考模型”进行比较，称为外部指标
对于数据集$D &#x3D; {x_1,x_2,…,x_m}$，使用聚类模型A，得到簇标记向量$\lambda$，另外使用参考聚类模型B，得到簇标记向量$\lambda^{*}$。
于是我们可以根据$\lambda_i$与$\lambda_ -->
        <!-- </div> -->

        
        <h2 id="聚类任务简介"><a href="#聚类任务简介" class="headerlink" title="聚类任务简介"></a>聚类任务简介</h2><p>简单地说，就是要对一个n维向量元素的集合求一个划分，划分后的子集就是一类的（不相交的簇）。</p>
<p>对于数据集$D &#x3D; {x_1,x_2,…,x_m}$，划分为k个不相交的集合$C_1, C_2, …, C_k$，若$x_i \in C_j$，则$\lambda_i &#x3D; j$，其中$j \in {1,2,…,k}$，对应$\lambda_i$就是$x_i$的标签。聚类任务要做的是就是求出一个聚类结果$\lambda &#x3D; (\lambda_1,\lambda_2,…,\lambda_m)$，其中$\lambda$为数据集的簇标记向量，第$i$个分量标记了$x_i$属于哪一个簇。</p>
<h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><p>怎样的聚类是好的：</p>
<ol>
<li>簇内的样本尽量相似</li>
<li>簇间的样本尽量不同</li>
</ol>
<h3 id="外部指标"><a href="#外部指标" class="headerlink" title="外部指标"></a>外部指标</h3><p>外部指标：将聚类结果和某个“参考模型”进行比较，称为外部指标</p>
<p>对于数据集$D &#x3D; {x_1,x_2,…,x_m}$，使用聚类模型A，得到簇标记向量$\lambda$，另外使用参考聚类模型B，得到簇标记向量$\lambda^{*}$。</p>
<p>于是我们可以根据$\lambda_i$与$\lambda_j$相同与否的关系以及$\lambda^{<em>}_i$<br>与$\lambda^{</em>}_j$是否相同的关系定义如下集合。</p>
<p>$DD,DS,SD,SS$一共四个集合，这些集合中的元素类似$(x_i,x_j)$，是一个“向量对”，分别按照如下规则界定类似的向量对是否属于相应的集合</p>
<ol>
<li>$x_i$与$x_j$在模型A、B的划分下都属于同一簇，则$(x_i,x_j) \in SS$</li>
<li>$x_i$与$x_j$在模型A、B的划分下都不属于同一簇，则$(x_i,x_j) \in DD$</li>
<li>$x_i$与$x_j$在模型A划分下属于同一簇，在B划分下不属于同一簇，则$(x_i,x_j) \in SD$</li>
<li>$x_i$与$x_j$在模型A划分下不属于同一簇，在B划分下属于同一簇，则$(x_i,x_j) \in DS$</li>
</ol>
<p><code>D即different，S即same 这样就非常容易理解了</code></p>
<p>根据上面的集合，我们可以定义如下过度变量</p>
<ol>
<li>$\lvert SS \rvert &#x3D; a$</li>
<li>$\lvert SD \rvert &#x3D; b$</li>
<li>$\lvert DS \rvert &#x3D; c$</li>
<li>$\lvert DD \rvert &#x3D; d$</li>
</ol>
<p>进一步，我们定义常用于性能度量的第一组系数</p>
<ol>
<li><strong>JC系数</strong> $JC &#x3D; \frac{a}{a+b+c}$</li>
<li><strong>FMI系数</strong> $FMI &#x3D; \sqrt{\frac{a}{a+b} \ast \frac{a}{a+c}}$</li>
<li><strong>Rand指数</strong> $RI &#x3D; \frac{2(a+b)}{m(m-1)}$</li>
</ol>
<p>这些性能指标的范围都是$[0,1]$，并且越大说明聚类效果越好<br><code>当然，前提是参考的模型是“正确”的</code></p>
<h3 id="距离计算"><a href="#距离计算" class="headerlink" title="距离计算"></a>距离计算</h3><h4 id="闵可夫斯基距离"><a href="#闵可夫斯基距离" class="headerlink" title="闵可夫斯基距离"></a>闵可夫斯基距离</h4><p>定义函数$dist(\cdot,\cdot)$，用于计算两个向量的距离。则它应该满足下述三个性质</p>
<ol>
<li>非负性</li>
<li>对称性</li>
<li>直递性</li>
</ol>
<p>常用的距离是闵可夫斯基距离</p>
<p>$dist_mk(x_i,x_j) &#x3D; (\sum_{\mu &#x3D; 1}^{n} \lvert x_{i\mu} - x_{j\mu} \rvert ^{p})^{\frac{1}{p}}$<br>显然当$p &#x3D; 2$时即我们常用的欧氏距离，$p &#x3D; 1$时为曼哈顿距离</p>
<h4 id="有序属性和无序属性"><a href="#有序属性和无序属性" class="headerlink" title="有序属性和无序属性"></a>有序属性和无序属性</h4><p>在考虑属性之间的距离的时候，序十分重要。这里通过简单的例子引入有序和无序。属性值出自于能够直接计算距离的属性称为有序属性，例如属性定义域为${1,2,3}$，而不能的就是无序属性，例如${货车,西瓜,乐乐}$。</p>
<p>显然，闵可夫斯基距离是用于衡量有序属性的距离的。</p>
<h4 id="VDM——衡量无序属性的距离"><a href="#VDM——衡量无序属性的距离" class="headerlink" title="VDM——衡量无序属性的距离"></a>VDM——衡量无序属性的距离</h4><p>假设有$k$个样本簇，$m_\mu,a$表示在属性$\mu$上取值为$a$的样本的个数，$m_\mu,a,i$表示在第i个样本簇中，属性$\mu$取值为$a$的样本个数。定义VDM如下。</p>
<p>$VDM &#x3D; \sum_{i&#x3D;1}^{k} \lvert \frac{m_\mu,a,i}{m_\mu,a} - \frac{m_\mu,b,i}{m_\mu,b}\rvert ^{p}$</p>
<p>值得注意的是，这里衡量的只是无序属性的距离，而要衡量两个无序样本$x_i$与$x_j$的距离，即其中的各个属性（类比向量的分量）都是无序属性，我们应该对各个属性的$VDM$求和。</p>
<h4 id="混合元素的距离"><a href="#混合元素的距离" class="headerlink" title="混合元素的距离"></a>混合元素的距离</h4><p>不失一般性，我们可以定义混合元素的距离如下：<br>$MinkovDM_p(x_i,x_j) &#x3D; (\sum_{\mu&#x3D;1}^{n_c} \lvert x_{i\mu} - x_{j\mu} \rvert ^{p} + \sum_{\mu&#x3D;n_c+1}^{n} VDM_p(x_{i,\mu},x_{j,\mu}))^{\frac{1}{p}}$</p>
<p>其中$x_i,x_j$为混合属性的元素，$1到n_c$对应为有序属性，$n_c到n$对应为无序属性</p>
<h3 id="内部指标"><a href="#内部指标" class="headerlink" title="内部指标"></a>内部指标</h3><p>于是我们可以根据元素的不同（有序、无序、混合），选取我们需要的距离函数$dist(\cdot,\cdot)$，定义如下常用于刻画簇的性质的量</p>
<ol>
<li>$\mu_i &#x3D; \frac{1}{\lvert C \rvert} \sum_{1 \le i \le \lvert C \rvert} x_i, \mu &#x3D; (\mu_1,\mu_2,…,\mu_m)$为簇$C$的中心点</li>
<li>$avg(C) &#x3D; \frac{2}{\lvert C \rvert (\lvert C \rvert - 1)} \sum_{1 \le i &lt; j \le \lvert C \rvert} dist(x_i,x_j)$ 簇$C$内样本间的平均距离</li>
<li>$diam(C) &#x3D; max_{1 \le i &lt; j \le \lvert C \rvert} dist(x_i,x_j)$ 簇$C$内样本间的最远距离</li>
<li>$d_{min}(C_i,C_j) &#x3D; min_{x_i \in C_i,x_j \in C_j} dist(x_i,x_j)$ 簇$C_i$和簇$C_j$中最近样本的距离</li>
<li>$d_{cen}(C_i,C_j) &#x3D; dist(\mu_i,\mu_j)$ 簇$C_i$和簇$C_j$的中心点距离</li>
</ol>
<p>进一步我们定义一些内部指标如下。</p>
<ol>
<li>$DBI &#x3D; \frac{1}{k} \sum_{i&#x3D;1}^{k} max_{j \ne i}(\frac{avg(C_i)+avg(C_j)}{d_{cen}(\mu_i,\mu_j)})$</li>
<li>$DI &#x3D; min_{1 \le i \le k} { min_{j \ne i}(\frac{d_{min}(C_i,C_j)}{min_{1 \le l \le k} diam(C_i)}) }$</li>
</ol>
<p>DB指数越小越好，Dunn指数越大越好</p>
<h2 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h2><p>原型的概念对应的是空间中的点。原型聚类的前提是认为，数据集中的聚类结构可以通过一组原型来描述。而原型聚类要做的就是通过某些方法找出这组“原型”。常见的原型聚类算法的代表有<code>k-means（k均值算法）</code>、<code>学习向量量化算法</code>等等</p>
<p>在后续的blog中会记录我复现相关算法的过程</p>

        


        <span>
          <a class="article-read" href="/2025/04/30/Clustering-watermelon-book/"> Read more -->
          </span>
        </div>

        
      </div>
      


      <div id="recent-posts-paginator">
        <a class="extend prev" rel="prev" href="/"> </a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"> </a>
      </div>

    </div>

<aside id="sidebar">
  
  <div class="widget-box">
  	  <div class="widget-box">
    <h3 class="widget-title-friends">friends</h3>
    <div class="widget">
      
    </div>
  </div>

  </div>
  
  <div class="widget-box">
  	

  </div>
  
  <div class="widget-box">
  	
  <div class="widget-box">
    <h3 class="widget-title-tag">tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/unity/" rel="tag">unity</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" rel="tag">分布式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A7%E5%AD%A6/" rel="tag">大学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" rel="tag">数据结构与算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88MTL%EF%BC%89/" rel="tag">机器学习（MTL）</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%85%83%E5%AD%A6%E4%B9%A0%EF%BC%89/" rel="tag">机器学习（元学习）</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%89/" rel="tag">机器学习（强化学习）</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%EF%BC%89/" rel="tag">机器学习（联邦学习）</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E8%81%9A%E7%B1%BB%EF%BC%89/" rel="tag">机器学习（聚类）</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/" rel="tag">计算机基础</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AF%97%E6%AD%8C/" rel="tag">诗歌</a></li></ul>
    </div>
  </div>


  </div>
  
  <div class="widget-box">
  	
  <div class="widget-box">
    <h3 class="widget-title-archive">archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/08/">August 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/07/">July 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/05/">May 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/04/">April 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">February 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li></ul>
    </div>
  </div>

  </div>
  
  <div class="widget-box">
  	
  <div class="widget-box">
    <h3 class="widget-title-post">recent_posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a class="recent_posts-list-link" href="/2025/08/17/PFL-SRDP/">PFL-SRDP</a>
          </li>
        
          <li>
            <a class="recent_posts-list-link" href="/2025/08/06/PFL2/">PFL2</a>
          </li>
        
          <li>
            <a class="recent_posts-list-link" href="/2025/07/29/PFL/">PFL</a>
          </li>
        
          <li>
            <a class="recent_posts-list-link" href="/2025/07/16/Joint-Local-Relational-Augmentation-and-Global-Nash-Equilibrium-for-Federated-Learning-with-Non-IID-Data/">Joint Local Relational Augmentation and Global Nash Equilibrium for Federated Learning with Non-IID Data</a>
          </li>
        
          <li>
            <a class="recent_posts-list-link" href="/2025/07/13/Reforcement-learning%E5%85%A5%E9%97%A8/">Reforcement learning入门</a>
          </li>
        
      </ul>
    </div>
  </div>

  </div>
  
</aside>

<!-- <div id="paginator"> -->
<!--   <a class="extend prev" rel="prev" href="/"> </a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"> </a> -->
<!-- </div> -->

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });
      </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });
      </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });
    </script>

    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



			</div>
		</div>

		<div id="bottom-outer">
			<div id="bottom-inner">
				Site by 阳生 | 
				Powered by <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a> |
				theme <a target="_blank" rel="noopener" href="https://github.com/fireworks99/hexo-theme-PreciousJoy">PreciousJoy</a>
			</div>
		</div>

		
	</div>





	
	<!-- scripts list from theme config.yml -->
	
	<script src="/js/jquery-3.5.1.min.js"></script>
	
	<script src="/js/PreciousJoy.js"></script>
	
	<script src="/js/highlight.pack.js"></script>
	
	<script src="/js/jquery.fancybox.min.js"></script>
	
	<script src="/js/search.js"></script>
	
	<script src="/js/load.js"></script>
	
	<script src="/js/jquery.mCustomScrollbar.concat.min.js"></script>
	
	<script src="/js/clipboard.min.js"></script>
	
	

	<script>hljs.initHighlightingOnLoad();</script>

</body>
</html>
